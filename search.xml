<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Varint编码]]></title>
    <url>%2Fposts%2F63107%2F</url>
    <content type="text"><![CDATA[什么是Varint编码Varint是一种使用一个或多个字节序列化整数的方法，会把整数编码为变长字节。 对于32位整型的4个字节数据经过Varint编码后需要1~5个字节，小的数字使用1个byte，大的数字使用5个bytes。 64位整型数据编码后占用1~10个字节。在实际场景中小数字的使用率远远多于大数字，因此通过Varint编码对于大部分场景都可以起到很好的压缩效果。 编码原理Varint 中的每个 byte 的最高位 bit 有特殊的含义，如果该位为 1，表示后续的 byte 也是该数字的一部分，如果该位为 0，则结束。 其他的 7 个 bit 都用来表示数字。因此小于 128 的数字都可以用一个 byte 表示。大于 128 的数字，比如 300，会用两个字节来表示：1010 1100 0000 0010 由于负数的高位为1,所以采用这种压缩处理的时候必须负数转成正数。 解码的过程就是将字节依次取出，去掉最高有效位，因为是小端排序所以先解码的字节要放在低位，之后解码出来的二进制位继续放在之前已经解码出来的二进制的高位，最后转换为10进制数完成varint编码的解码过程。 举例对数字123456进行varint编码，123456用二进制表示为1 11100010 01000000，每次低从向高取7位再加上最高有效位变成1100 0000 - 11000100 - 00000111 所以经过varint编码后123456占用三个字节分别为192 196 7。 每8位的第一位是最高有效位（most significant bit - msb）–msb。]]></content>
      <categories>
        <category>架构</category>
      </categories>
      <tags>
        <tag>Varint</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Kafka解压缩]]></title>
    <url>%2Fposts%2F27626%2F</url>
    <content type="text"><![CDATA[压缩的目的时间换空间，用CPU时间去换磁盘空间或网络IO传输量。 配置// 开启GZIP压缩// Producer启动后，生产的每个消息集合都会经过GZIP压缩，能够很好地节省网络传输带宽和Kafka Broker端的磁盘占用。 123props.put("compression.type", "gzip");Producer&lt;String, String&gt; producer = new KafkaProducer&lt;&gt;(props); Consumer通常来说解压缩发生在消费者Producer压缩，Broker保持、Consumer解压缩Kafka会将启用的压缩算法封装进消息集合中，当Consumer读取到消息集合时，会知道这些消息使用了哪一种压缩算法。 Broker与消息格式转换时发生的解压缩是不同的场景（主要为了兼容老版本的消费者）。 每个压缩过的消息集合在Broker端写入时都要发生解压缩操作，目的是为了对消息执行各种验证（主要影响CPU使用率）。 压缩算法对比Kafka 2.1.0之前，Kafka支持三种压缩算法：GZIP、Snappy、LZ4，从2.1.0开始正式支持zstd算法。 zstd是Facebook开源的压缩算法，能够提供超高的压缩比 评估一个压缩算法的优劣，主要有两个指标：压缩比、压缩/解压缩吞吐量。 zstd具有最高的压缩比，LZ4具有最高的吞吐量在Kafka的实际使用中 吞吐量：LZ4 &gt; Snappy &gt; zstd &gt; GZIP 压缩比：zstd &gt; LZ4 &gt; GZIP &gt; Snappy 带宽：由于Snappy的压缩比最低，因此占用的网络带宽最大 CPU：各个压缩算法差不多，在压缩时Snappy使用更多的CPU，在解压缩时GZIP使用更多的CPU带宽资源比CPU资源和磁盘资源更吃紧（千兆网络是标配），首先排除Snappy，其次排除GZIP，剩下在LZ4和zstd中选择。 如果客户端的CPU资源充足，强烈建议开启zstd压缩，可以极大地节省网络带宽。]]></content>
      <categories>
        <category>架构</category>
      </categories>
      <tags>
        <tag>kafka</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Kafka Producer配置]]></title>
    <url>%2Fposts%2F38013%2F</url>
    <content type="text"><![CDATA[acksproducer希望leader返回的用于确认请求完成的确认数量. 可选值 all, -1, 0 1. 默认值为1。 acks=0 不需要等待服务器的确认. 这是retries设置无效. 响应里来自服务端的offset总是-1. producer只管发不管发送成功与否。延迟低，容易丢失数据。 acks=1 表示leader写入成功（但是并没有刷新到磁盘）后即向producer响应。延迟中等，一旦leader副本挂了，就会丢失数据。 acks=all等待数据完成副本的复制, 等同于-1. 假如需要保证消息不丢失, 需要使用该设置. 同时需要设置unclean.leader.election.enable为true, 保证当ISR列表为空时, 选择其他存活的副本作为新的leader. buffer.memoryproducer可以使用的最大内存来缓存等待发送到server端的消息. 如果消息速度大于producer交付到server端的阻塞时间max.block.ms, 将会抛出异常. 默认值33554432 byte (32m). 这个设置不是一个严格的边界, 因为producer除了用来缓存消息, 还要用来进行压缩. compression.typeproducer压缩数据的类型, 默认为none, 就是不压缩. 可选none, gzip, snappy 和lz4. 压缩整个batch的数据, 因此batch的效果对压缩率也有影响. 更多的批处理意味着更好的压缩。 retries设置大于零的值将导致客户端重新发送其发送失败并发生潜在的瞬时错误的记录. 相当于client在发送失败的时候会重新发行. 如果设置了retries而没有将max.in.flight.request.per.connection设置为1, 在两个batch发送到同一个partition时有可能打乱消息的发送顺序(第一个发送失败, 而第二个发送成功) batch.sizeproducer会尝试批量发送属于同一个partition的消息以减少请求的数量. 这样可以提升客户端和服务端的性能. 默认大小是16348 byte (16k). 发送到broker的请求可以包含多个batch, 每个batch的数据属于同一个partition. 太小的batch会降低吞吐. 太大会浪费内存. max.request.size请求的最大大小（以字节为单位）。 此设置将限制生产者在单个请求中发送的记录批次数，以避免发送巨大的请求。 这也是最大记录批量大小的上限。 请注意，服务器拥有自己的记录批量大小，可能与此不同。 partitioner.classPartitioner接口的实现类, 默认是org.apache.kafka.clients.producer.internals.DefaultPartitioner. 需要处理数据倾斜等原因调整分区逻辑的时候使用. request.timeout.ms配置控制客户端等待请求响应的最长时间。 如果在超时之前未收到响应，客户端将在必要时重新发送请求，如果重试耗尽，则该请求将失败。 这应该大于replica.lag.time.max.ms(broker配置)，以减少由于不必要的生产者重试引起的消息重复的可能性。 enable.idempotence设置为’true’, 将开启exactly-once模式. 设置为’false’(默认值), producer会因为borker失败等原因重试发送, 可能会导致消息重复. 设置为’true’时需要结合max.in.flight.requests.per.connection设为’1’和retires不能为’0’, 同时acks需要设置为’all’或者”-1’. interceptor.classes一组ProducerInterceptor接口的实现类, 默认为null. 可以通过该接口的实现类去拦截(可能需要修改)producer要发送的消息在发送到服务端之前. retry.backoff.ms失败请求重试的间隔时间. 默认是100毫秒 transactional.id用于事务传递的TransactionalId。 这使得可以跨越多个生产者会话的可靠性语义，因为它允许客户端保证在开始任何新事务之前使用相同的TransactionalId的事务已经完成。 如果没有提供TransactionalId，则生产者被限制为幂等传递。 请注意，如果配置了TransactionalId，则必须启用enable.idempotence。 默认值为空，这意味着无法使用事务。 linger.ms在正常负载的情况下, 要想减少请求的数量. 加上一个认为的延迟: 不是立即发送消息, 而是延迟等待更多的消息一起批量发送. 当达到得了batch.size的同一partition的消息会立即发送, 不管linger.ms的设置. 假如要发送的消息比较少, 会等待指定的时间以获取更多的消息. 默认设置为0 ms(没有延迟). max.in.flight.requests.per.connection没有被确认unacknowledge的batch数, 如果设置大于1在retries设置了的情况下会出现消息发送顺序错误.]]></content>
      <categories>
        <category>架构</category>
      </categories>
      <tags>
        <tag>kafka</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Maven 打包Plugins集成]]></title>
    <url>%2Fposts%2F22633%2F</url>
    <content type="text"><![CDATA[目标 jar冲突检测 源码编译 源码生成jar pom依赖jar拷贝 spring boot可执行jar生成 脚本动态生成 生成目录和打包tar 版本及配置123456789101112131415&lt;properties&gt; &lt;app.main.class&gt;&lt;/app.main.class&gt; &lt;maven-enforcer-plugin&gt;1.4.1&lt;/maven-enforcer-plugin&gt; &lt;maven-compiler-plugin&gt;3.1&lt;/maven-compiler-plugin&gt; &lt;maven-jar-plugin&gt;2.6&lt;/maven-jar-plugin&gt; &lt;maven-dependency-plugin&gt;2.10&lt;/maven-dependency-plugin&gt; &lt;maven-source-plugin&gt;3.0.1&lt;/maven-source-plugin&gt; &lt;spring-boot-maven-plugin&gt;1.5.13.RELEASE&lt;/spring-boot-maven-plugin&gt; &lt;src.data.dir&gt;src/main/data&lt;/src.data.dir&gt; &lt;dependency.dist.dir&gt;$&#123;project.build.directory&#125;/dist&lt;/dependency.dist.dir&gt; &lt;dependency.lib.dir&gt;$&#123;dependency.dist.dir&#125;/lib&lt;/dependency.lib.dir&gt; &lt;dependency.data.dir&gt;$&#123;dependency.dist.dir&#125;/data&lt;/dependency.data.dir&gt; &lt;dependency.bin.dir&gt;$&#123;dependency.dist.dir&#125;/bin&lt;/dependency.bin.dir&gt; &lt;dependency.log.dir&gt;$&#123;dependency.dist.dir&#125;/logs&lt;/dependency.log.dir&gt; &lt;/properties&gt; 资源目录1234567891011&lt;resources&gt; &lt;resource&gt; &lt;directory&gt;src/main/resources&lt;/directory&gt; &lt;filtering&gt;false&lt;/filtering&gt; &lt;/resource&gt; &lt;!--非资源目录--&gt; &lt;resource&gt; &lt;directory&gt;bin&lt;/directory&gt; &lt;filtering&gt;true&lt;/filtering&gt; &lt;/resource&gt; &lt;/resources&gt; plugins插件123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177&lt;plugins&gt; &lt;!--jar冲突排查--&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-enforcer-plugin&lt;/artifactId&gt; &lt;version&gt;$&#123;maven-enforcer-plugin&#125;&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;enforce&lt;/id&gt; &lt;configuration&gt; &lt;rules&gt; &lt;dependencyConvergence&gt; &lt;uniqueVersions&gt;true&lt;/uniqueVersions&gt; &lt;/dependencyConvergence&gt; &lt;/rules&gt; &lt;/configuration&gt; &lt;goals&gt; &lt;goal&gt;enforce&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;!--jdk版本编译--&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;version&gt;$&#123;maven-compiler-plugin&#125;&lt;/version&gt; &lt;configuration&gt; &lt;useIncrementalCompilation&gt;false&lt;/useIncrementalCompilation&gt; &lt;source&gt;1.8&lt;/source&gt; &lt;target&gt;1.8&lt;/target&gt; &lt;encoding&gt;UTF-8&lt;/encoding&gt; &lt;skip&gt;true&lt;/skip&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;!-- 用于生成jar包的plugin --&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-jar-plugin&lt;/artifactId&gt; &lt;version&gt;$&#123;maven-jar-plugin&#125;&lt;/version&gt; &lt;configuration&gt; &lt;outputDirectory&gt;$&#123;dependency.lib.dir&#125;&lt;/outputDirectory&gt; &lt;skip&gt;true&lt;/skip&gt; &lt;archive&gt; &lt;manifest&gt; &lt;addClasspath&gt;true&lt;/addClasspath&gt; &lt;mainClass&gt;$&#123;app.main.class&#125;&lt;/mainClass&gt; &lt;useUniqueVersions&gt;false&lt;/useUniqueVersions&gt; &lt;/manifest&gt; &lt;manifestEntries&gt; &lt;Class-Path&gt;./&lt;/Class-Path&gt; &lt;/manifestEntries&gt; &lt;/archive&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;!-- 用于拷贝maven依赖的plugin --&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-dependency-plugin&lt;/artifactId&gt; &lt;version&gt;$&#123;maven-dependency-plugin&#125;&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;copy-dependencies&lt;/id&gt; &lt;phase&gt;install&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;copy-dependencies&lt;/goal&gt; &lt;/goals&gt; &lt;configuration&gt; &lt;!-- 把依赖的所有jar包拷贝到lib目录中--&gt; &lt;outputDirectory&gt;$&#123;dependency.lib.dir&#125;&lt;/outputDirectory&gt; &lt;excludeTransitive&gt;false&lt;/excludeTransitive&gt; &lt;stripVersion&gt;false&lt;/stripVersion&gt; &lt;overWriteSnapshots&gt;true&lt;/overWriteSnapshots&gt; &lt;overWriteReleases&gt;true&lt;/overWriteReleases&gt; &lt;overWriteIfNewer&gt;true&lt;/overWriteIfNewer&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;configuration&gt; &lt;excludeScope&gt;provided&lt;/excludeScope&gt; &lt;includeScope&gt;runtime&lt;/includeScope&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;!--将Spring Boot应用打包为可执行的jar或war文件--&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;version&gt;$&#123;spring-boot-maven-plugin&#125;&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;goals&gt; &lt;goal&gt;build-info&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;!--源码打包并发布--&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-source-plugin&lt;/artifactId&gt; &lt;version&gt;$&#123;maven-source-plugin&#125;&lt;/version&gt; &lt;configuration&gt; &lt;outputDirectory&gt;$&#123;project.build.directory&#125;/sources-lib&lt;/outputDirectory&gt; &lt;/configuration&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;attach-sources&lt;/id&gt; &lt;goals&gt; &lt;goal&gt;jar&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;!-- copy文件 --&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-antrun-plugin&lt;/artifactId&gt; &lt;executions&gt; &lt;execution&gt; &lt;phase&gt;install&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;run&lt;/goal&gt; &lt;/goals&gt; &lt;configuration&gt; &lt;tasks&gt; &lt;mkdir dir="$&#123;src.data.dir&#125;"/&gt; &lt;mkdir dir="$&#123;dependency.dist.dir&#125;"/&gt; &lt;mkdir dir="$&#123;dependency.lib.dir&#125;"/&gt; &lt;mkdir dir="$&#123;dependency.log.dir&#125;"/&gt; &lt;mkdir dir="$&#123;dependency.data.dir&#125;"/&gt; &lt;mkdir dir="$&#123;dependency.bin.dir&#125;"/&gt; &lt;copy todir="$&#123;dependency.dist.dir&#125;" overwrite="true"&gt; &lt;fileset dir="$&#123;src.data.dir&#125;"/&gt; &lt;/copy&gt; &lt;chmod file="$&#123;dependency.bin.dir&#125;/app.sh" perm="ugo+rx"/&gt; &lt;tar destfile="$&#123;project.build.directory&#125;/$&#123;project.artifactId&#125;-$&#123;project.version&#125;.tar" basedir="$&#123;project.build.directory&#125;/dist"/&gt; &lt;/tasks&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;groupId&gt;ru.yaal.maven&lt;/groupId&gt; &lt;artifactId&gt;write-text-files-maven-plugin&lt;/artifactId&gt; &lt;version&gt;1.1&lt;/version&gt; &lt;configuration&gt; &lt;charset&gt;UTF-8&lt;/charset&gt; &lt;files&gt; &lt;file&gt; &lt;path&gt;$&#123;dependency.bin.dir&#125;/app.sh&lt;/path&gt; &lt;lines&gt; &lt;line&gt;#!/bin/sh&lt;/line&gt; &lt;line&gt;exit 0&lt;/line&gt; &lt;/lines&gt; &lt;/file&gt; &lt;/files&gt; &lt;/configuration&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;write-text-files&lt;/id&gt; &lt;phase&gt;prepare-package&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;write-text-files&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt;&lt;/plugins&gt;]]></content>
      <categories>
        <category>工具利器</category>
      </categories>
      <tags>
        <tag>Maven</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis Cluster]]></title>
    <url>%2Fposts%2F39943%2F</url>
    <content type="text"><![CDATA[Redis ClusterRedis Cluster是Redis3.0版本推出的高可用及分布式解决方案，多个Redis实例组成，数据按照槽(slot)存储分布在多个Redis实例上，通过Gossip流言协议来进行节点之间通信。 Redis Cluster实现的功能： • 将数据分片到多个实例(按照slot存储)；• 集群节点宕掉会自动failover；• 提供相对平滑扩容(缩容)节点。 Redis Cluster暂未有的：• 实时同步• 强一致性 分片实现基于hash的分片方式，具体是虚拟槽分区。 虚拟槽分区 槽(slot):使用分散度良好的hash函数把所有数据映射到一个固定范围的整数集合中。 Redis Cluster槽的范围是0 ~ 16383。槽是集群内数据管理和迁移的基本单位。 分片的具体算法Redis Cluster使用slot = CRC16(key) %16384来计算键key属于哪个slot。 CRC算法全称循环冗余校验算法。16位的CRC码产生的规则是先将要发送的二进制序列数左移16位（既乘以）后,再除以一个多项式,最后 所得到的余数既是CRC码。(注: CRC16算法——循环冗余校验(Cyclic Redundancy Check/Code)，即G(x)为：x16+ x12+ x5+ 1。) 集群状态当16384个槽都有节点在处理时，集群处于上线状态(ok)； 如果有任何一个槽没有得到处理(或者某一分片的最后一个节点挂了)，那么集群处于下线状态(fail)。 如果集群超过半数以上master挂掉，无论是否有slave集群，均进入fail状态。 节点ID每个节点在集群中都有唯一的ID，该ID是由40位的16进制字符组成，具体是节点第一次启动由linux的/dev/urandom生成。 具体信息会保存在node.cnf配置文件中(该文件有Redis Cluster自动维护，可以通过参数cluster-config-file来指定路径和名称)，如果该文件被删除，节点ID将会重新生成。 节点ID用于标识集群中的每个节点，包括指定Replication Master。只要节点ID不改变，哪怕节点的IP和端口发生了改变，Redis Cluster可以自动识别出IP和端口的变化，并将变更的信息通过Gossip协议广播给其他节点。 clusterNode结构的slots属性记录了节点负责处理那些槽。 Slots属性是一个二进制位数组(bitarray)，这个数组的长度为16384/8=2048个字节，共包含16384个二进制位。 Master节点用bit来标识对于某个槽自己是否拥有。比如对于编号为1的槽，Master只要判断序列的第二位（索引从0开始）是不是为1即可。时间复杂度为O（1）。 将所有槽的指派信息保存在clusterState.slots数组里面，程序要检查槽i是否已经被指派，又或者取得负责处理槽i的节点，只需要访问clusterState.slots[i]的值即可，复杂度仅为O（1）。 请求重定向由于每个节点只负责部分slot，以及slot可能从一个节点迁移到另一节点，造成客户端有可能会向错误的节点发起请求。 因此需要有一种机制来对其进行发现和修正，这就是请求重定向。有两种不同的重定向场景： a)MOVED错误1.请求的key对应的槽不在该节点上，节点将查看自身内部所保存的哈希槽到节点ID的映射记录，节点回复一个MOVED错误。2.需要客户端进行再次重试。 b)ASK错误1.请求的key对应的槽目前的状态属于MIGRATING状态，并且当前节点找不到这个key了，节点回复ASK错误。ASK会把对应槽的IMPORTING节点返回给你，告诉你去IMPORTING的节点尝试找找。2.客户端进行重试首先发送ASKING命令，节点将为客户端设置一个一次性的标志（flag），使得客户端可以执行一次针对IMPORTING状态的槽的命令请求，然后再发送真正的命令请求。3.不必更新客户端所记录的槽至节点的映射。 节点通信采用P2P的Gossip协议，Gossip协议的原理就是每个节点与其他节点间不断通信交换信息，一段时间后节点信息一致，每个节点都知道集群的完整信息。 (1)集群中的每个节点都会单独开辟一个TCP通道，用于节点之间彼此通信，通信端口号在基础端口上加10000； (2)每个节点在固定周期内通过特定规则选择几个节点发送ping消息； (3)接收到ping消息的节点用pong消息作为响应。 集群中每个节点通过一定规则挑选要通信的节点，每个节点可能知道全部节点，也可能仅知道部分节点.只要这些节点彼此可以正常通信，最终它们会达到一致的状态。 当节点出故障、新节点加入、主从角色变化、槽信息变更等事件发生时，通过不断的ping/pong消息通信，经过一段时间后所有的节点都会知道整个集群全部节点的最新状态，从而达到集群状态同步的目的。 Gossip消息Gossip协议的主要职责就是信息交换，信息交换的载体就是节点彼此发送的Gossip消息，常用的Gossip消息可分为： • meet消息：用于通知新节点加入。消息发送者通知接收者加入到当前集群，meet消息通信正常完成后，接收节点会加入到集群中并进行周期性的ping、pong消息交换； • ping消息：集群内交换最频繁的消息，集群内每个节点每秒向多个其他节点发送ping消息，用于检测节点是否在线和交换彼此状态信息。ping消息发送封装了自身节点和部分其他节点的状态数据。 • pong消息：当接收到ping、meet消息时，作为响应消息回复给发送方确认消息正常通信。pong消息内部封装了自身状态数据。节点也可以向集群内广播自身的pong消息来通知整个集群对自身状态进行更新。 • fail消息：当节点判定集群内另一个节点下线时，会向集群内广播一个fail消息，其他节点接收到fail消息之后把对应节点更新为下线状态。 通信规则Redis集群内节点通信采用固定频率(定时任务每秒执行10次)。由于内部需要频繁地进行节点信息交换，而ping/pong消息会携带当前节点和部分其他节点的状态数据，势必会加重带宽和计算的负担。 • 通信节点选择过多可以让信息及时交换，但是成本过高； • 通信节点选择过少会降低集群内所有节点彼此信息交换频率，从而影响故障判定、新节点发现等需求的速度。 节点选择消息交换的成本主要体现在单位时间选择发送消息的节点数量和每个消息携带的数据量。 (1)选择发送消息的节点数量 集群内每个节点维护定时任务默认每秒执行10次，每秒会随机选择5个节点找出最久没有通信的节点发送ping消息，用于Gossip信息交换的随机性。 每100毫秒都会扫描本地节点列表，如果发现节点最后一次接受pong消息的时间大于cluster_node_timeout/2，则立刻发送ping消息,防止该节点信息太长时间未更新。 根据以上规则得出每个节点每秒需要发送ping消息的数量=1+10*num(node.pong_received&gt; cluster_node_timeout/2)，因此cluster_node_timeout参数对消息发送的节点数量影响非常大。 当我们的带宽资源紧张时，可以适当调大此参数。但是如果cluster_node_timeout过大会影响消息交换的频率从而影响故障转移、槽信息更新、新节点发现的速度。因此需要根据业务容忍度和资源消耗进行平衡。同时整个集群消息总交换量也跟节点数成正比。 消息数据量每个ping消息的数据量体现在消息头和消息体中，其中消息头主要占用空间的字段是myslots[CLUSTER_SLOTS/8]，占用2KB，这块空间占用相对固定。 消息体会携带一定数量的其他节点信息用于信息交换。而消息体携带数据量跟集群的节点数量相关，集群越大每次消息通信的成本也就更高。]]></content>
      <categories>
        <category>架构</category>
      </categories>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis跳表]]></title>
    <url>%2Fposts%2F64570%2F</url>
    <content type="text"><![CDATA[跳表跳表（skiplist）是一个特俗的链表，相比一般的链表，有更高的查找效率，其效率可比拟于二叉查找树。 Redis里面使用skiplist是为了实现sorted set这种对外的数据结构。 跳表预先间隔地保存了有序链表中的节点，从而在查找过程中能达到类似于二分搜索的效果，而二分搜索思想就是通过比较中点数据放弃另一半的查找，从而节省一半的查找时间，缺点即浪费了空间。 性质 由很多层结构组成 每一层都是一个有序的链表 最底层(Level 1) 的链表包含所有元素 如果一个元素出现在 Level i 的链表中，则它在 Level i 之下的链表也都会出现。 每个节点包含两个指针，一个指向同一链表中的下一个元素，一个指向下面一层的元素。 插入新插入一个节点之后，就会打乱上下相邻两层链表上节点个数严格的2:1的对应关系。如果要维持这种对应关系，就必须把新插入的节点后面的所有节点（也包括新插入的节点）重新进行调整，这会让时间复杂度重新蜕化成O(n)。 skiplist为了避免这一问题，它不要求上下相邻两层链表之间的节点个数有严格的对应关系，而是为每个节点随机出一个层数(level)。 首先确定该关键字的层数，层数是根据随机算法生成的，但是为了不让层数过大，会有一个最大层数MAX_LEVEL限制，随机算法生成的数值不得大于该值。 每一个节点的层数（level）是随机出来的，而且新插入一个节点不会影响其它节点的层数。因此，插入操作只需要修改插入节点前后的指针，而不需要对很多节点都进行调整。这就降低了插入操作的复杂度。实际上，这是skiplist的一个很重要的特性，这让它在插入性能上明显优于平衡树的方案。 查找skiplist除了最下面第1层链表之外，它会产生若干层稀疏的链表，这些链表里面的指针故意跳过了一些节点（而且越高层的链表跳过的节点越多）。这就使得我们在查找数据的时候能够先在高层的链表中进行查找，然后逐层降低，最终降到第1层链表来精确地确定数据位置。在这个过程中，我们跳过了一些节点，从而也就加快了查找速度。 skiplist与平衡树、哈希表的比较 skiplist和各种平衡树（如AVL、红黑树等）的元素是有序排列的，而哈希表不是有序的。因此，在哈希表上只能做单个key的查找，不适宜做范围查找。所谓范围查找，指的是查找那些大小在指定的两个值之间的所有节点。 在做范围查找的时候，平衡树比skiplist操作要复杂。在平衡树上，我们找到指定范围的小值之后，还需要以中序遍历的顺序继续寻找其它不超过大值的节点。如果不对平衡树进行一定的改造，这里的中序遍历并不容易实现。而在skiplist上进行范围查找就非常简单，只需要在找到小值之后，对第1层链表进行若干步的遍历就可以实现。 平衡树的插入和删除操作可能引发子树的调整，逻辑复杂，而skiplist的插入和删除只需要修改相邻节点的指针，操作简单又快速。 查找单个key，skiplist和平衡树的时间复杂度都为O(log n)，大体相当；而哈希表在保持较低的哈希值冲突概率的前提下，查找时间复杂度接近O(1)，性能更高一些。所以我们平常使用的各种Map或dictionary结构，大都是基于哈希表实现的。 从算法实现难度上来比较，skiplist比平衡树要简单得多。]]></content>
      <categories>
        <category>架构</category>
      </categories>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zero-Copy]]></title>
    <url>%2Fposts%2F20850%2F</url>
    <content type="text"><![CDATA[Zero-Copy零拷贝Zero-Copy用于提高Linux平台上的IO密集型的应用程序的性能。能够避免中间缓冲区中的冗余数据复制以及减少Linux内核空间和用户空间上下文交换的次数。 Zero-Copy使得应用程序从本地磁盘读取数据，再将读取的数据原封不动直接地发送给Socket。 传统数据传输过程数据先从本地磁盘读取到内核空间中，再通过缓冲区由用户程序得到，用户程序再通过缓冲区将数据发送到Socket。 即: 本地磁盘-&gt;内核buffer:用户态-&gt;内核态 内核buffer-&gt;用户buffer:内核态-&gt;用户态 用户buffer-&gt;socket buffer:用户态-&gt;内核态 socket buffer-&gt;协议引擎:内核态-&gt;用户态 这个过程当中一共出现了4次数据拷贝和4次用户态-内核态的上下文切换。 每次数据传输到内核-用户缓冲区时，必须进行复制，这消耗了CPU和内存，通过zerocopy请求使得数据直接从内核发送到Socket。即: 本地磁盘-&gt;内核buffer:用户态-&gt;内核态 内核buffer-&gt;socket buffer:内核态-&gt;内核态 socket buffer-&gt;协议引擎:内核态-&gt;用户态这个过程当中一共出现了3次数据拷贝和2次用户态-内核态的上下文切换。 transferToJAVA类库通过java.nio.channels.FileChannel. transferTo()方法支持zerocopy技术。 transferTo() 方法将数据从一个文件channel传输到一个可写channel。在内部它依赖于操作系统对 Zero-copy 的支持，在UNIX/Linux系统上， transferTo() 实际会调用 sendfile() 这个系统函数，将数据从一个文件描述符传输到另一个。 与传统方法相比，使用transferTo（）API可减少大约65％的时间。这对于需要将大量数据从一个I / O通道复制到另一个I / O通道的应用程序（如Web服务器）来说可以显著提高性能。 内核态和用户态内核态：cpu可以访问内存的所有数据，包括外围设备，例如硬盘，网卡，cpu也可以将自己从一个程序切换到另一个程序。 用户态：只能受限的访问内存，且不允许访问外围设备，占用cpu的能力被剥夺，cpu资源可以被其他程序获取。 为什么要有用户态和内核态？由于需要限制不同的程序之间的访问能力, 防止他们获取别的程序的内存数据, 或者获取外围设备的数据, 并发送到网络, CPU划分出两个权限等级 – 用户态和内核态。 用户态与内核态的切换所有用户程序都是运行在用户态的，但是有时候程序确实需要做一些内核态的事情，例如从硬盘读取数据, 或者从键盘获取输入等。 而唯一可以做这些事情的就是操作系统,所以此时程序就需要先操作系统请求以程序的名义来执行这些操作。 用户态切换到内核态的唯一途径：中断/异常/陷入内核态切换到用户态的途径：设置程序状态字]]></content>
      <categories>
        <category>架构</category>
      </categories>
      <tags>
        <tag>Zero-Copy</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ThreadLocal原理]]></title>
    <url>%2Fposts%2F46263%2F</url>
    <content type="text"><![CDATA[使用定义123456private static ThreadLocal&lt;String&gt; CHARSET = new ThreadLocal&lt;String&gt;() &#123; @Override protected String initialValue() &#123; return "utf-8"; &#125; &#125;; 或者 1private static ThreadLocal&lt;String&gt; CHARSET = ThreadLocal.withInitial(() -&gt; "utf-8"); 销毁1CHARSET.remove(); 原理 一个线程Thread包含一个ThreadLocalMap变量 一个ThreadLocal包含一个ThreadLocalMap内部类 一个ThreadLocalMap包含一个Entry内部类 一个ThreadLocalMap的key为ThreadLocal对象 一个ThreadLocalMap的value为Entry的数组 初始化1234567891011121314private T setInitialValue() &#123; //默认null T value = initialValue(); //native方法，返回线程对象引用 Thread t = Thread.currentThread(); //默认null ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value); else //创建ThreadLocalMap createMap(t, value); return value;&#125; setInitialValue为ThreadLocal方法，负责 初始化线程变量 初始化线程变量值 123public class Thread implements Runnable &#123;ThreadLocal.ThreadLocalMap threadLocals = null;&#125; threadLocals属于当前线程，负责 记录线程变量 保持多线程隔离1234567891011public class ThreadLocal&lt;T&gt; &#123; void createMap(Thread t, T firstValue) &#123; //初始化值到map中，this为ThreadLocal对象 //threadLocals为线程变量 t.threadLocals = new ThreadLocalMap(this, firstValue); &#125; ThreadLocalMap getMap(Thread t) &#123; //获取本线程变量map return t.threadLocals; &#125;&#125; createMap为ThreadLocal方法，负责创建线程变量map 12345678910111213141516171819public class ThreadLocal&lt;T&gt; &#123; static class ThreadLocalMap &#123; //构造方法 ThreadLocalMap(ThreadLocal&lt;?&gt; firstKey, Object firstValue) &#123; //创建table，初始容量16 table = new Entry[INITIAL_CAPACITY]; //索引位置 int i = firstKey.threadLocalHashCode &amp; (INITIAL_CAPACITY - 1); //填充 table[i] = new Entry(firstKey, firstValue); //当前大小 size = 1; //resize 阈值,2/3 //threshold = len * 2 / 3; setThreshold(INITIAL_CAPACITY); &#125; &#125; &#125;&#125; ThreadLocalMap为ThreadLocal静态类，key为ThreadLocal对象，提供 当前线程内，所有变量和值得map 设置索引位置，设置resize阈值 setThreadLocal方法 12345678910public void set(T value) &#123; //当前线程对象 Thread t = Thread.currentThread(); //获取线程内的变量map ThreadLocalMap map = getMap(t); if (map != null) //赋值 map.set(this, value); else createMap(t, value); 赋值 123456789101112131415161718192021222324252627282930private void set(ThreadLocal&lt;?&gt; key, Object value) &#123; Entry[] tab = table; int len = tab.length; //取余 int i = key.threadLocalHashCode &amp; (len-1); //存在该索引值 for (Entry e = tab[i]; e != null; e = tab[i = nextIndex(i, len)]) &#123; ThreadLocal&lt;?&gt; k = e.get(); //找到key if (k == key) &#123; //替换 e.value = value; return; &#125; //k为null，即弱引用的垃圾回收，则清除旧值并替换设置值 if (k == null) &#123; replaceStaleEntry(key, value, i); return; &#125; &#125; //不存在则新建 tab[i] = new Entry(key, value); //当前大小+1 int sz = ++size; //清除弱引用无用数据并确定是否扩容 if (!cleanSomeSlots(i, sz) &amp;&amp; sz &gt;= threshold) rehash(); &#125; 负责设置变量值 get123456789101112131415161718192021222324252627public T get() &#123; //当前线程 Thread t = Thread.currentThread(); //线程内变量map ThreadLocalMap map = getMap(t); if (map != null) &#123; //获取值对象 ThreadLocalMap.Entry e = map.getEntry(this); if (e != null) &#123; @SuppressWarnings("unchecked") T result = (T)e.value; return result; &#125; &#125; //初始化 return setInitialValue();&#125;private Entry getEntry(ThreadLocal&lt;?&gt; key) &#123; //索引位置 int i = key.threadLocalHashCode &amp; (table.length - 1); //数组取值 Entry e = table[i]; if (e != null &amp;&amp; e.get() == key) return e; else return getEntryAfterMiss(key, i, e);&#125; hash和索引计算firstKey.threadLocalHashCode，获取线程变量hashcode 12345private final int threadLocalHashCode = nextHashCode();private static final int HASH_INCREMENT = 0x61c88647;private static int nextHashCode() &#123; return nextHashCode.getAndAdd(HASH_INCREMENT);&#125; 0x61c88647，斐波那契散列即黄金分割 HASH_INCREMENT的0x61c88647对应的十进制为1640531527 0x61c88647与一个神奇的数字产生关系，就是 (Math.sqrt(5) - 1)/2。也就是传说中的黄金比例 0.618（0.618 只是一个粗略值），即0x61c88647 = 2^32 * 黄金分割比。 通过HASH_INCREMENT再借助一定的算法，就可以将哈希码能均匀的分布在2的N次方的数组里，保证了散列表的离散度，从而降低了冲突几率。 用0x61c88647作为魔数累加为每个ThreadLocal分配各自的ID也就是threadLocalHashCode再与2的幂取模，得到的结果分布很均匀。 firstKey.threadLocalHashCode &amp; (INITIAL_CAPACITY - 1)即求余]]></content>
      <categories>
        <category>架构</category>
      </categories>
      <tags>
        <tag>ThreadLocal</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Canal配置]]></title>
    <url>%2Fposts%2F60983%2F</url>
    <content type="text"><![CDATA[新增用户和权限12345678910# 新增用户CREATE USER canal IDENTIFIED BY 'canal';# 授权REPLICATION权限GRANT SELECT, REPLICATION SLAVE, REPLICATION CLIENT ON *.* TO 'canal'@'%'; FLUSH PRIVILEGES; # checkshow grants for 'canal';# 查看当前db binlog文件show binary logs ; 编译包编译 123git clone git@github.com:alibaba/canal.gitgit co canal-$version #切换到对应的版本上mvn clean install -Denv=release 解压部署 1234# 启动./startup.sh# 关闭./stop.sh canal配置文件：canal.properties canal.destinations当前server上部署的instance列表，多个以逗号隔开 canal.ipcanal server绑定的本地IP信息，如果不配置，默认选择一个本机IP进行启动服务 canal.register.ipcanal server注册到外部zookeeper、admin的ip信息 (针对docker的外部可见ip) canal.portcanal server提供socket服务的端口，默认11111 canal.instance.memory.batch.modecanal内存store中数据缓存模式 ITEMSIZE : 根据buffer.size进行限制，只限制记录的数量 MEMSIZE : 根据buffer.size * buffer.memunit的大小，限制缓存记录的大小 canal.instance.memory.buffer.sizecanal内存store中可缓存buffer记录数，需要为2的指数 canal.instance.memory.buffer.memunit内存记录的单位大小，默认1024即1KB，和buffer.size组合决定最终的内存使用大小 canal.instance.filter.query.dcl是否忽略dcl语句，默认false，比如grant/create user等 canal.instance.filter.query.dml是否忽略DML的query语句，比如insert/update/delete table。 canal.instance.filter.query.ddl是否忽略DDL的query语句，比如create table/alater table/drop table/rename table/create index/drop index。(目前支持的ddl类型主要为table级别的操作，create databases/trigger/procedure暂时划分为dcl类型) canal.instance.binlog.format支持的binlogFormat,如果设置会执行强校验。默认无，可以设置ROW,STATEMENT,MIXED。 canal.instance.filter.rows是否忽略dml的数据变更事件(主要针对用户只订阅ddl/dcl的操作) canal.usercanal数据端口订阅的ACL配置；如果为空，代表不开启 canal.passwdcanal数据端口订阅的ACL配置；如果为空，代表不开启 instance配置文件：instance.properties参数列表： canal.instance.master.addressmysql主库链接地址 canal.instance.master.journal.namemysql主库链接时起始的binlog文件 canal.instance.master.positionmysql主库链接时起始的binlog偏移量 canal.instance.master.timestampmysql主库链接时起始的binlog的时间戳 canal.instance.dbUsernamemysql数据库帐号 canal.instance.dbPasswordmysql数据库密码 canal.instance.defaultDatabaseNamemysql链接时默认schema canal.instance.filter.regex mysql 数据解析关注的表，Perl正则表达式. 多个正则之间以逗号(,)分隔，转义符需要双斜杠(\) 常见例子： 所有表：.* or .\.. canal schema下所有表： canal\..* canal下的以canal打头的表：canal\.canal.* canal schema下的一张表：canal\.test1 多个规则组合使用：canal\..*,mysql.test1,mysql.test2 (逗号分隔) canal.instance.filter.black.regexmysql数据解析表的黑名单，表达式规则见白名单的规则 起始位置canal.instance.master.journal.name+canal.instance.master.position精确指定一个binlog位点，进行启动 canal.instance.master.timestamp指定一个时间戳，canal会自动遍历mysql binlog，找到对应时间戳的binlog位点后，进行启动。 不指定任何信息默认从当前数据库的位点，进行启动。(show master status)]]></content>
      <categories>
        <category>架构</category>
      </categories>
      <tags>
        <tag>Canal</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker搭建kafka]]></title>
    <url>%2Fposts%2F58214%2F</url>
    <content type="text"><![CDATA[搭建zookeeper环境1234567891011docker pull zookeeperdocker run -d \ --restart=always \ -v /opt/docker/zookeeper/zoo1/data:/data \ -v /opt/docker/zookeeper/zoo1/datalog:/datalog \ -e ZOO_MY_ID=1 \ -e ZOO_SERVERS="server.1=zookeeper-A:2888:3888 server.2=zookeeper-B:2888:3888 server.3=zookeeper-C:2888:3888" \ --name=zookeeper-A \ --net=host \ --privileged \ zookeeper 指定了–net=host和–privileged选项，使得容器可以使用主机的ip地址和端口进行通信。 restart=always当Docker重启时，容器能自动启动 2181：对client端提供服务 3888：选举leader使用 2888：集群内机器通讯使用（Leader监听此端口） 创建kafka环境12docker pull wurstmeister/kafkadocker run -d --name kafka -p 9092:9092 --env KAFKA_ADVERTISED_HOST_NAME=localhost -e KAFKA_ZOOKEEPER_CONNECT=192.168.9.219:2181 -e KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://192.168.9.219:9092 -e KAFKA_LISTENERS=PLAINTEXT://0.0.0.0:9092 -e KAFKA_HEAP_OPTS="-Xmx256M -Xms128M" --net=host wurstmeister/kafka Kafka命令并创建topic 生产者 1234docker exec -it kafka bashcd /opt/kafka_2.11-2.0.0/bin/./kafka-topics.sh --create --zookeeper 192.168.1.43:2181 --replication-factor 1 --partitions 8 --topic test./kafka-console-producer.sh --broker-list localhost:9092 --topic test 创建kafka消费者消费消息 123docker exec -it kafka bashcd /opt/kafka_2.11-2.0.0/bin/./kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test --from-beginning 搭建kafka-manager 123docker pull sheepkiller/kafka-managerdocker run -it -d --rm -p 9000:9000 -e ZK_HOSTS="192.168.1.43:2181" --net=host sheepkiller/kafka-managerfirewall-cmd --add-port=9000/tcp 查看消息主题列表 1./kafka-topics.sh --list --zookeeper zookeeper:2181 test 查看指定topic信息 1./kafka-topics.sh --describe --zookeeper zookeeper:2181 --topic test]]></content>
      <categories>
        <category>架构</category>
      </categories>
      <tags>
        <tag>kafka</tag>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SQL-Server备份]]></title>
    <url>%2Fposts%2F9251%2F</url>
    <content type="text"><![CDATA[备份方案 SSIS（SQL Server Integration Services） 分区文件组等备份方案 备份策略 数据归档 数据压缩 后续处理 数据备份至ES或Solr集群 备份文件上传HDFS]]></content>
      <categories>
        <category>架构</category>
      </categories>
      <tags>
        <tag>SqlServer</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Log工具类打印调用者信息]]></title>
    <url>%2Fposts%2F38650%2F</url>
    <content type="text"><![CDATA[方法调用栈方法调用栈，在Java 中可以通过两种方法获取到方法调用栈的信息 (new Throwable()).getStackTrace() Thread.currentThread().getStackTrace() 这两种方式都能返回一个 StackTraceElement 数组，StackTraceElement 对象中包含了类名、方法名、文件名、代码行号这样的信息。 区别(new Throwable()).getStackTrace()调用native StackTraceElement getStackTraceElement(int index); Thread.currentThread().getStackTrace()调用return (new Exception()).getStackTrace(); 也就是说第一张方式比第二种少一个层级 获取上级调用者 (new Throwable()).getStackTrace()[1] Thread.currentThread().getStackTrace()[2] 示例1234567891011121314151617181920package com.okada.go;public class StackTraceDemo &#123; public static void main(String[] args) &#123; method(); &#125; private static void method() &#123; StackTraceElement[] stackTraceElements = (new Throwable()).getStackTrace(); for (int i = 0; i &lt; stackTraceElements.length; i++) &#123; StackTraceElement stackTraceElement = stackTraceElements[i]; System.out.println("index=" + i + "----------------------------------"); System.out.println("className=" + stackTraceElement.getClassName()); System.out.println("fileName=" + stackTraceElement.getFileName()); System.out.println("methodName=" + stackTraceElement.getMethodName()); System.out.println("lineNumber=" + stackTraceElement.getLineNumber()); &#125; &#125;&#125;]]></content>
      <categories>
        <category>架构</category>
      </categories>
      <tags>
        <tag>log</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Protobuf和JSON]]></title>
    <url>%2Fposts%2F3676%2F</url>
    <content type="text"><![CDATA[ProtobufProtobuf是用于允许对结构化数据进行序列化和反序列化。Google开发它的目的是提供一种比XML更好的方法来使系统进行通信。因此，他们专注于使其比XML更简单，更小，更快和更可维护，甚至以更好的性能，更好的可维护性和更小的大小超过了JSON。 Protobuf具有三个主要组件： 消息描述符。使用Protobuf时，我们必须在.proto文件中定义消息结构。 消息实现。消息定义不足以用任何编程语言表示和交换数据。我们必须生成类/对象来处理所选编程语言中的数据。幸运的是，Google为最常见的编程语言提供了代码生成器。 解析和序列化。定义和创建Protobuf消息后，我们需要能够交换这些消息。只要我们使用一种受支持的编程语言， 与JSON有何不同尽管JSON和Protobuf消息可以互换使用，但是这些技术的设计目的不同。 JSON（JavaScript对象表示法）的简称，它只是一种消息格式，源于JavaScript编程语言的子集。 JSON消息以文本格式交换，如今，它们是完全独立的，并且几乎受所有编程语言的支持。 Protobuf不仅是消息格式，还是定义和交换这些消息的一组规则和工具。 该协议的创建者Google已使其成为开源软件，并提供了工具来为诸如JavaScript，Java，PHP，C＃，Ruby，Objective C，Python，C ++和Go之类的最常用的编程语言生成代码。 除此之外，Protobuf具有比JSON更多的数据类型，例如枚举和方法，并且也大量用于RPC（远程过程调用）上。 缺点 缺乏资源。有关Protobuf的使用和开发的资源少。 较小的社区。可能是第一个劣势的根本原因。例如，在Stack Overflow上，会发现大约1.500个带有Protobuf标签的问题。JSON在同一平台上有18万多个问题。 缺乏支持。Google不提供对其他编程语言（如Swift，R，Scala等）的支持。但是，有时，您可以使用第三方库（如Apple提供的Swift Protobuf）克服此问题。 非人类可读性。JSON以文本格式交换并且具有简单的结构，很容易被人阅读和分析。二进制格式不是这种情况。 优点 正式格式。格式是自描述的。 RPC支持。服务器RPC接口可以声明为协议文件的一部分。 结构验证。与JSON相比，具有预定义且更大的数据类型集，可以通过负责交换它们的代码自动验证在Protobuf上序列化的消息 性能Protobuf是Google创建的一种二进制格式，用于序列化不同服务之间的数据。Google将该协议开源，现在它提供了对大多数常用语言（如JavaScript，Java，C＃，Ruby和其他语言）的支持。测试中，证明该协议的执行速度比JSON快6倍。 Protobuf/JSON性能及压缩比较 Java通信如果仅使用JavaScript环境（例如Node.js应用程序和Web浏览器）作为接口，那么在花时间学习和将端点迁移到Protobuf之前，会三思而后行。但是，当开始添加其他平台（例如Java，Android，Python等）时，将开始看到使用Protobuf的真正好处 当拥有不是JSON原生部分的环境时，性能将得到极大改善。因此，每当遇到JSON的某些延迟问题时，请考虑迁移到Protobuf。 用Java解析和序列化123protobuf-javaprotobuf-java-utilprotobuf-java-format 使用JavaScript进行解析和序列化使用的库protobuf.js帮助我将.proto消息编译为JavaScript并交换了这些消息。我要做的第一件事是将其安装为依赖项。]]></content>
      <categories>
        <category>架构</category>
      </categories>
      <tags>
        <tag>protobuf</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Canal及MQ顺序性]]></title>
    <url>%2Fposts%2F47529%2F</url>
    <content type="text"><![CDATA[顺序性Binlog本身是有序的，写入到mq之后需要保障顺序。 方案Canal目前选择支持Kafka/Rocketmq，本质上都是基于本地文件的方式来支持了分区级的顺序消息的能力。 也就是Binlog写入mq是可以有一些顺序性保障，这个取决于用户的一些参数选择。 Canal支持MQ数据的几种路由方式： 单topic单分区，可以严格保证与binlog相同的顺序，但效率比较低，TPS只有2~3K。 多topic单分区，由于是按照表划分topic，因此可以保证表级别的有序性，但是每个表的热度不一样，对于热点表仍然会有性能问题。 单/多topic多分区，按照给定的hash方法来划分partition，性能无疑是最好的。但必须要多加小心，每个表的hash依据都必须是其主键或者主键组。只有保证每表每主键binlog的顺序性，才能准确恢复变动数据。 多线程消费为了保证一个消费者中多个线程去处理时，不会使得消息的顺序被打乱，则可以在消费者中，消息分发至不同的线程时，加一个队列，消费者去做hash分发，将需要放在一起的数据，分发至同一个队列中，最后多个线程从队列中取数据。 生产指定分区DefaultPartitioner默认的分区策略 如果key为null 则先根据topic名获取上次计算分区时使用的一个整数并加一。然后判断topic的可用分区数是否大于0，如果大于0则使用获取的nextValue的值和可用分区数进行取模操作。 如果topic的可用分区数小于等于0，则用获取的nextValue的值和总分区数进行取模操作（其实就是随机选择了一个不可用分区）。 但是消息的key不为空，则基于key的哈希值来选择一个分区。 如果既没有指定分区，且消息的key也是空，则用轮询的方式选择一个分区。 如果在发消息的时候指定了分区，则消息投递到指定的分区。 自定义分区策略 1props.put(ProducerConfig.PARTITIONER_CLASS_CONFIG, CustomPartition.class.getName()); 123456789101112131415161718192021222324public static class CustomPartition implements Partitioner &#123; @Override public int partition(String s, Object o, byte[] bytes, Object o1, byte[] bytes1, Cluster cluster) &#123; if (null == o) &#123; return 0; &#125; long id = getPartitionByKey(String.valueOf(o)); return (int) id; &#125; private long getPartitionByKey(String key) &#123; long id = key.hashCode(); // key取模 int partition = (int) (id &amp; (BusConfig.partitionNum - 1)); return Math.abs(partition); &#125; @Override public void close() &#123; &#125; @Override public void configure(Map&lt;String, ?&gt; map)&#123; &#125;&#125;]]></content>
      <categories>
        <category>架构</category>
      </categories>
      <tags>
        <tag>Canal</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[散列算法]]></title>
    <url>%2Fposts%2F64783%2F</url>
    <content type="text"><![CDATA[何为散列散列（Hash）也称为哈希，就是把任意长度的输入，通过散列算法，变换成固定长度的输出，这个输出值就是散列值。 散列算法的宗旨就是：构造冲突较低的散列地址，保证散列表中数据的离散度。 除法散列法散列长度 m, 对于一个小于 m 的数 p 取模，所得结果为散列地址。对 p 的选择很重要，一般取素数或 m 公式：f(k) = k % p （p&lt;=m） 因为求模数其实是通过一个除法运算得到的，所以叫“除法散列法” 先通过求关键字的平方值扩大相近数的差别，然后根据表长度取中间的几位数作为散列函数值。又因为一个乘积的中间几位数和乘数的每一位都相关，所以由此产生的散列地址较为均匀。 公式：f(k) = ((k * k) &gt;&gt; X) &lt;&lt; Y对于常见的32位整数而言，也就是 f(k) = (k * k) &gt;&gt; 28 平方散列法（平方取中法）先通过求关键字的平方值扩大相近数的差别，然后根据表长度取中间的几位数作为散列函数值。又因为一个乘积的中间几位数和乘数的每一位都相关，所以由此产生的散列地址较为均匀。 公式：f(k) = ((k * k) &gt;&gt; X) &lt;&lt; Y对于常见的32位整数而言，也就是 f(k) = (k * k) &gt;&gt; 28 斐波那契（Fibonacci）散列法和平方散列法类似，此种方法使用斐波那契数列的值作为乘数而不是自己。 对于 16 位整数而言，这个乘数是 40503。对于 32 位整数而言，这个乘数是 2654435769。对于 64 位整数而言，这个乘数是 11400714819323198485。 公式：f(k) = ((k * 2654435769) &gt;&gt; X) &lt;&lt; Y对于常见的32位整数而言，也就是 f(k) = (k * 2654435769) &gt;&gt; 28 可以发现 0x61c88647 与一个神奇的数字产生了关系，它就是 (Math.sqrt(5) - 1)/2。也就是传说中的黄金比例 0.618（0.618 只是一个粗略值），即0x61c88647 = 2^32 * 黄金分割比。同时也对应上了上文所提到的斐波那契散列法。 随机数法选择一随机函数，取关键字的随机值作为散列地址，通常用于关键字长度不同的场合。 公式：f(k) = random(k) 链地址法（拉链法）懂了散列算法，我们再来了解下拉链法。拉链法是为了 HashMap 中降低冲突，除了拉链法，还可以使用开放寻址法、再散列法、链地址法、公共溢出区等方法。这里就只简单介绍了拉链法。 把具有相同散列地址的关键字(同义词)值放在同一个单链表中，称为同义词链表。有 m 个散列地址就有 m 个链表，同时用指针数组 T[0..m-1] 存放各个链表的头指针，凡是散列地址为 i 的记录都以结点方式插入到以 T[i] 为指针的单链表中。T 中各分量的初值应为空指针。]]></content>
      <categories>
        <category>工具利器</category>
      </categories>
      <tags>
        <tag>散列</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Kafka消费配置]]></title>
    <url>%2Fposts%2F39128%2F</url>
    <content type="text"><![CDATA[offset在Kafka中无论是producer往topic中写数据,还是consumer从topic中读数据,都避免不了和offset打交道,关于offset主要有以下几个概念。 Last Committed Offset consumer group最新一次 commit 的 offset，表示这个 group 已经把 Last Committed Offset 之前的数据都消费成功了。 Current Position consumer group 当前消费数据的 offset，也就是说，Last Committed Offset 到 Current Position 之间的数据已经拉取成功，可能正在处理，但是还未 commit。 Log End Offset(LEO) 记录底层日志(log)中的下一条消息的 offset。,对producer来说，就是即将插入下一条消息的offset。 High Watermark(HW) 已经成功备份到其他 replicas 中的最新一条数据的 offset，也就是说 Log End Offset 与 High Watermark 之间的数据已经写入到该 partition 的 leader 中，但是还未完全备份到其他的 replicas 中，consumer是无法消费这部分消息(未提交消息)。 消费 每个consumer都要维护一个独立的TCP连接，如果分区数和创建consumer线程的数量过多，会造成不小系统开销。但是如果处理消息足够快速，消费性能也会提升,如果慢的话就会导致消费性能降低。 采用一个consumer，多个消息处理线程来处理消息，其实在生产中，瓶颈一般是集中在消息处理上的(可能会插入数据到数据库，或者请求第三方API)，所以我们采用多个线程来处理这些消息。 订阅/取消主题订阅： 使用subscribe()方法订阅主题 使用assign()方法订阅确定主题和分区区别：通过subscribe()方法订阅主题具有消费者自动再均衡(reblance)的功能，存在多个消费者的情况下可以根据分区分配策略来自动分配各个消费者与分区的关系。当组内的消费者增加或者减少时，分区关系会自动调整。实现消费负载均衡以及故障自动转移。使用assign()方法订阅则不具有该功能。 消费配置消费者必须的属性有4个。 group.id。Consummer中有一个Consumer group(消费组)，由它来决定同一个Consumer group中的消费者具体拉取哪个partition的数据,所以这里必须指定group.id属性。同一个group只能消费1次。 bootstrap.servers。连接Kafka集群的地址，多个地址以逗号分隔 key.deserializer。消息中key反序列化类,需要和Producer中key序列化类相对应。 value.deserializer。消息中value的反序列化类,需要和Producer中Value序列化类相对应。 消费涉及到了2个offset，一个是current position,一个是处理完毕向服务器确认的committed offset。 提交策略Kafka提供了3种提交offset的方式。 自动提交 1234// 自动提交,默认trueprops.put("enable.auto.commit", "true");// 设置自动每1s提交一次props.put("auto.commit.interval.ms", "1000"); 手动同步提交offset 1consumer.commitSync(); 手动异步提交offset 1consumer.commitAsync(); 重复消费异步提交offset和同步提交都存在重复消费问题。 异步模式下committed offset是落后于current position的。如果consumer挂掉了,那么下一次消费数据又只会从committed offset的位置拉取数据，就会导致数据被重复消费。 同步操作存在原子操作问题。例如insertIntoDB和commitSync()做不到原子操作；如果insertIntoDB()成功了，但是提交offset的时候consumer挂掉了，然后服务器重启，仍然会导致重复消费问题。 是否需要做到不重复消费？只要保证处理消息和提交offset得操作是原子操作，就可以做到不重复消费。我们可以自己管理committed offset,而不让kafka来进行管理。 如果消费的数据刚好需要存储在数据库，那么可以把offset也存在数据库，就可以就可以在一个事务中提交这两个结果，保证原子操作。 借助搜索引擎，把offset和数据一起放到索引里面，比如Elasticsearch。 每条记录都有自己的offset,所以如果要管理自己的offset还得要做下面事情： 设置enable.auto.commit=false 使用每个ConsumerRecord提供的offset来保存消费的位置 在重新启动时使用seek(TopicPartition, long)恢复上次消费的位置 通过上面的方式就可以在消费端实现”Exactly Once”的语义,即保证只消费一次。 但是是否真的需要保证不重复消费呢？这个得看具体业务,重复消费数据对整体有什么影响在来决定是否需要做到不重复消费。 再均衡(reblance)Kafka数据使用多线程阻塞的方式进行消费，即每个线程通过poll()的形式消费一个或者多个partition， 每次得到的消息集处理完成之后才会继续进行下一次poll()操作，同时使用了自动提交offset的模式。 Rebalance发生的原因有可能是集群的问题，但大部分都在客户端，一旦服务端在设定的超时时间内没有收到消费者发起的心跳，则认为这个消费者已经死掉，就会执行Rebalance动作。 Rebalance对数据的影响主要有以下几点： 数据重复消费: 消费过的数据由于提交offset任务也会失败，在partition被分配给其他消费者的时候，会造成重复消费，数据重复且增加集群压力 Rebalance扩散到整个ConsumerGroup的所有消费者，因为一个消费者的退出，导致整个Group进行了Rebalance，并在一个比较慢的时间内达到稳定状态，影响面较大 频繁的Rebalance反而降低了消息的消费速度，大部分时间都在重复消费和Rebalance 数据不能及时消费，会消息堆积即消费滞后(Lag)，在Kafka的TTL之后会丢弃数据 为了更精确的控制消息的消费，我们可以在订阅主题的时候，通过指定监听器的方式来设定发生再均衡动作前后的一些准备或者收尾的动作。 1234567891011consumer.subscribe(Collections.singletonList("test3"), new ConsumerRebalanceListener() &#123; @Override public void onPartitionsAssigned(Collection&lt;TopicPartition&gt; partitions) &#123; //再均衡之前和消费者停止读取消息之后被调用 &#125; @Override public void onPartitionsRevoked(Collection&lt;TopicPartition&gt; partitions) &#123; //重新分配分区之后和消费者开始消费之前被调用 &#125;&#125;); 其中采用了 N consumer thread + N Event Handler的方式来消费数据,并采用自动提交offset。对于无法消费的数据往往只是简单处理下，打印下日志以及消息体(无法消费的情况非常非常少)。 配置 fetch.min.bytes配置poll()拉取请求过程种能从Kafka拉取的最小数据量，如果可用数据量小于它指定的大小会等到有足够可用数据时才会返回给消费者，其默认值时1B fetch.max.wait.ms和fetch.min.bytes有关,用于指定Kafka的等待时间，默认时间500ms。 如果fetch.min.bytes设置为1MB,fetch.max.wait.ms设置为100ms,Kafka收到消费者请求后,要么返回1MB数据,要么在100ms后返回所有可用数据,就看哪个提交得到满足。 max.poll.records用于控制单次调用poll()能返回的最大记录数量，默认为500条数据 partition.assignment.stragety分区会被分配给群组的消费者,这个参数用于指定分区分配策略。默认是RangeAssignore,可选的还有RoundRobinAssignor。同样它还支持自定义。 注意：KafkaConsumer是非线程安全的类，当使用多个线程操作同一个KafkaConsumer对象时就会引起KafkaConsumer is not safe for multi-threaded access错误。]]></content>
      <categories>
        <category>架构</category>
      </categories>
      <tags>
        <tag>kafka</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Consumer手动提交Kafka偏移量和Rebalance]]></title>
    <url>%2Fposts%2F32177%2F</url>
    <content type="text"><![CDATA[再均衡是指分区的所属权从一个消费者转移到另一个消费者的行为，再均衡期间，消费组内的消费组无法读取消息。 消费者需要自己保留一个offset，从kafka 获取消息时，只拉去当前offset以后的消息。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167@Slf4jpublic class DemoConsumer extends Thread &#123; private final KafkaConsumer&lt;String, byte[]&gt; consumer; private final String topic; /** * 已消费最大offset */ final Map&lt;TopicPartition, OffsetAndMetadata&gt; offsetAndMetadataMap = new ConcurrentHashMap&lt;&gt;(); /** * 初始化 * * @param topic */ public DemoConsumer(String topic) &#123; Properties props = new Properties(); props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, BusConfig.servers.get(0)); props.put(ConsumerConfig.GROUP_ID_CONFIG, BusConfig.group); //自动提交 props.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, BusConfig.autoCommit); //自动提交时间间隔 props.put(ConsumerConfig.AUTO_COMMIT_INTERVAL_MS_CONFIG, "1000"); //coordinator检测失败的时间，1分钟 props.put(ConsumerConfig.SESSION_TIMEOUT_MS_CONFIG, "60000"); //每次poll总消费时长，3分钟 props.put(ConsumerConfig.MAX_POLL_INTERVAL_MS_CONFIG, "300000"); //心跳 props.put(ConsumerConfig.HEARTBEAT_INTERVAL_MS_CONFIG, "5000"); //最大10k props.put(ConsumerConfig.FETCH_MAX_BYTES_CONFIG, "10240"); //每次最大拉取数量 props.put(ConsumerConfig.MAX_POLL_RECORDS_CONFIG, "20"); props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName()); props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, ByteArrayDeserializer.class.getName()); this.topic = topic; consumer = new KafkaConsumer&lt;&gt;(props); &#125; public ConsumerRebalanceListener listen() &#123; return new ConsumerRebalanceListener() &#123; @Override public void onPartitionsAssigned(Collection&lt;TopicPartition&gt; partitions) &#123; //重新分配分区之后和消费者开始读取消息之前被调用，获取最新的偏移量，设置拉取分量 log.warn("kafka rebalance onPartitionsAssigned"); for (TopicPartition partition : partitions) &#123; //获取消费偏移量，实现原理是向协调者发送获取请求 OffsetAndMetadata offset = consumer.committed(partition); log.warn("kafka rebalance offset:" + offset.offset()); //设置本地拉取分量，下次拉取消息以这个偏移量为准 consumer.seek(partition, offset.offset()); &#125; &#125; @Override public void onPartitionsRevoked(Collection&lt;TopicPartition&gt; partitions) &#123; //在再均衡开始之前和消费者停止读取消息之后被调用,提交偏移量 log.warn("kafka rebalance onPartitionsRevoked"); commit(); &#125; &#125;; &#125; /** * commit */ private void commit() &#123; // 尽量降低synchronized块对offsets锁定的时间 Map&lt;TopicPartition, OffsetAndMetadata&gt; unmodfiedMap; synchronized (offsetAndMetadataMap) &#123; if (offsetAndMetadataMap.isEmpty()) &#123; return; &#125; unmodfiedMap = Collections.unmodifiableMap(new HashMap&lt;&gt;(offsetAndMetadataMap)); unmodfiedMap.forEach((k, v) -&gt; log.info("commit last offset:" + v.offset())); offsetAndMetadataMap.clear(); &#125; consumer.commitSync(unmodfiedMap); &#125; /** * 消费 */ @Override public void run() &#123; //订阅且监听rebalance consumer.subscribe(Collections.singletonList(this.topic), listen()); //检查线程中断标志是否设置, 如果设置则表示外界想要停止该任务,终止该任务 while (!Thread.currentThread().isInterrupted()) &#123; //提交 commit(); //如果关闭 if (!BusConfig.enable) &#123; try &#123; TimeUnit.SECONDS.sleep(5); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; continue; &#125; //开启 ConsumerRecords&lt;String, byte[]&gt; records = consumer.poll(Duration.ofSeconds(1)); if (records != null &amp;&amp; records.count() &gt; 0) &#123; log.info("consume message,size:&#123;&#125;", records.count()); records.forEach(this::handle); &#125; //控制并发 try &#123; TimeUnit.SECONDS.sleep(1); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; /** * 异步处理 * * @param record */ public void handle(ConsumerRecord&lt;String, byte[]&gt; record) &#123; Runnable runnable = () -&gt; &#123; Message message = null; try &#123; message = Message.parseFrom(record.value()); if (message == null) &#123; return; &#125; BusConfig.businessHandler.handle(message); &#125; catch (Exception e) &#123; e.printStackTrace(); log.error("consume handle error:" + message.toString()); &#125; log.info("consume messageId:&#123;&#125;,offset:&#123;&#125;", record.key(), record.offset()); TopicPartition topicPartition = new TopicPartition(topic, record.partition()); synchronized (offsetAndMetadataMap) &#123; //下一条需要读的偏移量 long lastOffset = record.offset() + 1; if (!offsetAndMetadataMap.containsKey(topicPartition)) &#123; offsetAndMetadataMap.put(topicPartition, new OffsetAndMetadata(lastOffset)); &#125; else if (offsetAndMetadataMap.get(topicPartition).offset() &lt; lastOffset) &#123; offsetAndMetadataMap.put(topicPartition, new OffsetAndMetadata(lastOffset)); &#125; &#125; &#125;; TaskThreadPool.getInstance().execute(runnable); &#125; /** * 关闭 */ public void close() &#123; BusConfig.enable = false; consumer.wakeup(); &#125;&#125;]]></content>
      <categories>
        <category>架构</category>
      </categories>
      <tags>
        <tag>kafka</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[二进制按位与&及求余数]]></title>
    <url>%2Fposts%2F19120%2F</url>
    <content type="text"><![CDATA[按位与&amp;移位运算规则：0&amp;0=0; 0&amp;1=0; 1&amp;0=0; 1&amp;1=1; 在移位运算中我们可知，计算机中的数据都是0和1的序列，当我们把某个数字左移一位，该数字会扩大为原来的2倍；而将其右移一位时，该数字就会缩小为原来的1/2，即相当于对该数字做了一次被2整除的运算。 举例说明： 11的二进制是1011，如果右移一位的话，将变成0101，也就是5。 现在我们考虑11除以8的余数，很显然是3；因为8是2的3次幂，求余时相当于除以2的3次幂，也就是把1011右移3位，该过程会把1011的低3位011给移走，事实上，这个被移走的011就是11除以8的余数！ 取余但是，我们该如何把这个011给保存下来呢？ 现在的问题就转化为如何保存11的二进制1011的低三位数字了——这时就是按位与运算出马的时候了！ 和1做与运算会保存原来的数字，所以我们就可以用1011&amp;0111来计算。 那么这个0111又是如何得到的呢？ 有两种方法，第一种是2^N-1，比如8按照此公式就得出了0111；第二种是8的二进制取反，即1000取反得到0111。 综上所述，位运算求余一定要注意，只适合于除数是2的N次方的情况。其原理就是：对2的N次方求余，就预示着数字将向右移N位；这被右移的N位，就是余数！只要我们再用与运算将这N位保存下来即可！ 应用设X对Y求余，Y等于2^N，公式为：X &amp; (2^N - 1)或X&amp;(~Y)。 例如：14%8，取余数，相当于取出低位，而余数最大为7，14二进制为1110，8的二进制1000，8-1 = 7的二进制为0111，由于现在低位全为1，让其跟14做&amp;运算，正好取出的是其低位上的余数。 1110&amp;0111=110即6=14%8；（此公式只适用b=2n，是因为可以保证b始终只有最高位为1，其他二进制位全部为0，减去1，之后，可以把高位1消除，其他位都为1，而与1做&amp;运算，会保留原来的数。） 因此，按位与&amp;操作是指对两操作数进行按位与运算，其中两位都为1结果为1，其他情况为0。按位与是二目运算符。 实际上相当于h%length取余数，但&amp;计算速度更快。 由于我们知道位运算比较高效，在某些情况下，当b为2的n次方时，有如下替换公式：a % b = a &amp; (b-1)(b=2n)即：a % 2n = a &amp; (2n-1)]]></content>
      <categories>
        <category>工具利器</category>
      </categories>
      <tags>
        <tag>按位与</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Snowflake根据设备生成15位ID]]></title>
    <url>%2Fposts%2F19968%2F</url>
    <content type="text"><![CDATA[Snowflakesnowflake是Twitter开源的分布式ID生成算法，结果是一个long型的ID。 其核心思想是，生成64位即一个long类型的递增序列Id，保障有序及不重复，具体如下： 使用41bit作为毫秒数， 10bit作为机器的ID，5个bit是数据中心，5个bit的机器ID 12bit作为毫秒内的流水号，意味着每个节点在每毫秒可以产生 4096个ID 最后还有一个符号位，永远是0 规则64位=符号位（1bit）+ 时间戳相对值（41bit）+ 数据标志（5bit）+ 机器标志（5bit）+ 递增序号（12bit） 0 - 0000000000 0000000000 0000000000 0000000000 0 - 00000 - 00000 - 000000000000 Id位数长度正数Long类型长度为最多19位,因此结果长度在1到19位之间,最小是0,最大9,223,372,036,854,775,807。 一般为18位，但时间超过一定值后，会变为19位。 消耗完18位所需的时间：1*10^18 / (3600 * 24 * 365 * 1000 * 2^22) ≈ 7.56年，即时间差超过7.56年，就会达到19位。 比如以2010年1月1日为epoch，则差不多到2017年中就19位了。 关于长度，可以通过数字2进制转10进制的长度比。一个用2进制表示的数字是用10进制表示长度的3.3倍。 正整数n，用10进制表示的长度为：a=⌊log10n⌋+1a=⌊log10⁡n⌋+1而用2进制表示为：b=⌊log2n⌋+1b=⌊log2⁡n⌋+1所以比值：c=limn→∞ab=limn→∞⌊log10n⌋⌊log2n⌋=log210≈3.32 假设生成长度为15位，则需要字节长度为53。 根据设备生成15位Id123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184public class SnowFlakeGenerator &#123; /** * 长度15 */ private static final int TOTAL_BITS = 53; /** * 毫秒级时间戳，可以用(2^41-1)/(1000*60*60*24*365)=69.7年，即2015+69.7=2084年 */ private static final int EPOCH_BITS = 41; /** * 最大31台，0-31一共32台 */ private static final int NODE_ID_BITS = 5; /** * 每毫秒自增最大127，0-127，一共128个 */ private static final int SEQUENCE_BITS = 7; /** * 最大节点 * 移位算法可以很快的计算出几位二进制数所能表示的最大十进制数 */ private static final int maxNodeId = (int) (~(-1L &lt;&lt; NODE_ID_BITS)); /** * 最大自增数 */ private static final int maxSequence = (int) (~(-1L &lt;&lt; SEQUENCE_BITS)); /** * 偏移量，增大可用时间大概2015-1970=45年 * 开始时间，2015-01-01T00:00:00Z */ private static final long CUSTOM_EPOCH = 1420070400000L; /** * 当前节点 */ private volatile int nodeId; /** * 最后时间戳 */ private volatile long lastTimestamp = -1L; /** * 当前id，每次均+1 */ private volatile int sequence = 0; /** * 时间戳左移，空出节点和序列号位 */ private int EPOCH_SHIFT = TOTAL_BITS - EPOCH_BITS; /** * 节点位左移，空出序列号位 */ private int NODE_ID_SHIFT = TOTAL_BITS - EPOCH_BITS - NODE_ID_BITS; /** * 主动设置节点 * * @param nodeId */ public SnowFlakeGenerator(int nodeId) &#123; if (nodeId &lt; 0 || nodeId &gt; maxNodeId) &#123; throw new IllegalArgumentException(String.format("NodeId must be between %d and %d", 0, maxNodeId)); &#125; this.nodeId = nodeId; &#125; /** * 生成节点默认id */ public SnowFlakeGenerator() &#123; this.nodeId = createNodeId(); &#125; /** * 获取下一个id * * @return */ public synchronized long nextId() &#123; //当前时间戳 long currentTimestamp = timestamp(); //出现时间回拨 if (currentTimestamp &lt; lastTimestamp) &#123; //换个节点 nodeId = createNodeId(true); &#125; //当前轮 if (currentTimestamp == lastTimestamp) &#123; sequence = (sequence + 1) &amp; maxSequence; if (sequence == 0) &#123; //id用完，等下一毫秒 currentTimestamp = waitNextMillis(currentTimestamp); &#125; &#125; else &#123; //每轮开始 sequence = 0; &#125; lastTimestamp = currentTimestamp; //时间戳左移8位，即乘以2的8次方 long id = currentTimestamp &lt;&lt; EPOCH_SHIFT; //节点id左移3位，或运算拼id到一起 id |= nodeId &lt;&lt; NODE_ID_SHIFT; //或运算拼id到一起 id |= sequence; //41bits|5bits|7bits return id; &#125; /** * 获取秒 * * @return */ private static long timestamp() &#123; return Instant.now().toEpochMilli() - CUSTOM_EPOCH; &#125; private int createNodeId() &#123; return createNodeId(false); &#125; /** * 根据设备地址生成节点 * * @return */ private int createNodeId(boolean random) &#123; int nodeId; try &#123; if (random) &#123; nodeId = (new SecureRandom().nextInt()); &#125; else &#123; StringBuilder sb = new StringBuilder(); Enumeration&lt;NetworkInterface&gt; networkInterfaces = NetworkInterface.getNetworkInterfaces(); while (networkInterfaces.hasMoreElements()) &#123; NetworkInterface networkInterface = networkInterfaces.nextElement(); byte[] mac = networkInterface.getHardwareAddress(); if (mac != null) &#123; for (int i = 0; i &lt; mac.length; i++) &#123; sb.append(String.format("%02X", mac[i])); &#125; &#125; &#125; //hash nodeId = sb.toString().hashCode(); &#125; &#125; catch (Exception ex) &#123; nodeId = (new SecureRandom().nextInt()); &#125; //取余 nodeId = nodeId &amp; maxNodeId; if (nodeId == this.nodeId) &#123; //重新随机 nodeId = createNodeId(true); &#125; return nodeId; &#125; /** * 等一毫秒 * * @param currentTimestamp * @return */ private long waitNextMillis(long currentTimestamp) &#123; while (currentTimestamp == lastTimestamp) &#123; currentTimestamp = timestamp(); &#125; return currentTimestamp; &#125; public static void main(String[] args) &#123; SnowFlakeGenerator snowFlakeGenerator = new SnowFlakeGenerator(); System.out.println(snowFlakeGenerator.nextId()); &#125;&#125; 用位运算计算n个bit能表示的最大数值1long maxNodeId = (int) (~(-1L &lt;&lt; 5)); 所以上面那行代码中，运行顺序是： 12-1 左移 5，得结果a-1 异或 a 二进制运算过程如下： 12345-1 左移 5，得结果a ： 11111111 11111111 11111111 11111111 //-1的二进制表示（补码） 11111 11111111 11111111 11111111 11100000 //高位溢出的不要，低位补0 11111111 11111111 11111111 11100000 //结果a 123456-1 异或 a ： 11111111 11111111 11111111 11111111 //-1的二进制表示（补码） ^ 11111111 11111111 11111111 11100000 //两个操作数的位中，相同则为0，不同则为1--------------------------------------------------------------------------- 00000000 00000000 00000000 00011111 //最终结果31 最终结果是31，二进制00000000 00000000 00000000 00011111转十进制可以这么算：24+23+22+21+20=16+8+4+2+1=31-1L ^ (-1L &lt;&lt; 5L)结果是31，$2^{5}-1$的结果也是31，所以在代码中，-1L ^ (-1L &lt;&lt; 5L)的写法是利用位运算计算出5位能表示的最大正整数是多少 防止溢出1sequence = (sequence + 1) &amp; maxSequence 这段代码通过位与运算保证计算的结果范围始在0-maxSequence，其实就是取余操作。 用位运算汇总结果|或运算符，也是一个位运算符。 其含义是：x的第n位和y的第n位，只要有一个是1，则结果的第n位也为1，否则为0。 正因为左移的操作，使四个不同的值移到了SnowFlake理论上相应的位置，然后做位或运算（只要有1结果就是1），就把几段的二进制数合并成一个二进制数。 最后转换成10进制，就是最终生成的id。]]></content>
      <categories>
        <category>工具利器</category>
      </categories>
      <tags>
        <tag>Snowflake</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git操作]]></title>
    <url>%2Fposts%2F53101%2F</url>
    <content type="text"><![CDATA[分支创建分支git branch &lt;branch-name&gt;如git branch testing 切换分支从当前所处的分支切换到其他分支git checkout &lt;branch-name&gt;如git checkout testing； 新建并切换新建并切换到新建分支上git checkout -b &lt;branch-name&gt; 分支合并将当前分支与指定分支进行合并git merge &lt;branch-name&gt; 显示本地仓库的所有分支git branch 分支历史查看各个分支最后一个提交对象的信息git branch -v 标签标签信息列出现在所有的标签git tag 查看相应标签的版本信息，并连同显示打标签时的提交对象git show v1.4 创建标签创建一个含附注类型的标签，需要加-a参数git tag -a v1.4 -m &quot;my version 1.4&quot; 将标签推送到远程仓库中git push origin如git push origin v1.5 上传已有仓库1234567cd existing_git_repogit remote add origin git@xx.gitgit push -u origin mastergit push --all origin 如果当前分支与多个主机存在追踪关系，那么这个时候-u选项会指定一个默认主机，这样后面就可以不加任何参数使用git push。 如果当前分支与多个主机存在追踪关系，那么这个时候-u选项会指定一个默认主机，这样后面就可以不加任何参数使用git push。 添加多个远程仓库1234567git remote -vgit remote set-url --add origin git@xx.com:xx.gitgit remote -vgit push --all 查看存储库中的大文件git rev-list –objects –all | grep -E git verify-pack -v .git/objects/pack/*.idx | sort -k 3 -n | tail -10 | awk &#39;{print$1}&#39; | sed &#39;:a;N;$!ba;s/\n/|/g&#39;]]></content>
      <categories>
        <category>工具利器</category>
      </categories>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Canal日志增量订阅和消费]]></title>
    <url>%2Fposts%2F53545%2F</url>
    <content type="text"><![CDATA[基于日志增量订阅和消费的业务 数据库镜像 数据库实时备份 索引构建和实时维护(拆分异构索引、倒排索引等) 业务 cache 刷新 带业务逻辑的增量数据处理 MySQL主备复制原理 MySQL master 将数据变更写入二进制日志( binary log, 其中记录叫做二进制日志事件binary log events，可以通过 show binlog events 进行查看) MySQL slave 将 master 的 binary log events 拷贝到它的中继日志(relay log) MySQL slave 重放 relay log 中事件，将数据变更反映它自己的数据 binlogmysql的binlog是多文件存储，定位一个LogEvent需要通过binlog filename + binlog position，进行定位 mysql的binlog数据格式，按照生成的方式，主要分为：statement-based、row-based、mixed。 1234567mysql&gt; show variables like 'binlog_format';+---------------+-------+| Variable_name | Value |+---------------+-------+| binlog_format | ROW |+---------------+-------+1 row in set (0.00 sec) 目前canal支持所有模式的增量订阅(但配合同步时，因为statement只有sql，没有数据，无法获取原始的变更日志，所以一般建议为ROW模式) canal 工作原理 canal 模拟 MySQL slave 的交互协议，伪装自己为 MySQL slave ，向 MySQL master 发送dump 协议 MySQL master 收到 dump 请求，开始推送 binary log 给 slave (即 canal ) canal 解析 binary log 对象(原始为 byte 流) 架构说明： server代表一个canal运行实例，对应于一个jvm instance对应于一个数据队列 （1个server对应1..n个instance) instance模块： eventParser (数据源接入，模拟slave协议和master进行交互，协议解析) eventSink (Parser和Store链接器，进行数据过滤，加工，分发的工作) eventStore (数据存储) metaManager (增量订阅&amp;消费信息管理器) canal-adminv1.1.4+，引入canal-admin工程，支持面向WebUI的canal管理能力 get/ack/rollback协议介绍 Message getWithoutAck(int batchSize)，允许指定batchSize，一次可以获取多条，每次返回的对象为Message，包含的内容为：a. batch id 唯一标识b. entries 具体的数据对象，对应的数据对象格式：EntryProtocol.proto void rollback(long batchId)，顾命思议，回滚上次的get请求，重新获取数据。基于get获取的batchId进行提交，避免误操作 void ack(long batchId)，顾命思议，确认已经消费成功，通知server删除数据。基于get获取的batchId进行提交，避免误操作 关键配置服务配置canal.properties 12//实例名称canal.destinations = example 实例配置instance.properties 12345678//mysql地址canal.instance.master.address=192.168.x.x:3306//数据库名canal.instance.dbUsername=x//数据库密码canal.instance.dbPassword=x//监听的schema筛选canal.instance.filter.regex=x.* 关键代码12345&lt;dependency&gt; &lt;groupId&gt;com.alibaba.otter&lt;/groupId&gt; &lt;artifactId&gt;canal.client&lt;/artifactId&gt; &lt;version&gt;1.1.4&lt;/version&gt;&lt;/dependency&gt; 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859 //获取地址 public List&lt;InetSocketAddress&gt; getAddress() &#123; return BinlogConfig.ips.stream() .map(e -&gt; &#123; String[] ip = e.split(":"); return new InetSocketAddress(ip[0], Integer.parseInt(ip[1])); &#125;) .collect(Collectors.toList()); &#125; //创建连接 private boolean createConnector() &#123; log.info("create connector ..."); connector = CanalConnectors.newClusterConnector(getAddress(), BinlogConfig.destination, BinlogConfig.username, BinlogConfig.password); log.info("create connector success"); return true; &#125; //连接 private boolean connect() &#123; log.info("connect ..."); connector.connect(); connector.subscribe(); log.info("connect success"); return true; &#125; //处理过程 public void process() &#123; while (BinlogConfig.running) &#123; log.info("processing ..."); // 获取指定数量的数据 Message message = connector.get(BinlogConfig.batchSize); long batchId = message.getId(); //过滤有效待处理消息 List&lt;CanalEntry.Entry&gt; entries = message.getEntries().stream() .filter(e -&gt; e.getEntryType() == CanalEntry.EntryType.ROWDATA) .collect(Collectors.toList()); if (batchId != -1 &amp;&amp; !CollectionUtil.isEmpty(entries)) &#123; int size = entries.size(); long memSize = entries .stream() .mapToLong(e -&gt; e.getHeader().getEventLength()) .sum(); log.info(receiveInfo, batchId, size, memSize); BinlogConfig.parseFunction.apply(entries); &#125; else &#123; try &#123; //惩罚等待TimeUnit.SECONDS.sleep(BinlogConfig.waitSeconds); &#125; catch (InterruptedException e)&#123; e.printStackTrace(); &#125; &#125; &#125; &#125; 注意，get方法和getWithoutAck方法的区别是： get方法会立即调用ack getWithoutAck方法不会调用ack]]></content>
      <categories>
        <category>架构</category>
      </categories>
      <tags>
        <tag>Canal</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hazelcast持久化及优化]]></title>
    <url>%2Fposts%2F53779%2F</url>
    <content type="text"><![CDATA[数据内存格式参数:in-memory-format,有3种。 BINARY 默认，数据k-v均二进制。 适合绝大多数put、get等操作，效率最高。 OBJECT 数据存储为对象反序列化，适合对象复杂查询操作，避免反序列时间消耗。 k为二进制，v为对象。 NATIVE 企业版，二进制格式，存储在非堆空间，避免GC。 元数据策略 参数:Metadata Policy 自动预处理数据类型，以快速进行数据查询。 仅支持json类型，开启时，对json对象添加额外属性。 不影响其他类型的吞吐量。 如果json类型不需要复杂查询，可以关闭，默认开启。 123&lt;map name="map-a"&gt; &lt;metadata-policy&gt;OFF&lt;/metadata-policy&gt;&lt;/map&gt; 数据更新 MapStore，持久化接口，将数据持久化。 MapLoader，数据加载接口。可以进行启动时的缓存初始化，采用多线程。 实现接口不应使用hz的例如map各种操作，应使用持久化的方法，否则陷入死循环。 持久化策略支持3种策略，Read-Through、Write-Through和Write-Behind。 读时 如不存在从数据库读，同时写入缓存 写时 写入缓存时，即时写入持久化，设置write-delay-seconds=0 触发条件：写入、更新(修改、删除)、backup-count大于0 写后 写入缓存延迟时间后再写入持久化 write-delay-seconds大于0 异步执行，仅保存最后更新结果 可以设置MapStoreConfig.setWriteCoalescingto为FALSE存储所有更新。 超出负载抛出异常，停止异步存储。 删除方法 delete删除缓存 remove删除存储 evict删除缓存和存储 持久化实现12345678&lt;map name="default"&gt; &lt;map-store enabled="true" initial-mode="LAZY"&gt; &lt;class-name&gt;com.hazelcast.examples.DummyStore&lt;/class-name&gt; &lt;write-delay-seconds&gt;60&lt;/write-delay-seconds&gt; &lt;write-batch-size&gt;1000&lt;/write-batch-size&gt; &lt;write-coalescing&gt;true&lt;/write-coalescing&gt; &lt;/map-store&gt; &lt;/map&gt; class-name:MapLoader或MapStore的实现类 InitialLoadModeMapLoader.loadAllKeys接口，预加载数据。 getMap()时提供InitialLoadMode模式，LAZY和EAGER。 LAZY，map创建时不加载所有，仅加载所触达的分区数据。 EAGER，map创建时所有分区全部加载。 123456789101112&lt;map name="default"&gt; &lt;backup-count&gt;0&lt;/backup-count&gt; &lt;async-backup-count&gt;1&lt;/async-backup-count&gt;&lt;/map&gt;&lt;map name="default"&gt; &lt;map-store enabled="true" initial-mode="LAZY"&gt; &lt;class-name&gt;com.hazelcast.examples.DummyStore&lt;/class-name&gt; &lt;write-delay-seconds&gt;60&lt;/write-delay-seconds&gt; &lt;write-batch-size&gt;1000&lt;/write-batch-size&gt; &lt;write-coalescing&gt;true&lt;/write-coalescing&gt; &lt;/map-store&gt;&lt;/map&gt; Optimistic Locking乐观锁使用 1map.replace( key, oldValue, newValue ) near-cache本地cache 在client端进行本地缓存，减少网络开销，提高性能 同时支持member上的修改和删除等操作导致的脏数据同步过期。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152 &lt;near-cache&gt; &lt;time-to-live-seconds&gt;0&lt;/time-to-live-seconds&gt; &lt;max-idle-seconds&gt;60&lt;/max-idle-seconds&gt; &lt;invalidate-on-change&gt;true&lt;/invalidate-on-change&gt; &lt;in-memory-format&gt;BINARY&lt;/in-memory-format&gt; &lt;cache-local-entries&gt;false&lt;/cache-local-entries&gt; &lt;eviction size="1000" max-size-policy="ENTRY_COUNT" eviction-policy="LFU"/&gt; &lt;/near-cache&gt;``` - 适合本地大量读业务，例如client端- 不适合大量修改业务，否则开销更大- Near Cache不支持强一致性- member上开启时，将增大内存消耗- client或server均支持，各自也均需要配置- client hits时和server hits无关，此时server上空闲时间不受影响- client的name必须和member上一致，也可以用匹配符- 仅对get操作生效### 一个机器一个member多节点在一个机器上性能不如一个节点一个机器，因为可能有大量的上下文切换。### I/O线程Hazelcast采用多线程的线程池进行IO操作。每个member拆分3中线程类型：- 接收请求- 读取数据，从member或client- 写数据，到member或client`hazelcast.io.thread.count`配置每个member线程数默认是3.默认3个线程数情况下，总计是7个io线程，1个接收数据，3个读，3个写。每个io线程有自己的Selector和waits。### Back Pressure背压解决负载和操作导致的OOM问题- 设置并发操作数- 设置定期异步备份### Flake ID Generator在member上的操作总是本地的。在client上操作newId()，在指定的时间，会在本地随机一个member和获取批量的ids。批量数和有效期在每个client及member均可指定。配置```xml &lt;flake-id-generator name="default"&gt; &lt;prefetch-count&gt;100&lt;/prefetch-count&gt; &lt;prefetch-validity-millis&gt;600000&lt;/prefetch-validity-millis&gt; &lt;/flake-id-generator&gt; 全局序列化client端代码 123456789101112131415161718192021222324252627public class GlobalStreamSerializer implements StreamSerializer&lt;Object&gt; &#123; @Override public void write(ObjectDataOutput out, Object oo) throws IOException &#123; out.writeUTF(oo.getClass().getName()); out.writeByteArray(new ObjectMapper().writeValueAsBytes(oo)); &#125; @Override public Object read(ObjectDataInput in) throws IOException &#123; String clazz = in.readUTF(); try &#123; return new ObjectMapper().readValue(in.readByteArray(), Class.forName(clazz)); &#125; catch (ClassNotFoundException e) &#123; throw ExceptionUtil.peel(e); &#125; &#125; @Override public int getTypeId() &#123; return 1; &#125; @Override public void destroy() &#123; &#125;&#125; 123456&lt;user-code-deployment enabled="true"&gt; &lt;classNames&gt; &lt;!-- for classes available in client's class path --&gt; &lt;className&gt;xx.cache.client.GlobalStreamSerializer&lt;/className&gt; &lt;/classNames&gt;&lt;/user-code-deployment&gt;]]></content>
      <categories>
        <category>架构</category>
      </categories>
      <tags>
        <tag>Hazelcast</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java8新变化]]></title>
    <url>%2Fposts%2F3769%2F</url>
    <content type="text"><![CDATA[Java8优势自1998年JDK1.0（Java1.0）发布以来,从Java1.1（1997年）-Java7（2011年），Java不断升级,Java8则是在2014年3月发布。 流处理Java 8在java.util.stream中添加了一个Stream API;Stream可以看成一种迭代器。 Stream API的可以链接形成一个复杂的流水线，就像Unix命令。 可以在一个更高的抽象层次上写Java8程序，把这样的流变成那样的流(就像写数据库查询语句时的那种思路)，而不是一次只处理一个项目。 Java8可以透明地把输入的不相关部分拿到几个CPU内核上去分别执行。Stream操作流水线——这是几乎免费的并行，用不着去费劲搞Thread。 用行为参数化把代码传递给方法可以写一个compareUsingCustomerId来比较两张发票的代码，但是在Java8之前，你没法把这个方法传给另一个方法。可以创建一个Comparator对象，将之传递给sort方法，但这不但啰嗦，而且让“重复使用现有行为”的思想变得不那么清楚了。 Java8增加了把方法(代码)作为参数传递给另一个方法的能力。 并行与共享的可变数据行为必须能够同时对不同的输入安全地执行。这就意味着，写代码时不能访问共享的可变数据。这些函数有时被称为“纯 函数”或“无副作用函数”或“无状态函数”。 Java8的流实现并行比Java现有的线程API更容易，因此，尽管可以使用synchronized来打破“不能有共享的可变数据”这一规则，但这相当于是在和整个体系作对，因为它使所有围绕这一规则做出的优化都失去意义了。 在多个处理器内核之间使用synchronized，其代价往往比预期的要大得多，因为同步迫使代码按照顺序执行，而这与并行处理的宗旨相悖。 没有共享的可变数据及将方法函数即代码传递给其他方法的能力是函数式编程范式的基石。不能有共享的可变数据的要求意味着，方法的行为就像一个数学函数，没有可见的副作用。 Java8中的主要变化反映了它开始远离常侧重改变现有值的经典面向对象思想，而向函数式编程领域转变。 Java8中的函数Java8中新增了函数——值的一种新形式。它有助于使用流，可以进行多核处理器上的并行编程。 值是Java中的一等公民，但其他很多Java概念(如方法和类等)则是二等公民。在运行时传递方法能将方法变成一等公民。 方法和Lambda作为一等公民方法引用Java8的方法引用采用::语法，写下File::isHidden的时候，就创建了一个方法引用，你同样可以传递它。 Lambda——匿名函数将函数作为值的思想 123456789101112public static boolean isGreenApple(Apple apple) &#123; return "green".equals(apple.getColor());&#125; static List&lt;Apple&gt; filterApples(List&lt;Apple&gt; inventory, Predicate&lt;Apple&gt; p) &#123; List&lt;Apple&gt; result = new ArrayList&lt;&gt;(); for (Apple apple: inventory)&#123; if (p.test(apple)) &#123; result.add(apple); &#125; &#125; return result; &#125; 传递方法 12filterApples(inventory, Apple::isGreenApple); filterApples(inventory, Apple::isHeavyApple); 谓词传递方法Apple::isGreenApple（接受参数Apple并返回一个boolean）给filterApples，后者则希望接受一个Predicate参数。 谓词（predicate）在数学上常常用来代表一个类似函数的东西，它接受一个参数值，并返回true或false。 从传递方法到Lambda类似于isHeavyApple和isGreenApple这种可能只用一两次的短方法写一堆定义有点儿烦人。 Java8解决了这个问题，它引入了一套新记法（匿名函数或Lambda）。 1234filterApples(inventory, (Apple a) -&gt; "green".equals(a.getColor()) );filterApples(inventory, (Apple a) -&gt; a.getWeight() &gt; 150 );filterApples(inventory, (Apple a) -&gt; a.getWeight() &lt; 80 || "brown".equals(a.getColor()) ); 甚至都不需要为只用一次的方法写定义；代码更干净、更清晰，因为用不着去找自己到底传递了什么代码。 但要是Lambda的长度多于几行（它的行为也不是一目了然）的话，那还是应该用方法引用来指向一个有描述性名称的方法，而不是使用匿名的Lambda，应该以代码的清晰度为准绳。 Java8流用for-each循环一个个去迭代元素，然后再处理元素。我们把这种数据迭代的方法称为外部迭代。 Stream API，根本用不着操心循环的事情。数据处理完全是在库内部进行的，我们把这种思想叫作内部迭代。Java8提供了新的编程风格，可更好地利用多核计算机。 Java8默认方法直接对List调用sort方法，它是用Java8 List接口中如下所示的默认方法实现的 123default void sort(Comparator&lt;? super E&gt; c) &#123; Collections.sort(this, c); &#125; 这意味着List的任何实体类都不需要显式实现sort，而在以前的Java版本中，除非提供了sort的实现，否则这些实体类在重新编译时都会失败。 Java8来自函数式编程的其他好思想Java中从函数式编程中引入的两个核心思想：将方法和Lambda作为一等值，以及在没有可变共享状态时，函数或方法可以有效、安全地并行执行。 Optional在Java 8里有一个Optional类，如果你能一致地使用它的话，就可以帮助你避免出现NullPointer异常。它是一个容器对象，可以包含，也可以不包含一个值。 模式匹配模式匹配可以看作switch的扩展形式，可以同时将一个数据类型分解成元素。 在Java中，你可以在这里写一个if-then-else语句或一个switch语句。其他语言表明，对于更复杂的数据类型，模式匹配可以比if-then-else更简明地表达编程思想。 给定一个数据类型Expr代表表达式，在Scala里可以写以下代码，把Expr分解给它的各个部分，然后返回另一个Expr。 123456def simplifyExpression(expr: Expr): Expr = expr match &#123; case BinOp("+", e, Number(0)) =&gt; e case BinOp("*", e, Number(1)) =&gt; e case BinOp("/", e, Number(1)) =&gt; e case _ =&gt; expr &#125; 这里，Scala的语法expr match就对应于Java中的switch (expr)。 Java中的switch语句限于原始类型值和Strings。函数式语言倾向于允许switch用在更多的数据类型上，包括允许模式匹配（在Scala代码中是通过match操作实现的）。 模式匹配的一个优点是编译器可以报告常见错误。]]></content>
      <categories>
        <category>工具利器</category>
      </categories>
      <tags>
        <tag>Java8</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hazelcast队列和发布订阅实现]]></title>
    <url>%2Fposts%2F48149%2F</url>
    <content type="text"><![CDATA[队列和订阅区别 队列是queue，订阅是topic 队列是只能被消费一次，订阅是被消费多次 队列消费是主动轮询take，订阅是消息被动通知 队列实现 采用FIFO先进先出顺序消费 元素没有批量处理，只能迭代逐个take 元素被复制到本地处理 可能使用ItemListener监听队列新增和删除操作 生产123456789101112public class ProducerMember &#123; public static void main( String[] args ) throws Exception &#123; HazelcastInstance hz = Hazelcast.newHazelcastInstance(); IQueue&lt;Integer&gt; queue = hz.getQueue( "queue" ); for ( int k = 1; k &lt; 100; k++ ) &#123; queue.put( k ); System.out.println( "Producing: " + k ); Thread.sleep(1000); &#125; queue.put( -1 ); System.out.println( "Producer Finished!" );&#125; &#125; 消费123456789101112131415public class ConsumerMember &#123; public static void main( String[] args ) throws Exception &#123; HazelcastInstance hz = Hazelcast.newHazelcastInstance(); IQueue&lt;Integer&gt; queue = hz.getQueue( "queue" ); while ( true ) &#123; int item = queue.take(); System.out.println( "Consumed: " + item ); if ( item == -1 ) &#123; queue.put( -1 );break; &#125; Thread.sleep( 5000 ); &#125; System.out.println( "Consumer Finished!" ); &#125;&#125; 效率提升 提供多个消费者 非严格顺序，可以创建多个队列分别生产和消费 消费者可以启动定时任务，提高消费频度 可靠性 一个队列成员，会有一个备份 队列元素使用全局递增itemId，不会重复 QueueStore提供队列内存时，同时也持久化，在超内存限制时数据也会持久化 max-size可以设置队列长度，多余元素put会被阻塞，直到有队列空间 高吞吐量时，可支持多个消费者并发 网络分区故障时，提供Split-Brain脑裂保护，避免仅部分员执行操作成功 订阅实现 发布/订阅模型，发布是异步操作 订阅同一个topic，所有订阅者均收到消息 支持全局顺序 实现发布 1234567public class TopicPublisher &#123; public static void main(String[] args) &#123; HazelcastInstance hz = Hazelcast.newHazelcastInstance(); ITopic&lt;Date&gt; topic = hz.getTopic("topic"); topic.publish(new Date()); &#125; &#125; 订阅 12345678910111213public class TopicSubscriber &#123; public static void main(String[] args) &#123; HazelcastInstance hz = Hazelcast.newHazelcastInstance(); ITopic&lt;Date&gt; topic = hz.getTopic("topic"); topic.addMessageListener(new MessageListenerImpl()); System.out.println("Subscribed"); &#125; private static class MessageListenerImpl implements MessageListener&lt;Date&gt; &#123; public void onMessage(Message&lt;Date&gt; m) &#123; System.out.println("Received: " + m.getMessageObject()); &#125; &#125;&#125; MessageListener 可以监听和消费具体消息 全局顺序 消息是顺序发布，订阅者是顺序接受 消息也可能是全局顺序，所有订阅者接受多个发布者消息的顺序都是一致 例如有3个成员，member1发布消息a1 和 a2. Member3 发布消息 c1 and c2. 可能有以下顺序： member1 → c1, a1, a2, c2 member2 → c1, c2, a1, a2 开启 globalOrderEnabled 如果member1 → a1, c1, a2, c2 则member2 → a1, c1, a2, c2 确保所有成员接受所有消息的顺序是一致，而非来自某个发布者。 StripedExecutor 有很多线程，负责消息的全局顺序发布。 hazelcast.event.thread.count是线程数量。 Topic的名称取hash%线程数量，即为处理该Topic的线程id Reliable Topic Reliable Topic 根据Ringbuffer数据结构进行备份 可靠性高，解决事件丢失问题 快速消费，更稳定和安全 1ITopic&lt;Long&gt; topic = hz.getReliableTopic("sometopic"); TopicOverloadPolicy 超过容量可以设置过载策略，DISCARD_OLDEST丢失最老、DISCARD_NEWEST丢弃最新、BLOCK阻塞直到超时、ERROR抛出异常 read-batch-size，支持批量读取消息]]></content>
      <categories>
        <category>架构</category>
      </categories>
      <tags>
        <tag>Hazelcast</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Gradle安装和IDEA配置]]></title>
    <url>%2Fposts%2F52236%2F</url>
    <content type="text"><![CDATA[下载 下载地址 gradle 选择二进制包，包括文档和源码 下载V5.6.2，后解压 安装 环境变量 export PATH=$PATH:/opt/gradle/gradle-5.6.2/bin 测试 $ gradle -v Gradle 5.6.2 配置创建.gradle目录 ~/.gradle/ 设置源 vi ~/.gradle/init.gradle 1234567891011121314151617181920212223allprojects&#123; repositories &#123; def ALIYUN_REPOSITORY_URL = &apos;http://maven.aliyun.com/nexus/content/groups/public&apos; def ALIYUN_JCENTER_URL = &apos;http://maven.aliyun.com/nexus/content/repositories/jcenter&apos; all &#123; ArtifactRepository repo -&gt; if(repo instanceof MavenArtifactRepository)&#123; def url = repo.url.toString() if (url.startsWith(&apos;https://repo1.maven.org/maven2&apos;)) &#123; project.logger.lifecycle &quot;Repository $&#123;repo.url&#125; replaced by $ALIYUN_REPOSITORY_URL.&quot; remove repo &#125; if (url.startsWith(&apos;https://jcenter.bintray.com/&apos;)) &#123; project.logger.lifecycle &quot;Repository $&#123;repo.url&#125; replaced by $ALIYUN_JCENTER_URL.&quot; remove repo &#125; &#125; &#125; maven &#123; url ALIYUN_REPOSITORY_URL url ALIYUN_JCENTER_URL &#125; &#125;&#125; IDEA 打开file-&gt;setting-&gt;Build,Execution,Deployment-&gt;Gradle 配置Gradle home，选择用本地Gradle，输入Gradle安装目录 配置Service directory path，指定gradle数据目录]]></content>
      <categories>
        <category>架构</category>
      </categories>
      <tags>
        <tag>Gradle</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[NPM包管理工具]]></title>
    <url>%2Fposts%2F45569%2F</url>
    <content type="text"><![CDATA[介绍npm 是JavaScript 世界的包管理工具，并且是Node.js 平台的默认包管理工具。通过npm 可以安装、共享、分发代码，管理项目依赖关系。 npm 由三个独立的部分组成： 网站；网站 是开发者查找包（package）、设置参数以及管理 npm 使用体验的主要途径。 注册表（registry）；注册表 是一个巨大的数据库，保存了每个包（package）的信息。 命令行工具 (CLI)；CLI 通过命令行或终端运行。开发者通过 CLI 与 npm 打交道。 安装 安装Node.js和NPM Node.js download page安装后运行 node -v，版本应该是v8.9.1或更高。 更新 npm npm -v npm install npm@latest -g #最新的官方和测试版 npm install npm@next -g #更新将来下一版 命令 版本npm -v 升级sudo npm install npm -g 国内源npm install -g cnpm –registry=https://registry.npm.taobao.orgcnpm: npm 客户端( cnpmjs.org )淘宝 NPM 镜像，同步频率目前为 10分钟 一次以保证尽量与官方服务同步。 安装模块npm install # 本地安装npm install express -g # 全局安装 卸载模块npm uninstall express 查看安装信息npm list -g #查看所有全局安装的模块npm ls #本地安装npm list grunt #如果要查看某个模块的版本号 更新模块npm update express 搜索模块npm search express 创建模块npm init，输入模块信息和生成 package.json 文件npm adduser，在 npm 资源库中注册用户npm publish，发布模块 删除以前安装npm cache clean package.jsonpackage.json 位于模块的目录下，用于定义包的属性。Package.json 属性说明name - 包名。 version - 包的版本号。 description - 包的描述。 homepage - 包的官网 url 。 author - 包的作者姓名。 contributors - 包的其他贡献者姓名。 dependencies - 依赖包列表。如果依赖包没有安装，npm 会自动将依赖包安装在 node_module 目录下。 repository - 包代码存放的地方的类型，可以是 git 或 svn，git 可在 Github 上。 main - main 字段指定了程序的主入口文件，require(‘moduleName’) 就会加载这个文件。这个字段的默认值是模块根目录下面的 index.js。 keywords - 关键字]]></content>
      <categories>
        <category>架构</category>
      </categories>
      <tags>
        <tag>NPM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot+JPA实体自动生成数据库]]></title>
    <url>%2Fposts%2F4871%2F</url>
    <content type="text"><![CDATA[POM1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-jpa&lt;/artifactId&gt;&lt;/dependency&gt; 引入SpringBoot 引入Jpa 配置1234spring.jpa.database=mysqlspring.jpa.database-platform: org.hibernate.dialect.MySQL5InnoDBDialect# 自动检查实体和数据库表是否一致，如果不一致则会进行更新数据库表spring.jpa.hibernate.ddl-auto=update MySQL5InnoDBDialect数据库引擎 ddl-auto validate 加载 Hibernate 时，验证创建数据库表结构 create 每次加载 Hibernate ，重新创建数据库表结构 create-drop 加载 Hibernate 时创建，sessionFactory关闭退出时删除表结构 update 加载 Hibernate 自动更新数据库结构开启12345678@SpringBootApplication//自动填充或更新实体中的CreateDate、CreatedBy@EnableJpaAuditingpublic class Startup &#123; public static void main(String[] args) &#123; SpringApplication.run(Startup.class, args); &#125;&#125; EnableJpaAuditing审计注解 公共实体12345678910111213141516@Data//该注解标注的类不会映射到数据库中单独的表，该类所拥有的属性都将映射到其子类@MappedSuperclasspublic abstract class CommonEntity &#123; @Id @Column(columnDefinition = "varchar(20) comment '主键'") private String id; @Column(columnDefinition = "int(11) default 0 comment '乐观锁'") private int version; @Column(columnDefinition = "timestamp default CURRENT_TIMESTAMP comment '创建时间'") private LocalDateTime createDate; @Column(columnDefinition = "timestamp default CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP comment '最后修改时间'") private LocalDateTime lastModifiedDate; @Column(columnDefinition = "int(2) default 0 comment '状态:0-有效，1-无效'") private int status;&#125; 超类，公共实体 Column定义字段、Id定义唯一标识 columnDefinition定义字段类型、长度、默认值、注释 CURRENT_TIMESTAMP定义默认的创建和修改时间 审计字段123456@Versionprivate Long version;@CreatedDateprivate LocalDateTime createDate;@LastModifiedDateprivate LocalDateTime lastModifiedDate; 乐观锁 创建时间 修改时间 ### 123456789101112@Data@ToString@Entity(name = "xx")@Table(appliesTo = "xx", comment = "xx表")public class XXEntity extends CommonEntity &#123; @Column(columnDefinition = "varchar(50) COMMENT 'xx'", unique = true) private String name; @Column(columnDefinition = "varchar(20) COMMENT 'xx'") @Index(name = "idx_projectId") private String projectId;&#125; 数据库定义 表定义、注释，Table为org.hibernate.annotations.Table 索引定义 唯一约束]]></content>
      <categories>
        <category>架构</category>
      </categories>
      <tags>
        <tag>SpringBoot</tag>
        <tag>JPA</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Maven自定义Parent并集成SpringBoot]]></title>
    <url>%2Fposts%2F53117%2F</url>
    <content type="text"><![CDATA[自定义Parent123456&lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;&lt;groupId&gt;com.xx.xx&lt;/groupId&gt;&lt;artifactId&gt;xx-parent&lt;/artifactId&gt;&lt;version&gt;1.0.1&lt;/version&gt;&lt;packaging&gt;pom&lt;/packaging&gt; parent依赖管理集成SpringBoot1234567891011&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.0.5.RELEASE&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; 子项目继承和使用继承Parent12345678910&lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;&lt;artifactId&gt;xx-xx&lt;/artifactId&gt;&lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;&lt;parent&gt; &lt;artifactId&gt;xx-xx&lt;/artifactId&gt; &lt;groupId&gt;com.xx.xx&lt;/groupId&gt; &lt;version&gt;1.0.1&lt;/version&gt;&lt;/parent&gt; 使用SpringBoot123456&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt;]]></content>
      <categories>
        <category>工具利器</category>
      </categories>
      <tags>
        <tag>Maven</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SaaS多租户数据库方案]]></title>
    <url>%2Fposts%2F20124%2F</url>
    <content type="text"><![CDATA[方案选择独立数据库一个租户一个数据库，这种方案的用户数据隔离级别最高，安全性最好，但成本较高。 优点：为不同的租户提供独立的数据库，有助于简化数据模型的扩展设计，满足不同租户的独特需求；如果出现故障，恢复数据比较简单。 缺点：增多了数据库的安装数量，随之带来维护成本和购置成本的增加。 这种方案与传统的一个客户、一套数据、一套部署类似，差别只在于软件统一部署在运营商那里。 如果面对的是银行、医院等需要非常高数据隔离级别的租户，可以选择这种模式，提高租用的定价。如果定价较低，产品走低价路线，这种方案一般对运营商来说是无法承受的。 共享数据库，隔离数据架构多个或所有租户共享Database，但是每个租户一个Schema（也可叫表）。 优点： 为安全性要求较高的租户提供了一定程度的逻辑数据隔离，并不是完全隔离；每个数据库可支持更多的租户数量。 缺点：如果出现故障，数据恢复比较困难，因为恢复数据库将牵涉到其他租户的数据；如果需要跨租户统计数据，存在一定困难。 共享数据库，共享数据架构租户共享同一个Database、同一个Schema，但在表中增加TenantID多租户的数据字段。 这是共享程度最高、隔离级别最低的模式。 优点： 三种方案比较，第三种方案的维护和购置成本最低，允许每个数据库支持的租户数量最多。 缺点： 隔离级别最低，安全性最低，需要在设计开发时加大对安全的开发量； 数据备份和恢复最困难，需要逐表逐条备份和还原。 如果希望以最少的服务器为最多的租户提供服务，并且租户接受牺牲隔离级别换取降低成本，这种方案最适合。 综合考量考量成本角度因素，隔离性越好，设计和实现的难度和成本越高，初始成本越高。共享性越好，同一运营成本下支持的用户越多，运营成本越低。 考量安全因素要，考虑业务和客户的安全方面的要求。安全性要求越高，越要倾向于隔离。 考量可能的租户越多，越倾向于共享。 考量平均每个租户要存储数据需要的空间大小。存贮的数据越多，越倾向于隔离。 每个租户的同时访问系统的最终用户数量。需要支持的越多，越倾向于隔离。 是否想针对每一租户提供附加的服务，例如数据的备份和恢复等。这方面的需求越多，越倾向于隔离。]]></content>
      <categories>
        <category>架构</category>
      </categories>
      <tags>
        <tag>多租户</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot+Mybatis+Mycat多租户数据库实现]]></title>
    <url>%2Fposts%2F64375%2F</url>
    <content type="text"><![CDATA[Mycat下载1wget http://dl.mycat.io/1.6.7.3/20190927161129/Mycat-server-1.6.7.3-release-20190927161129-linux.tar.gz 配置server.xml，Mycat服务器配置，默认端口8066 12345678910111213141516171819202122232425&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;!DOCTYPE mycat:server SYSTEM "server.dtd"&gt;&lt;mycat:server xmlns:mycat="http://io.mycat/"&gt; &lt;system&gt; &lt;property name="useSqlStat"&gt;0&lt;/property&gt; &lt;property name="useGlobleTableCheck"&gt;0&lt;/property&gt; &lt;property name="sequnceHandlerType"&gt;2&lt;/property&gt; &lt;property name="handleDistributedTransactions"&gt;0&lt;/property&gt; &lt;property name="useOffHeapForMerge"&gt;1&lt;/property&gt; &lt;property name="memoryPageSize"&gt;1m&lt;/property&gt; &lt;property name="spillsFileBufferSize"&gt;1k&lt;/property&gt; &lt;property name="useStreamOutput"&gt;0&lt;/property&gt; &lt;property name="systemReserveMemorySize"&gt;384m&lt;/property&gt; &lt;property name="useZKSwitch"&gt;true&lt;/property&gt; &lt;/system&gt; &lt;!--Mycat用户名--&gt; &lt;user name="root"&gt; &lt;!--Mycat密码--&gt; &lt;property name="password"&gt;root&lt;/property&gt; &lt;!--Mycat数据库名--&gt; &lt;property name="schemas"&gt;mycat_test&lt;/property&gt; &lt;/user&gt;&lt;/mycat:server&gt; schema.xml，Mycat和Mysql节点映射配置 12345678910111213141516171819202122&lt;?xml version="1.0"?&gt;&lt;!DOCTYPE mycat:schema SYSTEM "schema.dtd"&gt;&lt;mycat:schema xmlns:mycat="http://io.mycat/"&gt; &lt;!--Mycat数据库名--&gt; &lt;schema name="mycat_test" checkSQLschema="true" sqlMaxLimit="100"&gt; &lt;!--Mycat表名，节点名称列表--&gt; &lt;table name="mycat_test_student" dataNode="dn1,dn2"/&gt; &lt;/schema&gt; &lt;!--Mycat节点名称、节点地址、mysql数据库名--&gt; &lt;dataNode name="dn1" dataHost="localhost1" database="db01" /&gt; &lt;dataNode name="dn2" dataHost="localhost1" database="db02" /&gt; &lt;!--Mycat节点地址--&gt; &lt;dataHost name="localhost1" maxCon="1000" minCon="10" balance="0" writeType="0" dbType="mysql" dbDriver="native" switchType="1" slaveThreshold="100"&gt; &lt;heartbeat&gt;select user()&lt;/heartbeat&gt; &lt;!-- mysql数据库服务器、账户、密码 --&gt; &lt;writeHost host="hostM1" url="192.168.1.71:3306" user="test" password="test@1234"&gt; &lt;/writeHost&gt; &lt;/dataHost&gt;&lt;/mycat:schema&gt; Spring Boot数据源配置12345678//mycat连接信息spring.datasource.url=jdbc:mysql://localhost:8066/mycat_test?serverTimezone=GMTspring.datasource.username=rootspring.datasource.password=rootspring.datasource.driver-class-name=com.mysql.jdbc.Driver//mybatis拦截器配置mybatis.config-location=classpath:mybatis.xml Mybatismybatis.xml插件配置 12345678910111213141516171819202122&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;!DOCTYPE configuration PUBLIC "-//mybatis.org//DTD Config 3.0//EN" "http://mybatis.org/dtd/mybatis-3-config.dtd"&gt;&lt;configuration&gt; &lt;settings&gt; &lt;!-- 打印查询语句 --&gt; &lt;setting name="logImpl" value="STDOUT_LOGGING" /&gt; &lt;/settings&gt; &lt;typeAliases&gt; &lt;typeAlias alias="TestPojo" type="xx.xx.TestPojo"/&gt; &lt;/typeAliases&gt; &lt;!-- 拦截器插件，改写sql --&gt; &lt;plugins&gt; &lt;plugin interceptor="xx.interceptor.MyInterceptor"&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/configuration&gt; 拦截器12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152//拦截StatementHandler的prepare方法@Intercepts(value = &#123; @Signature(type = StatementHandler.class, method = "prepare", args = &#123;Connection.class,Integer.class&#125;)&#125;)public class MyInterceptor implements Interceptor &#123; // 修改sql，添加前后缀 private static final String preState="/*!mycat:datanode="; private static final String afterState="*/"; @Override public Object intercept(Invocation invocation) throws Throwable &#123; StatementHandler statementHandler=(StatementHandler)invocation.getTarget(); MetaObject metaStatementHandler=SystemMetaObject.forObject(statementHandler); Object object=null; //分离代理对象链 while(metaStatementHandler.hasGetter("h"))&#123; object=metaStatementHandler.getValue("h"); metaStatementHandler=SystemMetaObject.forObject(object); &#125; //获取sql String sql=(String)metaStatementHandler.getValue("delegate.boundSql.sql"); //根据会话上下文，获取节点标识 String node=(String) SessionUtil.getSession().getAttribute("appId"); if(node!=null) &#123; //重写sql，适配mycat sql = preState + node + afterState + sql; &#125; System.out.println("sql is "+sql); metaStatementHandler.setValue("delegate.boundSql.sql",sql); Object result = invocation.proceed(); System.out.println("Invocation.proceed()"); return result; &#125; // 返回当前拦截的对象(StatementHandler)的动态代理 // 当拦截对象的方法被执行时, 动态代理中执行拦截器intercept方法. @Override public Object plugin(Object target) &#123; return Plugin.wrap(target, this); &#125; @Override public void setProperties(Properties properties) &#123; String prop1 = properties.getProperty("prop1"); String prop2 = properties.getProperty("prop2"); System.out.println(prop1 + "------" + prop2); &#125;&#125; 总结以上为关键实现，主要过程如下： 搭建Mycat服务，设置提供的数据库信息 配置Mycat动态映射的两个节点，Mycat根据sql语句中的/*!mycat:datanode=dn1*/进行动态切换数据源后执行sql 配置SpringBoot的Mycat数据源连接 配置Mybatis的拦截器插件 配置Mybatis拦截器实现，根据上下文节点，改写sql 注意 生产可采用Mycat集群，集群用ZK管理，以动态实例化数据源]]></content>
      <categories>
        <category>架构</category>
      </categories>
      <tags>
        <tag>SpringBoot</tag>
        <tag>多租户</tag>
        <tag>Mybatis</tag>
        <tag>Mycat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hazelcast分区原理]]></title>
    <url>%2Fposts%2F47449%2F</url>
    <content type="text"><![CDATA[Hazelcast分片Hazelcast分片被称为分区。 Hazelcast默认有271个分区。给定key，Hazelcast进行序列化、hash并根据分区数量取模，获取key对应的分区。 集群内成员的分区是对等的。Hazelcast将分区数据在成员间的区分内进行分布备份和冗余。 数据分发Hazelcast 没有主成员，每个成员在功能上都是对等的。 最先启动的成员会自动的将数据同步到集群其他成员中，如果最先启动成员宕机，由第二最先启动成员执行数据分发操作。 Hazelcast存储全部数据在内存，因此速度快。一旦有成员crash，也不会有数据丢失，因为有数据拷贝在其他成员中。 Hazelcast提供分布式数据结构和分布式计算工具，提供了丰富的访问分布式集群内存和CPU计算的能力。 分区过程Hazelcast分区是内存段，每段都包含成百上千个数据实体，依赖于系统的内存能力。 每个分区都有多个副本，分布在集群成员中。副本中有一个是主副本，其他的是备份副本。 拥有主副本的集群成员被称为分区owner。当读或写入数据实体时，实际是与拥有该数据主副本的分区交互。 Hazelcast默认是每个成员拥有271个分区，当集群中只有一个成员时，也就意味着该成员有271个分区，且拥有所有分区的主副本。 在一个只有一个成员的Hazelcast集群中，当启动第二个成员时，分区复制过程如下： 正常情况下，分区复制没有顺序，而是随机，每个分布式分区之间也没有顺序，因此成员间的主分区和备份复制都是对等的。 当添加更多成员时，Hazelcast逐步移动主和复制分区复制到新成员中，确保所有的成员是对等和冗余的。由于持久性hash算法，仅有最小数量的分区被移动以扩展集群。 Hazelcast分布式分区中的主、备的复制在成员中是相同的，备份复制分区用于维持冗余。 Hazelcast提供lite成员，这些成员没有自己的分区。lite成员是用于重量型计算任务的执行和监听注册。尽管没有分区，他们也可访问集群中其他成员的分区。 Hazelcast分布式数据实体到分区中是根据hash算法。根据给定的对象key或对象名： key或名进行序列化，转换成字节数组 将字节数组进行hash hash值对分区数量MOD取模 取模结果为该数据应该存储的分区Id，在集群所有成员中，指定key的分区Id一定是相同的。 分区表启动成员后，分区表就会创建。 分区表存储分区id列表和他们归属的集群成员。分区表用于确保所有的成员包括lite成员，在集群中有相同的信息量，并确保每个成员间互相可知数据存储地址。 集群最早的成员即第一个启动的，发送分区表到所有成员。每个成员都被通知，分区的任何变更，变更包括成员加入、离开等。 加入最早的成员crash，第二早的成员发送分区表到其他成员。 可以配置分区表发送频度，通过hazelcast.partition.table.send.interval系统参数，默认是15秒。 重新分区重新分区是重新分布式分区的过程。在成员加入和离开时，Hazelcast执行重新分区操作，且最早的成员将会更新分区表信息。 lite成员因为没有分区，则不进行重新分区。 Hazelcast可以用于:• 共享服务配置和信息• 事件通知• Near Cache• 任务调度• 共享用户信息、队列等• 提供Web服务key• 分布式消息订阅服务• 分布式数据和id• 多租户map• 数据集• Spring框架前置的缓存层• 近实时流• 会话存储]]></content>
      <categories>
        <category>架构</category>
      </categories>
      <tags>
        <tag>Hazelcast</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hazelcast超时配置]]></title>
    <url>%2Fposts%2F63914%2F</url>
    <content type="text"><![CDATA[超时错误1processor error:com.hazelcast.client.HazelcastClientNotActiveException: Client is shutting down 若Hazelcast中成员全部断开，Client则抛出以上异常，此时，连接池连接已无效 Hazelcast成员重启后，Client继续抛出以上异常，无法重新初始化连接池 为重新初始化连接，则需要修改重试策略，以便重启成员，且无需重启Client 默认重试网络重试 1234&lt;!--6s--&gt;&lt;connection-timeout&gt;6000&lt;/connection-timeout&gt;&lt;!--1day:14400--&gt;&lt;connection-attempt-limit&gt;14400&lt;/connection-attempt-limit&gt; timeout，超时时间 limit，超时次数 limit可以设置无限大，以保障服务重连；若超过次数，则断开该连接 重试策略细粒度的重试策略配置，若开启则忽略网络重试。 1234567891011&lt;connection-strategy async-start="true" reconnect-mode="ASYNC"&gt; &lt;connection-retry enabled="true"&gt; &lt;!--first time:1s --&gt; &lt;initial-backoff-millis&gt;1000&lt;/initial-backoff-millis&gt; &lt;!--max time:1s --&gt; &lt;max-backoff-millis&gt;1000&lt;/max-backoff-millis&gt; &lt;multiplier&gt;2&lt;/multiplier&gt; &lt;fail-on-max-backoff&gt;false&lt;/fail-on-max-backoff&gt; &lt;jitter&gt;0.5&lt;/jitter&gt; &lt;/connection-retry&gt; &lt;/connection-strategy&gt; async，异步连接，不阻塞当前线程，默认同步 initial，第一次超时时间 max，最大超时时间 multiplier，乘数因子，以扩大下一次连接时间，默认2 fail，超过最大连接时间后是否失败，如不失败，继续重连，默认继续重连 jitter，选择随机重试成员的权重，默认0.2 心跳配置1234&lt;properties&gt; &lt;property name="hazelcast.client.heartbeat.timeout"&gt;6000&lt;/property&gt; &lt;property name="hazelcast.client.heartbeat.interval"&gt;5000&lt;/property&gt;&lt;/properties&gt; timeout，心跳超时时间 interval，心跳频率 interval需小于timeout]]></content>
      <categories>
        <category>架构</category>
      </categories>
      <tags>
        <tag>Hazelcast</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hazelcast部署方案]]></title>
    <url>%2Fposts%2F34736%2F</url>
    <content type="text"><![CDATA[启动在/bin目录下 start.sh / start.bat: 使用默认配置启动成员实例。 stop.sh / stop.bat: 停止成员实例。 cluster.sh: 集群管理, 例如获取和改变集群状态, 关闭或删除数据等。 start.sh / start.bat 启动一个实例。可以解压Hazelcast ZIP 或 TAR.GZ 在多个目录下，启动多个实例。 配置文件配置文件位于/bin目录下： hazelcast.xml: 默认配置文件，适合大多数场景。 hazelcast.yaml: yaml形式配置文件，等同于hazelcast.xml。 hazelcast-full-example.xml: Hazelcast配置中所有的配置元素、属性和描述，是hazelcast.xml的超集，用于学习和配置参考。 hazelcast-full-example.yaml: 等同于hazelcast-full-example.xml。 hazelcast-client-full-example.xml: Java client配置样例。 hazelcast-client-full-example.yaml: 等同于hazelcast-client-full-example.xml。 部署方式部署集群有两种方式: Embedded 嵌入式 Client/Serve 如果应用聚焦点是异步、高性能计算或大量任务处理，可以选择嵌入式。 将成员的数据和服务嵌入在应用内，可以支持低延迟的数据访问。 如果选择Client/Server部署，Hazelcast数据和服务分布在一个或多个成员中，应用根据Client进行连接。 可以独立提供和扩展成员集群，客户端将连接各成员的数据和服务。 Hazelcast 提供clients包括 (Java, .NET and C++), Memcache and REST clients, Scala, Pythonand Node.js client 各种实现方式. Client/Server有利于高可靠的集群性能，易于辨别问题，最重要的就是也支持扩展性. 当需要扩展集群成员时, 只需要启动更多的Hazelcast server 成员，可以将客户端和服务端扩展分离。 注意： Hazelcast 成员包仅支持Java。因此, 嵌入式成员部署仅支持Java应用。 如果既响应数据的低延迟访问，也想要成员部署的可扩展性，可以考虑在Client使用Near Caches，将频繁访问的数据在客户端本地内存中进行缓存。 hazelcast-mancenter下载管理中心tar，解压后启动 1nohup java -Dhazelcast.mc.allowMultipleLogin=true -jar hazelcast-mancenter-3.12.5.war 8200 hazelcast-mancenter &gt;nohup.out 2&gt;&amp;1 &amp; 打开地址：localhost:8200/hazelcast-mancenter]]></content>
      <categories>
        <category>架构</category>
      </categories>
      <tags>
        <tag>Hazelcast</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hazelcast介绍和优势]]></title>
    <url>%2Fposts%2F2412%2F</url>
    <content type="text"><![CDATA[Hazelcast介绍全称是Hazelcast IMDG (In-Memory Data Grid)，内存数据网格。 特点 开源 仅需要JAR文件，无需安装其他软件。 提供类库，不影响业务架构。 提供开箱即用的分布式数据结构，例如Map, Queue, MultiMap, Topic, Lock and Executor。 无主概念，没有单点故障，成员都是对等。 集群动态扩展，新增成员可以弹性提高内存和计算能力。 数据相互冗余和备份，防止成员宕机导致的数据丢失。 成员相互感知，区别于传统的kv缓存解决方案。 可使用SPI构建自定义分布式数据结构 开源社区长久持续开发 适合选型 应用分析，需要大数据分区处理 网格化数据读取 缓存，且支持JCache及弹性分布式扩展 数据存储，支持高性能、可扩展、低延迟 基于内存NoSQL-kv存储 发布/订阅，应用间支持高传播和可用性 在分布式云环境支持弹性扩展 高可用cache 支持Coherence and Terracotta 优势 支持并发数据结构，提供Java常用的数据结构，例如 Map, Queue, ExecutorService, Lock and JCache。 轻量级、易用，提供JAR可快速集成，无需额外依赖。 支持分布式缓存, 同步, 集群, 发布/订阅等, 部署简单，启动hazelcast.jar即可快速扩展分布式集群。 去中心化，点对点。无master 和 slave，无单点故障，所有成员数据对等。可以在程序中引入server或client。 自动扩展，可以支持成百上千集群，支持成员自动发信和线性增长内存和处理能力，成员间在TCP层进行连接。 快速查询和更新，内存存储。 冗余，多成员间互相冗余数据，成员宕机后由副本成员提供不间断的操作支持。 数据上报Hazelcast内部采用Phone Home进行内部实例初始化和集群同步的情况上报；上报时间为启动时和每隔24小时。 上报地址是：http://phonehome.hazelcast.com/ping（版本3.6+） 上报内容是： Hazelcast IMDG 版本 Hazelcast IMDG 成员id 集群hash值 集群启动时间 .. 关闭上报：hazelcast.phone.home.enabled=false JDK版本兼容Hazelcast3.11+，支持JDK6-11]]></content>
      <categories>
        <category>架构</category>
      </categories>
      <tags>
        <tag>Hazelcast</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Shadowsocks配置]]></title>
    <url>%2Fposts%2F44441%2F</url>
    <content type="text"><![CDATA[更新源如果是新系统，请先刷新软件源及更新软件 1sudo apt-get update &amp;&amp; sudo apt-get upgrade Ubuntu 14.04 和 Ubuntu 16.04 用户需新增 PPA 源 1sudo apt-get install software-properties-common &amp;&amp; sudo add-apt-repository ppa:max-c-lv/shadowsocks-libev &amp;&amp; sudo apt-get update 安装 Shadowsocks-libev1sudo apt install shadowsocks-libev 安装 simple-obfs（依次运行） 123456789sudo apt-get install --no-install-recommends build-essential autoconf libtool libssl-dev libpcre3-dev libc-ares-dev libev-dev asciidoc xmlto automake gitgit clone https://github.com/shadowsocks/simple-obfs.gitcd simple-obfsgit submodule update --init --recursive./autogen.sh./configure &amp;&amp; makesudo make installcd ..rm -rf simple-obfs 配置编辑配置文件 123456789101112sudo vim /etc/shadowsocks-libev/config.json&#123; &quot;server”:”0.0.0.0”, &quot;server_port&quot;:8588, &quot;local_port&quot;:7080, &quot;password&quot;:&quot;xxx&quot;, &quot;timeout&quot;:600, &quot;method&quot;:&quot;chacha20-ietf-poly1305&quot;, &quot;mode&quot;:&quot;tcp_and_udp&quot;, &quot;plugin&quot;:&quot;/usr/local/bin/obfs-server&quot;, &quot;plugin_opts&quot;:&quot;obfs=http&quot;&#125; 客户端查看插件 1~/Library/Application Support/ShadowsocksX-NG/plugins/ 插件配置 12plugin：simple-obfsplugin_opts：obfs=http;obfs-host=www.baidu.com 管理 开启服务 1sudo systemctl start shadowsocks-libev 停止服务 1sudo systemctl stop shadowsocks-libev 重启服务 1sudo systemctl restart shadowsocks-libev 开机启动 1sudo systemctl enable shadowsocks-libev 日志 1systemctl status shadowsocks-libev 测试 1ss-server -c /etc/shadowsocks-libev/config.json start -v ps 1ps -ef | grep -v grep | grep "server"]]></content>
      <categories>
        <category>工具利器</category>
      </categories>
      <tags>
        <tag>Shadowsocks</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[IDEA自定义Archetype]]></title>
    <url>%2Fposts%2F31081%2F</url>
    <content type="text"><![CDATA[创建自定义骨架生成骨架在maven项目下，执行mvn archetype:create-from-project，在target/generated-sources/archetype目录下生成Archetype project 安装骨架到本地cd target/generated-sources/archetype后，mvn install安装archetype project到本地仓库 ps：如果是maven多模块项目，在根目录下执行mvn archetype:create-from-project mvn install后，会在本地的maven仓库，按照maven坐标创建对应的archetype文件 注意：骨架的ArtifactId默认使用当前且添加后缀-archetype 使用自定义模板查看本地在当前的目录下，mvn archetype:generate -DarchetypeCatalog=local，查看本地archetype列表 选择使用choose number，按步骤输入基本参数groupId/artifactId/version/package 随后在当前目录下，以artifactId为目录创建一个新的项目 IDEA使用自定义模板添加到IDEA File-&gt;New-&gt; Project 选择Create from archetype Add Archetype 输入刚创建的骨架 1234GroupId：xx.xx.xxArtifactId：xx-xx-archetypeVersion：1.0-SNAPSHOTRepository(option)：local 随后点击Next 输入新的项目标识,groupId/artifactId/version 修改生成的项目结构为所需]]></content>
      <categories>
        <category>工具利器</category>
      </categories>
      <tags>
        <tag>IDEA</tag>
        <tag>工具</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java8处理空对象之Optional]]></title>
    <url>%2Fposts%2F19687%2F</url>
    <content type="text"><![CDATA[OptionalJava8中引入java.util.Optional，这是一个封装Optional值的类。 举例来说，如果一个人可能有也可能没有车，那么Person类内部的car变量就不应该声明为Car，遭遇某人没有车时不应该把null引用赋值给它，而是应该将其声明为Optional类型。 在代码中始终如一地使用Optional，能非常清晰地界定出变量值的缺失是结构上的问题，还是算法上的缺陷，抑或是数据中的问题。 引入Optional类的意图并非要消除每一个null引用。与此相反，它的目标是帮助更好地设计出普适的API，以便看到方法签名，就能了解它是否接受一个Optional的值。这种强制会积极的将变量从Optional中解包出来，直面缺失的变量值。 创建Optional对象 Optional.empty，创建一个空的Optional对象 1Optional&lt;Car&gt; optCar = Optional.empty(); Optional.of，依据一个非空值创建一个Optional对象 1Optional&lt;Car&gt; optCar = Optional.of(car); 如果car是一个null，这段代码会立即抛出一个NullPointerException，而不是等到试图访问car的属性值时才返回一个错误。 Optional.ofNullable，创建一个允许null值的Optional对象1Optional&lt;Car&gt; optCar = Optional.ofNullable(car); 如果car是null，那么得到的Optional对象就是个空对象。 不过get()方法在遭遇到空的Optional对象时也会抛出异常，所以不按照约定的方式使用它，又会让再度陷入由null引起的代码维护的梦魇。 使用map从Optional对象中提取和转换值map操作会将提供的函数应用于流的每个元素。你可以把Optional对象看成一种特殊的集合数据，它至多包含一个元素。 如果Optional包含一个值，那函数就将该值作为参数传递给map，对该值进行转换。如 果Optional为空，就什么也不做。 1234String name = null;if(insurance != null)&#123; name = insurance.getName();&#125; 优化 123Optional&lt;Insurance&gt; optInsurance = Optional.ofNullable(insurance); Optional&lt;String&gt; name = optInsurance.map(Insurance::getName); 使用flatMap链接Optional对象使用流时，flatMap方法接受一个函数作为参数，这个函数的返回值是另一个流。 这个方法会应用到流中的每一个元素，最终形成一个新的流。但是flagMap会用流的内容替换每个新生成的流。 12345public String getCarInsuranceName(Optional&lt;Person&gt; person) &#123; return person.flatMap(Person::getCar) .flatMap(Car::getInsurance) .map(Insurance::getName) .orElse("Unknown");&#125; 使用Optional解引用串接对象上例中，以Optional封装的Person入手，对其调用flatMap(Person::getCar)。 flatMap将某个Function作为参数，被传递给Optional封装的Person对象，对其进行转换。Function的具体表现是一个方法引用，即对Person对象的getCar方法进行调用。由于该方法返回一个Optional类型的对象，Optional内的Person也被转换成了这种对象的实例，结果就是一个两层的Optional对象，最终它们会被flagMap操作合并。 可以将这种合并操作简单地看成把两个Optional对象结合在一起，如果其中有一个对象为空，就构成一个空的Optional对象。如果你对一个空的Optional对象调用flatMap，结果不会发生任何改变， 返回值也是个空的Optional对象。 如果Optional封装了一个Person对象，传递给flapMap的Function，就会应用到Person上对其进行处理。这个例子中，由于Function的返回值已经是一个Optional对象，flapMap方法就直接将其返回。 如果调用链上的任何一个方法返回一个空的Optional，那么结果就为空，否则返回的值就是你期望的保险公司的名称。 如何读出这个值呢?毕竟最后得到的这个对象还是个Optional，它可能包含保险公司的名称，也可能为空。可以使用了一个名为orElse的方法，当Optional的值为空时，它会为其设定一个默认值。 无法序列化由于Optional类设计时就没特别考虑将其作为类的字段使用，所以它也并未实现Serializable接口。由于这个原因，如果用了某些要求序列化的库或者框架，在模型中使用Optional，有可能引发应用程序故障。 如果你一定要实现序列化的域模型，作为替代方案，建议像下面这个例子那样，提供一个能访问声明为Optional、变量值可能缺失的接口。 123456public class Person &#123; private Car car; public Optional&lt;Car&gt; getCarAsOptional()&#123; return Optional.ofNullable(car); &#125; &#125; 两个Optional对象的组合12345if (person.isPresent() &amp;&amp; car.isPresent())&#123; return Optional.of(findCheapestInsurance(person.get(), car.get())); &#125; else &#123; return Optional.empty();&#125; 以不解包的方式组合两个Optional对象 1return person.flatMap(p -&gt; car.map(c -&gt; findCheapestInsurance(p, c))); 使用filter剔除特定的值filter方法接受一个谓词作为参数。如果Optional对象的值存在，并且它符合谓词的条件，filter方法就返回其值;否则它就返回一个空的Optional对象。 123if(insurance != null &amp;&amp; "CambridgeInsurance".equals(insurance.getName()))&#123;System.out.println("ok");&#125; 优化 12optInsurance.filter(insurance -&gt; "CambridgeInsurance".equals(insurance.getName())) .ifPresent(x -&gt; System.out.println("ok")); 123456return person.filter(p -&gt; p.getAge() &gt;= minAge) .flatMap(Person::getCar) .flatMap(Car::getInsurance) .map(Insurance::getName) .orElse("Unknown");&#125; 用Optional封装可能为null的值1Object value = map.get("key"); 优化 1Optional&lt;Object&gt; value = Optional.ofNullable(map.get("key")); 1234return Optional.ofNullable(props.getProperty(name)) .flatMap(OptionalUtility::stringToInt) .filter(i -&gt; i &gt; 0) .orElse(0); 异常与Optional的对比12345try &#123; return Optional.of(Integer.parseInt(s));&#125; catch (NumberFormatException e) &#123; return Optional.empty();&#125; 建议将多个类似的方法封装到一个工具类中。 基础类型的Optional对象和避免使用基础类型 OptionalInt OptionalLong OptionalDouble 不推荐使用基础类型的Optional，因为基础类型的Optional不支持map、flatMap以及filter方法，而这些却是Optional类最有用的方法。 Optional类方法 get() 是这些方法中最简单但又最不安全的方法。如果变量存在，它直接返回封装的变量值，否则就抛出一个NoSuchElementException异常。所以，除非非常确定Optional变量一定包含值，否则不使用。此外，这种方式即便相对于嵌套式的null检查，也并未体现出多大的改进。 orElse(T other) 允许在Optional对象不包含值时提供一个默认值。 orElseGet(Supplier&lt;? extends T&gt; other) 是orElse方法的延迟调用版，Supplier方法只有在Optional对象不含值时才执行调用。如果创建默认值是件耗时费力的工作，应该考虑采用这种方式(借此提升程序的性能)，或者需要非常确定某个方法仅在 Optional为空时才进行调用，也可以考虑该方式(这种情况有严格的限制条件)。 orElseThrow(Supplier&lt;? extends X&gt; exceptionSupplier) 和get方法非常类似，它们遭遇Optional对象为空时都会抛出一个异常，但是使用orElseThrow你可以定制希望抛出的异常类型。 ifPresent(Consumer&lt;? super T&gt;) 能在变量值存在时执行一个作为参数传入的方法，否则就不进行任何操作。 of 将指定值用Optional封装之后返回，如果该值为null，则抛出一个NullPointerException异常。 ofNullable 将指定值用Optional封装之后返回，如果该值为null，则返回一个空的Optional对象。 flatMap 如果值存在，就对该值执行提供的mapping函数调用，返回一个 Optional 类型的值，否则就返回一个空的Optional对象 map 如果值存在，就对该值执行提供的mapping函数调用将指定值用Optional封装之后返回，如果该值为null，则返回一个空的 Optional对象。]]></content>
      <categories>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>Java8</tag>
        <tag>Lambda</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JVM调试命令]]></title>
    <url>%2Fposts%2F9582%2F</url>
    <content type="text"><![CDATA[GC日志打开GC日志 1-server -XX:+PrintGCTimeStamps -XX:+PrintGCDetails -Xloggc:./logs/gc.log jmap生成 java 程序的 dump 文件， 也可以查看堆内对象示例的统计信息、查看 ClassLoader 的信息以及 finalizer 队列。 命令1、jmap -histo[:live] 通过histo选项，打印当前java堆中各个对象的数量、大小。 如果添加了live，只会打印活跃的对象。 2、jmap -dump:[live,]format=b,file= 通过-dump选项，把java堆中的对象dump到本地文件，然后使用MAT进行分析。 如果添加了live，只会dump活跃的对象。 jmap -histo 19470 | jmap -histo:live 19470 3、jmap -heap 通过-heap选项，打印java堆的配置情况和使用情况，还有使用的GC算法。 jmap -heap 19470 4、jmap -finalizerinfo 通过-finalizerinfo选项，打印那些正在等待执行finalize方法的对象。 5、jmap -permstat 通过-permstat选项，打印java堆永久代的信息，包括class loader相关的信息,和interned Strings的信息。``` 实现原理通过jmap和jvm之间进行通信，有两种实现方式：attach 和 SA。 attach attach方式，简单来说就是客户端和服务端之间的通信，客户端发送请求，主要逻辑在服务端执行，jmap相当于客户端，JVM相当于服务端。 在JVM中，有一个叫”Attach Listener”的线程，专门负责监听attach的请求，并执行对应的操作。 客户端连接到目标JVM，向其发出一个类似“inspectheap”命令 目标JVM接收到命令，执行JVM内相关函数，将收集到的结果以文本形式返回 客户端接收到返回的文本并将其显示出来；SA 假如执行”jmap -heap 5409″，就不会使用attach方式实现了。 在参数解析中，如果参数是”-heap|-heap:format=b|-permstat|-finalizerinfo”中的一种，或者添加了”-F”，比如”jmap -histo -F 5409″，则使用SA的方式。 SA方式，和attach方式不同的是，相关的主要逻辑都在SA中实现，从JVM中获取数据即可。jps只列出系统中所有的 Java 应用程序。 -q：只输出进程 ID -m：输出传入 main 方法的参数 -l：输出完全的包名，应用主类名，jar的完全路径名 -v：输出jvm参数 -V：输出通过flag文件传递到JVM中的参数 jinfo可以用来查看正在运行的 java 应用程序的扩展参数，包括Java System属性和JVM命令行参数；也可以动态的修改正在运行的 JVM 一些参数。当系统崩溃时，jinfo可以从core文件里面知道崩溃的Java应用程序的配置信息。 jinfo 19470 输出当前 jvm 进程的全部参数和系统属性 参数说明pid 对应jvm的进程id executable core 产生core dump文件 [server-id@]remote server IP or hostname 远程的ip或者hostname，server-id标记服务的唯一性id option no option 输出全部的参数和系统属性 -flag name 输出对应名称的参数 -flag [+|-]name 开启或者关闭对应名称的参数 -flag name=value 设定对应名称的参数 -flags 输出全部的参数 -sysprops 输出系统属性 jstack进程所包含线程情况查询 (位于”jdk_home/bin”目录下)，可以实时监测系统资源占用与jvm运行情况。 jstack 19470 查看当前java进程的堆栈状态 参数说明：-l 长列表. 打印关于锁的附加信息,例如属于java.util.concurrent 的 ownable synchronizers列表. -F 当’jstack [-l] pid’没有相应的时候强制打印栈信息 -m 打印java和native c/c++框架的所有栈信息. -h | -help 打印帮助信息 pid 需要被打印配置信息的java进程id,可以用jps查询. jstatjstat命令可以查看堆内存各部分的使用量，以及加载类的数量。命令的格式如下： jstat [-命令选项] [vmid] [间隔时间/毫秒] [查询次数] // 命令语法结构：Usage: jstat -help|-options jstat - [-t] [-h] [ []]// 参数解释：Options — 选项，我们一般使用 -gcutil 查看gc情况vmid — VM的进程号，即当前运行的java进程号interval– 间隔时间，单位为秒或者毫秒count — 打印次数，如果缺省则打印无数次 S0 — Heap上的 Survivor space 0 区已使用空间的百分比S1 — Heap上的 Survivor space 1 区已使用空间的百分比E — Heap上的 Eden space 区已使用空间的百分比O — Heap上的 Old space 区已使用空间的百分比P — Perm space 区已使用空间的百分比YGC — 从应用程序启动到采样时发生 Young GC 的次数YGCT– 从应用程序启动到采样时 Young GC 所用的时间(单位秒)FGC — 从应用程序启动到采样时发生 Full GC 的次数FGCT– 从应用程序启动到采样时 Full GC 所用的时间(单位秒)GCT — 从应用程序启动到采样时用于垃圾回收的总时间(单位秒)//示例jstat -options -class -compiler -gc -gccapacity -gccause -gcmetacapacity -gcnew -gcnewcapacity -gcold -gcoldcapacity -gcutil -printcompilationjstat -class -t 19470Timestamp Loaded Bytes Unloaded Bytes Time6188.4 3898 7178.4 40 58.3 1.78 jstat -gcutil 19470 1000 5 S0 S1 E O M CCS YGC YGCT FGC FGCT GCT0.00 25.00 98.55 15.37 96.94 94.88 21 0.069 7 0.237 0.3060.00 25.00 99.59 15.37 96.94 94.88 21 0.069 7 0.237 0.3060.00 25.00 99.59 15.37 96.94 94.88 21 0.069 7 0.237 0.3060.00 25.00 100.00 15.37 96.94 94.88 21 0.069 7 0.237 0.306]]></content>
      <categories>
        <category>工具利器</category>
      </categories>
      <tags>
        <tag>Java8</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker安装Nginx及配置]]></title>
    <url>%2Fposts%2F65243%2F</url>
    <content type="text"><![CDATA[Docker安装123456789docker search nginx name docker.io/nginx OFFICIAL okdocker pull nginxdocker images nginxdocker run --name nginx-test -p 9803:80 -d nginx 说明： nginx-test 容器名称。 -d设置容器在在后台一直运行。 -p 端口进行映射，将本地 8081 端口映射到容器内部的 80 端口。测试： curl -l localhost:9803 Docker配置创建目录 1mkdir -p ./nginx/www ./nginx/logs ./nginx/conf www: 目录将映射为 nginx 容器配置的虚拟目录。 logs: 目录将映射为 nginx 容器的日志目录。 conf: 目录里的配置文件将映射为 nginx 容器的配置文件。 配置文件 12345docker psCONTAINER ID 988101b6dbcfdocker cp 988101b6dbcf:/etc/nginx/nginx.conf ./nginx/conf 拷贝容器内 Nginx 默认配置文件到本地当前目录下的 conf 目录，容器 ID 可以查看 docker ps 命令输入中的第一列：重启 123456789docker kill 988101b6dbcfdocker rm 988101b6dbcfdocker run --name nginx-test -p 9803:80 -d -v /home/xxx/nginx/www:/usr/share/nginx/html -v /home/xxx/nginx/conf/nginx.conf:/etc/nginx/nginx.conf -v /home/xxx/nginx/logs:/var/log/nginx nginxc7d0b0a20287e46b759ccd73fe6ec3072695f93900b3d04172f1f34bd0104766curl -l localhost:9803 Nginx配置123cd ./nginx/wwwvi index.html 修改首页 1234567891011 &lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt;&lt;meta charset=&quot;utf-8&quot;&gt;&lt;title&gt;welcome&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;h1&gt;hello&lt;/h1&gt; &lt;p&gt;world。&lt;/p&gt;&lt;/body&gt;&lt;/html&gt; 修改配置文件 12345vi /home/xxx/nginx/conf/nginx.confinclude /home/xxx/nginx/conf/conf.d/*.conf;cd conf.dvi default.conf 配置 12345678910111213141516171819server&#123; listen 80; server_name localhost; index index.html index.htm; root /home/cuipeijun/nginx/www;#站点目录 location /recommend &#123; proxy_pass http://recommend; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; &#125;&#125;upstream recommend &#123; server 172.16.25.70:9819; server 192.168.1.41:9804 backup;&#125; 配置说明upstream可以为每个设备设置状态值，这些状态值的含义分别如下： down：表示单前的server暂时不参与负载. weight：默认为1.weight越大，负载的权重就越大。 max_fails：允许请求失败的次数默认为1.当超过最大次数时，返回proxy_next_upstream 模块定义的错误. fail_timeout : max_fails次失败后，暂停的时间。 backup： 其它所有的非backup机器down或者忙的时候，请求backup机器。所以这台机器压力会最轻分配策略none（轮询） upstream按照轮询（默认）方式进行负载，每个请求按时间顺序逐一分配到不同的后端服务器，如果后端服务器down掉，能自动剔除。虽然这种方式简便、成本低廉。但缺点是：可靠性低和负载分配不均衡。weight（权重） 指定轮询几率，weight和访问比率成正比，用于后端服务器性能不均的情况。例如 server 192.168.61.22 weight = 6; # 60% 请求 server 192.168.61.23 weight = 4; # 40% 请求ip_hash（访问ip） 每个请求按访问ip的hash结果分配，这样每个访客固定访问一个后端服务器，可以解决session的问题。 配置只需要在upstream中加入ip_hash;即可。 12345upstream tomcats &#123; ip_hash; server 127.0.0.1:9001; server 127.0.0.1:9002;&#125;fair（第三方） 按后端服务器的响应时间来分配请求，响应时间短的优先分配。与weight分配策略类似。 12345upstream tomcats &#123; server 127.0.0.1:9001; server 127.0.0.1:9002; fair;&#125;url_hash（第三方） 和IP哈希类似，只不过针对请求的url进行hash（基于缓存的server，页面静态化）。模板123456789101112131415161718192021222324252627upstream tomcats &#123; server ip:8080; &#125;server &#123; listen 80; server_name www.xxx.com; location / &#123; proxy_pass http://tomcats; #Proxy Settings proxy_redirect off; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_next_upstream error timeout invalid_header http_500 http_502 http_503 http_504; proxy_max_temp_file_size 0; proxy_connect_timeout 90; proxy_send_timeout 90; proxy_read_timeout 90; proxy_buffer_size 4k; proxy_buffers 4 32k; proxy_busy_buffers_size 64k; proxy_temp_file_write_size 64k; &#125;&#125;]]></content>
      <categories>
        <category>架构</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[解决MySql死锁脚本]]></title>
    <url>%2Fposts%2F10641%2F</url>
    <content type="text"><![CDATA[12345678910111213#!/usr/bin/env bashtmp_file=/tmp/my_process_listHOST='xx-01'USER='xxx'PASS='xxxxxx'mysql -u $&#123;USER&#125; -p $&#123;PASS&#125; -P3306 --protocol=tcp -h $&#123;HOST&#125; mysql -e "show processlist" &gt; $&#123;tmp_file&#125;for l in `grep 'table level lock' $&#123;tmp_file&#125; | grep -v 'system user' | awk '&#123;print $1&#125;'`; do mysql -u $&#123;USER&#125; -p $&#123;PASS&#125; -P3306 --protocol=tcp -h $&#123;HOST&#125; mysql -e "kill $l;"done]]></content>
      <categories>
        <category>架构</category>
      </categories>
      <tags>
        <tag>死锁</tag>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hazelcast Client配置]]></title>
    <url>%2Fposts%2F354%2F</url>
    <content type="text"><![CDATA[最大value 单个k-v的操作本身不受数据字节大小限制 操作受最大堆内存-Xmx限制 操作受超时时间限制hazelcast.max.operation.timeout 12INFO HazelcastTest - size:273437KBINFO HazelcastTest - elapsed:62ms 数量、过期等限制 针对每个map均可限制1234567891011121314151617//限制instruments特定mapMapConfig mCfg = new MapConfig("instruments");//超时时间mCfg.setTimeToLiveSeconds(60);//节点备份数mCfg.setBackupCount(1);//删除策略mCfg.setEvictionPolicy(EvictionPolicy.LRU);//存储模式mCfg.setInMemoryFormat(InMemoryFormat.BINARY);MaxSizeConfig maxSizeConfig = new MaxSizeConfig();//最大数量maxSizeConfig.setSize(1000);//针对节点限制maxSizeConfig.setMaxSizePolicy(MaxSizeConfig.MaxSizePolicy.PER_NODE);mCfg.setMaxSizeConfig(maxSizeConfig); Map过期时间123456//ttlmyMap.put( "1", "John", 50, TimeUnit.SECONDS )//ttlmyMap.setTTL( "1", 50, TimeUnit.SECONDS )//ttl 50,maxIdle 40myMap.put( "1", "John", 50, TimeUnit.SECONDS, 40, TimeUnit.SECONDS ) time-to-live-seconds:存活时间，期间没有写请求，则到期删除；默认0，无过期max-idle-seconds:最大空闲时间，期间没有读和写请求，则到期删除 删除策略当map大小超过max-size时，启用eviction-policy。 NONE，忽略max-size LRU，最近最久未使用 LFU，最近最少使用 集群性能 -Xms128M -Xmx256M 2个节点 k:递增,value：1k client并发50 双节点puts平均为290/s，延迟为0.5ms自动扩充 基于广播 基于TCP-IP 基于Eureka 基于Zk 检索1234567891011Cache cache1 = new Cache(); topiccache1Cache1.setA("1"); cache1.setB("你好"); cache1.setC("大家好"); Gson gson = new Gson();Client.getInstance().putKV(cache1.getA(), Predicate p1 = Predicates.like("b", "%好%"); Predicate p2 = Predicates.like("c", "%大%"); Predicate predicate = Predicates.or(p1, p2); Collection&lt;HazelcastJsonValue&gt; peopleUnder21 = Client.getInstance().values(predicate); log.info(peopleUnder21.toString());]]></content>
      <categories>
        <category>架构</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>Hazelcast</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hazelcast性能评估]]></title>
    <url>%2Fposts%2F19102%2F</url>
    <content type="text"><![CDATA[基准测试基于benchmarking tool 123INFO Performance IntByteMapTestTotal throughput 100.00% 7,948,805 ops 128,179.66 ops/s Agent C_A1 100.00% 7,948,805 ops 128,179.66 ops/s 结论 int-int每秒可完成17W请求，并发线程10，随机读写，写概率0.1，读0.9 int-byte每秒13万请求，value最大2k，并发线程10，随机读写，写概率0.1，读0.9 客户端测试 serive为40服务器docker client为本地java 单线程写入对象1万次 多线程10，并发 结论 单线程时，puts:56/s，server并发处理 多线程10个时，puts:496/s，server并发处理 处理延迟,0.02ms 优势 基于Java开发，部署简单、无主从、自动扩展 基础java集合框架，可本地使用，解决分布式缓存问题 提供全局id、消息、队列、分布式锁等分布式服务常见工具 有manager-ui spring boot/cloud默认已集成 劣势 中文材料较少 基准测试方法下载simulator 下载安装包至服务器或本地 安装包：https://download.hazelcast.com/simulator/hazelcast-simulator-0.9.10-dist.tar.gz 源码：https://github.com/hazelcast/hazelcast-simulator.git 安装与测试 ./hazelcast-simulator-0.9.8/bin/simulator-wizard –install 测试是否成功。新建一个teminor，输入命令:simulator-wizard –help 执行123simulator-wizard --createWorkDir testscd tests./run 等待console输出结果 修改测试条件cat test.properties 123IntByteMapTest@class = com.hazelcast.simulator.tests.map.IntByteMapTestIntByteMapTest@threadCount = 10IntByteMapTest@putProb = 0.1 测试类下载源码可见，默认com.hazelcast.simulator.tests.map.IntIntMapTest 注意 测试模拟器自带Hazelcast，无需安装配置 本地不要启动Hazelcast，否则端口冲突，无法成功否则有以下错误:12FATAL [C_A1] Failed to start Worker: Failed to start WorkerFATAL [C_A1] Failed to start Worker: Failed to start Worker]]></content>
      <categories>
        <category>架构</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>Hazelcast</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker部署Hazelcast]]></title>
    <url>%2Fposts%2F39886%2F</url>
    <content type="text"><![CDATA[Hazelcast management-center123docker pull hazelcast/management-centerdocker run -d -p 8200:8080 hazelcast/management-center:latest 安装配置管理节点，监控和实时查看缓存情况 Hazelcast镜像单节点部署下载镜像 1docker pull hazelcast/hazelcast 启动 1docker run -d -e JAVA_OPTS="-Dhazelcast.local.publicAddress=192.168.1.40:5701 -Dhazelcast.rest.enabled=true -Xms128M -Xmx256M" -p 5701:5701 hazelcast/hazelcast 注意： hazelcast.rest.enabled=true，需要开启，不然管理节点连不上 docker需要后台启动服务-d，内部端口为5701 最好指定publicAddress且需要设置JVM大小 节点输出 123Members &#123;size:1, ver:1&#125; [ Member [192.168.1.40]:5701 - dbbe08e2-ed8c-4228-9cf8-a0ab0ae08632 this] Hazelcast镜像多节点multicast集群部署节点1： 1docker run -d -e JAVA_OPTS="-Dhazelcast.local.publicAddress=192.168.1.43:5701 -Dhazelcast.rest.enabled=true -Xms128M -Xmx256M" -e MANCENTER_URL="http://192.168.1.40:8200/hazelcast-mancenter" -p 5701:5701 hazelcast/hazelcast 节点2： 1docker run -d -e JAVA_OPTS="-Dhazelcast.local.publicAddress=192.168.1.43:5702 -Dhazelcast.rest.enabled=true -Xms128M -Xmx256M" -e MANCENTER_URL="http://192.168.1.40:8200/hazelcast-mancenter" -p 5702:5701 hazelcast/hazelcast 注意： 指定MANCENTER_URL管理节点地址 multicast广播必须为同一台集群，因为docker下广播必须本机容器才能连接 Hazelcast镜像多节点TCP-IP集群部署hazelcast.xml配置： 123456789101112131415 &lt;management-center enabled="true"&gt;http://192.168.1.40:8200/hazelcast-mancenter&lt;/management-center&gt;...&lt;port auto-increment="true" port-count="10"&gt;5701&lt;/port&gt;... &lt;multicast enabled="false"&gt; &lt;multicast-group&gt;224.2.2.3&lt;/multicast-group&gt; &lt;multicast-port&gt;54327&lt;/multicast-port&gt; &lt;/multicast&gt; &lt;tcp-ip enabled="true"&gt; &lt;interface&gt;192.168.1.40-45&lt;/interface&gt; &lt;member-list&gt; &lt;member&gt;192.168.1.40&lt;/member&gt; &lt;member&gt;192.168.1.43&lt;/member&gt; &lt;/member-list&gt; &lt;/tcp-ip&gt; 节点1 1docker run -d -e JAVA_OPTS="-Dhazelcast.config=/opt/hazelcast/config_ext/hazelcast.xml -Dhazelcast.local.publicAddress=192.168.1.40:5701 -Dhazelcast.rest.enabled=true -Xms128M -Xmx512M" -v /home/xxx:/opt/hazelcast/config_ext -p 5701:5701 hazelcast/hazelcast 节点2 1docker run -d -e JAVA_OPTS="-Dhazelcast.config=/opt/hazelcast/config_ext/hazelcast.xml -Dhazelcast.local.publicAddress=192.168.1.43:5701 -Dhazelcast.rest.enabled=true -Xms128M -Xmx512M" -v /home/xxx:/opt/hazelcast/config_ext -p 5701:5701 hazelcast/hazelcast 输出 1234Members &#123;size:2, ver:2&#125; [ Member [192.168.1.40]:5701 - cd40d155-d993-46a5-b07c-19f001c71f3c Member [192.168.1.43]:5701 - 34d0798c-37d0-42e8-88f0-1268eab9a90a this] 注意： 端口自增限制为10，即每个机器端口限制为5701-5711，以提高发现效率 multicast关闭，tcp-ip开启 限制interface，指定ip范围 指定member-list，指定集群成员 指定宿主机配置文件地址 配置登录management-center 打开地址：http://192.168.1.40:8200/hazelcast-mancenter 第一次设置初始化账户和密码，密码有格式要求 添加成员节点，即Change URL 输入Cluster Name and Password，即集群名和集群密码 输入Server UR，为Management Center URL，即管理系统地址；例如http://192.168.1.40:8200/hazelcast-mancenter 测试连接引入包pom.xml12345678910&lt;dependency&gt; &lt;groupId&gt;com.hazelcast&lt;/groupId&gt; &lt;artifactId&gt;hazelcast&lt;/artifactId&gt; &lt;version&gt;3.8.5&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.hazelcast&lt;/groupId&gt; &lt;artifactId&gt;hazelcast-client&lt;/artifactId&gt; &lt;version&gt;3.8.5&lt;/version&gt;&lt;/dependency&gt; client代码1234567891011121314151617181920212223242526272829303132333435363738@Slf4jpublic class HazelcastTest &#123; public static void main(String[] args) &#123; ClientConfig clientConfig = new ClientConfig(); //集群组名称 clientConfig.getGroupConfig().setName("dev"); //节点地址 clientConfig.getNetworkConfig().addAddress("192.168.1.40", "192.168.1.40:5702"); //客户端 HazelcastInstance client = HazelcastClient.newHazelcastClient(clientConfig); UserInfo userInfo = new UserInfo(); userInfo.setUserName("xxxx"); userInfo.setUserDesc("com.hazelcast.core.Hazelcast"); //map缓存 Map&lt;Integer, UserInfo&gt; userInfoMap = client.getMap("instruments"); //并发测试 Runnable runnable = () -&gt; &#123; long total = 10000; Stopwatch stopwatch = Stopwatch.createStarted(); for (int i = 0; i &lt; total; i++) &#123; //插入缓存 userInfoMap.put(i, userInfo); &#125; stopwatch.stop(); log.info("total:&#123;&#125;,elapsed:&#123;&#125;,qps:&#123;&#125;", total, stopwatch.elapsed(TimeUnit.MILLISECONDS), stopwatch.elapsed(TimeUnit.MILLISECONDS) / total); &#125;; ExecutorService executorService = Executors.newFixedThreadPool(10); int threadNum = 10; for (int i = 0; i &lt; threadNum; i++) &#123; executorService.submit(runnable); &#125; &#125;&#125;]]></content>
      <categories>
        <category>架构</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>Hazelcast</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java并发编程艺术 - 多线程状态]]></title>
    <url>%2Fposts%2F80%2F</url>
    <content type="text"><![CDATA[6种状态线程可以有如下6种状态: New (新创建) Runnable (可运行) Blocked (被阻塞) Waiting (等待) Timed waiting (计时等待) Terminated (被终止) 要确定一个线程的当前状态， 可调用 getState 方法。 新创建线程当用new操作符创建一个新线程时，如newThread(r)，该线程还没有开始运行。这意味着它的状态是new。 当一个线程处于新创建状态时，程序还没有开始运行线程中的代码。在线程运行之前还有一些基础工作要做。 可运行线程一旦调用start方法， 线程处于runnable状态。一个可运行的线桿可能正在运行也可能没有运行， 这取决于操作系统给线程提供运行的时间。 一旦一个线程开始运行，它不必始终保持运行。事实上，运行中的线程被中断，目的是为了让其他线程获得运行机会。线程调度的细节依赖于操作系统提供的服务。 抢占式调度系统给每一个可运行线程一个时间片来执行任务。当时间片用完，操作系统剥夺该线程的运行权，并给另一个线程运行机会。当选择下一个线程时，操作系统考虑线程的优先级。 现在所有的桌面以及服务器操作系统都使用抢占式调度。但是，像手机这样的小型设备可能使用协作式调度。在这样的设备中，一个线程只有在调用yield方法、或者被阻塞或等待时，线程才失去控制权。在具有多个处理器的机器上，每一个处理器运行一个线程， 可以有多个线程并行运行。 当然， 如果线程的数目多于处理器的数目， 调度器依然采用时间片机制。记住， 在任何给定时刻， 二个可运行的线程可能正在运行也可能没有运行(这就是为什 么将这个状态称为可运行而不是运行 。) 被阻塞线程和等待线程当线程处于被阻塞或等待状态时，它暂时不活动。它不运行任何代码且消耗最少的资源。直到线程调度器重新激活它。细节取决于它是怎样达到非活动状态的。 当一个线程试图获取一个内部的对象锁而该锁被其他线程持有，则该线程进人阻塞状态。当所有其他线程释放该锁，并且线程调度器允许本线程持有它的时候，该线程将变成非阻塞状态。 当线程等待另一个线程通知调度器一个条件时，它自己进入等待状态。在调用Object.wait方法或Thread.join方法，或者是等待Lock或Condition时，就会出现这种情况。实际上，被阻塞状态与等待状态是有很大不同的。 有几个方法有一个超时参数。 调用它们导致线程进人计时等待(timed waiting)状态。这一状态将一直保持到超时期满或者接收到适当的通知。带有超时参数的方法有 Thread.sleep 和Object.wait、Thread.join、Lock,tryLock 以及Condition.await 的计时版。 线程可以具有的状态以及从一个状态到另一个状态可能的转换。当一个线程被阻塞或等待时(或终止时，) 另一个线程被调度为运行状态。当一个线程被重新激活(例如，因为超时期满或成功地获得了一个锁)，调度器检查它是否具有比当前运行线程更高的优先级。如果是这样，调度器从当前运行线程中挑选一个，剥夺其运行权，选择一个新的线程运行。 被终止的线程线程因如下两个原因之一而被终止: 因为run方法正常退出而自然死亡。 因为一个没有捕获的异常终止了run方法而意外死亡。]]></content>
      <categories>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>Java并发编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java并发编程艺术 - Join、Yield和Sleep]]></title>
    <url>%2Fposts%2F36650%2F</url>
    <content type="text"><![CDATA[Joinjoin() 的作用：让“主线程”等待“子线程”结束之后才能继续运行。 son.join()被调用的地方是发生在“Father主线程”中，但是son.join()是通过“子线程son”去调用的join()，父线程调用wait()的作用是让“当前线程”等待，而这里的“当前线程”是指当前在CPU上运行的线程。所以，虽然是调用子线程的wait()方法，但是它是通过“主线程”去调用的；所以，休眠的是主线程，而不是“子线程”！ 线程join方法1234public final void join() throws InterruptedException &#123; //调用父线程 join(0);&#125; 被调用的父线程12345678910111213141516171819202122232425262728public final synchronized void join(long millis)throws InterruptedException &#123; long base = System.currentTimeMillis(); long now = 0; if (millis &lt; 0) &#123; throw new IllegalArgumentException("timeout value is negative"); &#125; if (millis == 0) &#123; //父线程若激活，则一直等待被唤醒 while (isAlive()) &#123; wait(0); &#125; &#125; else &#123; //条件循环确认，即使被唤醒 while (isAlive()) &#123; long delay = millis - now; //等待超时退出 if (delay &lt;= 0) &#123; break; &#125; //等待唤醒 wait(delay); now = System.currentTimeMillis() - base; &#125; &#125;&#125; Demo12345678910111213141516public static void main(String[] args) throws InterruptedException &#123; AtomicInteger atomicInteger = new AtomicInteger(0); Runnable runnable = () -&gt; &#123; do &#123; log.info(atomicInteger.get() + "- run"); &#125; while (atomicInteger.incrementAndGet() &lt; 10); log.info(atomicInteger.get() + "- join"); &#125;; Thread thread = new Thread(runnable); thread.start(); //阻塞，等待子线程执行 thread.join(); log.info(atomicInteger.get() + "- end");&#125; 执行结果 1234567891011120- run1- run2- run3- run4- run5- run6- run7- run8- run9- run10- join10- end Yield1234static void yield( )导致当前执行线程处于让步状态。如果有其他的可运行线程具有至少与此线程同样高的优先级，那么这些线程接下来会被调度。注意，这是一个静态方法。`当前线程暂停，给予其他相同优先级或者更高优先级线程执行机会，但不会释放锁`。 Sleepsleep()方法需要指定等待的时间，它可以让当前正在执行的线程在指定的时间内暂停执行，进入阻塞状态，该方法既可以让其他同优先级或者高优先级的线程得到执行的机会，也可以让低优先级的线程得到执行机会。 但是sleep()方法不会释放“锁标志”，也就是说如果有synchronized同步块，其他线程仍然不能访问共享数据。 区别 sleep 和yield都不会释放对象的锁，都会导致当前线程等待。 sleep具有更大的灵活性，可以指定等待时间，可以唤醒其他更低优先级的线程，会抛出异常；yield只能唤醒同等优先级或者更高优先级的线程，不会给更低优先级线程执行机会，不会抛出异常。 yield,sleep都不会释放对象的锁， wait会释放对象的锁。如果不释放对象的锁，其他线程就没办法执行同步的代码。]]></content>
      <categories>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>Java并发编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java并发编程艺术 - 管道输入和输出流]]></title>
    <url>%2Fposts%2F18201%2F</url>
    <content type="text"><![CDATA[Java管道管道连接输入流和输出流。 管道I/O基于生产者 - 消费者模式，其中生产者产生数据，而消费者消费数据。在管道I/O中，创建两个流代表管道的两端。 PipedOutputStream对象表示流的一端，PipedInputStream对象则表示流的另一端。使用两个对象的connect()方法连接两端。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384@Slf4jpublic class PipedStreamTest &#123; public static void main(String[] args) throws InterruptedException &#123; PipedStreamReceive pipedStreamReceive1 = new PipedStreamReceive("receive1"); //指定输入管道 PipedStreamSend pipedStreamSend1 = new PipedStreamSend("send1", pipedStreamReceive1.pipedInputStream); Thread thread1 = new Thread(pipedStreamSend1.runnable); Thread thread2 = new Thread(pipedStreamReceive1.runnable); thread1.start(); //等先发一下 Thread.sleep(5000); thread2.start(); &#125; @Data public static class PipedStreamSend &#123; //初始化 private PipedOutputStream pipedOutputStream = new PipedOutputStream(); private PipedInputStream pipedInputStream; //消息内容 private AtomicInteger num = new AtomicInteger(0); //输入流管道标识 private String name; public PipedStreamSend(String name, PipedInputStream pipedInputStream) &#123; this.name = name; this.pipedInputStream = pipedInputStream; &#125; private Runnable runnable = () -&gt; &#123; try &#123; //连接输入管道 pipedOutputStream.connect(pipedInputStream); while (true) &#123; //写入流 pipedOutputStream.write(num.incrementAndGet()); //刷新缓冲 pipedOutputStream.flush(); log.info("name:&#123;&#125;,num:&#123;&#125;", this.name, this.num.get()); try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125;; &#125; @Data public static class PipedStreamReceive &#123; //初始化 private PipedInputStream pipedInputStream = new PipedInputStream(); //输入流管道标识 private String name; public PipedStreamReceive(String name) &#123; this.name = name; &#125; private Runnable runnable = () -&gt; &#123; try &#123; int num; //读取流 while ((num = pipedInputStream.read()) != -1) &#123; log.info("name:&#123;&#125;,num:&#123;&#125;", name, num); &#125; &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125;; &#125;&#125; 执行结果 123456789101112name:send1,num:1name:send1,num:2name:send1,num:3name:send1,num:4name:send1,num:5name:receive1,num:1name:receive1,num:2name:receive1,num:3name:receive1,num:4name:receive1,num:5name:receive1,num:6name:send1,num:6 优缺点优点: 创建管道输出流PipedOutputStream pos和管道输入流PipedInputStream pis 将pos和pis匹配，pos.connect(pis); 将pos赋给信息输入线程，pis赋给信息获取线程，就可以实现线程间的通讯了 缺点: 管道流只能在两个线程之间传递数据 管道流只能实现单向发送，如果要两个线程之间互通讯，则需要两个管道流 总结作为线程通讯方式之一，可以看到管道流使用起来很方便，但是制约也很大，具体使用要看实际的需求，如果项目中只有两个线程持续传递消息，那用管道流也很方便，如果项目中有很多个线程之间需要通讯，那还是用共享变量的方式来传递消息比较方便。]]></content>
      <categories>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>Java并发编程</tag>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java并发编程艺术 - 多线程wait和notify]]></title>
    <url>%2Fposts%2F48047%2F</url>
    <content type="text"><![CDATA[等待/通知机制等待/通知机制，是指一个线程A调用了对象O的wait()方法进入等待状态，而另一个线程B调用了对象O的notify()或者notifyAll()方法，线程A收到通知后从对象O的wait()方法返回，进而执行后续操作。 上述两个线程通过对象O来完成交互，而对象上的wait()和notify/notifyAll()的关系就如同开关信号一样，用来完成等待方和通知方之间的交互工作。 利用wait和notify进行交替执行12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758public class ThreadWaitAndNotify &#123; public static void main(String[] args) throws InterruptedException &#123; //对象锁标记 Object lock = new Object(); Runner runner1 = new Runner(lock, "runner1"); Runner runner2 = new Runner(lock, "runner2"); Thread thread1 = new Thread(runner1.runnable); Thread thread2 = new Thread(runner2.runnable); thread1.start(); Thread.sleep(100); thread2.start(); &#125; @Slf4j public static class Runner &#123; //全局自增 private static AtomicInteger num = new AtomicInteger(0); private Object lock; private String name; public Runner(Object lock, String name) &#123; this.lock = lock; this.name = name; &#125; //运行 Runnable runnable = () -&gt; &#123; //先获取锁，才能有锁状态变更 synchronized (lock) &#123; while (true) &#123; //首次：第一个线程为奇数，打印后等待；第二个线程为偶数，打印后通知第一个线程 num.incrementAndGet(); //等待唤醒 try &#123; if (num.get() % 2 == 1) &#123; log.info("name:&#123;&#125;,num:&#123;&#125;", this.name, num.get()); //奇数等待偶数放行通知 lock.wait(); lock.notify(); &#125; else if (num.get() % 2 == 0) &#123; log.info("name:&#123;&#125;,num:&#123;&#125;", this.name, num.get()); //偶数放行，等待奇数执行 lock.notify(); lock.wait(); &#125; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125;; &#125;&#125; 交替执行结果 12345678910$Runner - name:runner1,num:1$Runner - name:runner2,num:2$Runner - name:runner1,num:3$Runner - name:runner2,num:4$Runner - name:runner1,num:5$Runner - name:runner2,num:6$Runner - name:runner1,num:7$Runner - name:runner2,num:8$Runner - name:runner1,num:9$Runner - name:runner2,num:10 锁池和等待池每个同步对象都有自己的锁池和等待池。 锁池假设线程A已经拥有了某个对象(注意:不是类)的锁，而其它的线程想要调用这个对象的某个synchronized方法(或者synchronized块)，由于这些线程在进入对象的synchronized方法之前必须先获得该对象的锁的拥有权，但是该对象的锁目前正被线程A拥有，所以这些线程就进入了该对象的锁池中。 等待池假设一个线程A调用了某个对象的wait()方法，线程A就会释放该对象的锁(因为wait()方法必须出现在synchronized中，这样自然在执行wait()方法之前线程A就已经拥有了该对象的锁)，同时线程A就进入到了该对象的等待池中。如果另外的一个线程调用了相同对象的notifyAll()方法，那么处于该对象的等待池中的线程就会全部进入该对象的锁池中，准备争夺锁的拥有权。如果另外的一个线程调用了相同对象的notify()方法，那么仅仅有一个处于该对象的等待池中的线程(随机)会进入该对象的锁池. notify和notifyAll适用场景如上例，使用notify且2个runnner，可认为是一个生产者一个消费者的情况下，生产和消费有条不紊的运行，没有任何问题。 线程调用了wait()方法，便会释放锁，并进入等待池中，不会参与锁的竞争 调用notify()后，等待池中的某个线程(只会有一个)会进入该对象的锁池中参与锁的竞争，若竞争成功，获得锁，竞争失败，继续留在锁池中等待下一次锁的竞争。 调用notifyAll()后，等待池中的所有线程都会进入该对象的锁池中参与锁的竞争。 notify适用于所有等待的线程都是对等的（或者说唤醒顺序对其执行任务无影响），或者适用于本来就只有一个等待线程的场景。 只唤醒其它等待的消费者线程中的一个，如果改成notfiyAll的话就让其它线程被唤醒后立刻进入BLOCKED状态，增加了CPU的开销。 notfiyAll适用于等待的线程有不同的目标，可以并行执行的场景。这样才不至于使所有线程被唤醒后又进入到BLOCKED状态。]]></content>
      <categories>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>Java并发编程</tag>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java并发编程艺术 - 线程终结]]></title>
    <url>%2Fposts%2F52791%2F</url>
    <content type="text"><![CDATA[中断状态是线程的一个标识位，而中断操作是一种简便的线程间交互方式，而这种交互方式最适合用来取消或停止任务。 除了中断以外，还可以利用一个boolean变量来控制是否需要停止任务并终止该线程。 2种终结方式1234567891011121314151617181920212223242526272829303132333435363738394041424344454647public class ThreadShutdown &#123; public static void main(String[] args) throws InterruptedException &#123; Runner runner1 = new Runner("Runner1"); Thread thread1 = new Thread(runner1.runnable); thread1.start(); //中断方式1 Thread.sleep(1); thread1.interrupt(); Runner runner2 = new Runner("Runner2"); Thread thread2 = new Thread(runner2.runnable); thread2.start(); Thread.sleep(1); //中断方式2 runner2.shutdown(); &#125; @Slf4j public static class Runner &#123; //关闭标记 private AtomicBoolean shutdown = new AtomicBoolean(); //自增 private AtomicInteger num = new AtomicInteger(0); private String name = "Runner"; //运行 Runnable runnable = () -&gt; &#123; //手动关闭 while (!shutdown.get() &amp;&amp; !Thread.currentThread().isInterrupted()) &#123; num.incrementAndGet(); &#125; log.info("name:&#123;&#125;,end:&#123;&#125;", name, num.get()); &#125;; public Runner(String name) &#123; this.name = name; &#125; //关闭 public void shutdown() &#123; shutdown.set(true); &#125; &#125;&#125; 执行结果12[Thread-0] INFO ThreadShutdown$Runner - name:Runner1,end:4361[Thread-1] INFO ThreadShutdown$Runner - name:Runner2,end:64698 main线程通过中断操作和shutdown()方法均可使Runner得以终止。 这种通过标识位或者中断操作的方式能够使线程在终止时有机会去清理资源，而不是武断地将线程停止，因此这种终止线程的做法显得更加安全和优雅。]]></content>
      <categories>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>Java并发编程</tag>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java并发编程艺术 - 线程中断]]></title>
    <url>%2Fposts%2F45493%2F</url>
    <content type="text"><![CDATA[中断可以理解为线程的一个标识位属性，它表示一个运行中的线程是否被其他线程进行了中断操作。中断好比其他线程对该线程打了个招呼，其他线程通过调用该线程的interrupt()方法对其进行中断操作。 12345678910111213141516171819202122232425262728293031public static void main(String[] args) &#123; AtomicInteger atomicInteger = new AtomicInteger(0); Runnable runnable = () -&gt; &#123; while (true) &#123; atomicInteger.incrementAndGet(); try &#123; //阻塞cpu Thread.sleep(1000); if (atomicInteger.get() &gt; 5) &#123; //中断信号 Thread.currentThread().interrupt(); &#125; &#125; catch (InterruptedException e) &#123; e.printStackTrace(); //异常后的中断标记 System.out.println(Thread.currentThread().isInterrupted() + "-" + atomicInteger.get()); &#125; //输出中断标记 System.out.println(Thread.currentThread().isInterrupted() + "-" + atomicInteger.get()); &#125; &#125;; Thread thread = new Thread(runnable); //就绪，并行；不能直接使用run，run是串行 thread.start(); &#125; 输出 1234567891011false-1false-2false-3false-4false-5true-6java.lang.InterruptedException: sleep interrupted at java.lang.Thread.sleep(Native Method) at ThreadInterrupt.lambda$main$0(ThreadInterrupt.java:19) at java.lang.Thread.run(Thread.java:748)false-7 线程通过检查自身是否被中断来进行响应，线程通过方法isInterrupted()来进行判断是否被中断，也可以调用静态方法Thread.interrupted()对当前线程的中断标识位进行复位true-6。如果该线程已经处于终结状态，即使该线程被中断过，在调用该线程对象的isInterrupted()时依旧会返回false。 从上面false-7可以看到，抛出InterruptedException的方法，Java虚拟机会先将该线程的中断标识位清除，然后抛出InterruptedException，此时调用isInterrupted()方法将会返回false。 interrupt有两个非常类似的方法，interrupted 和 islnterrupted。Interrupted 方法是一个静态方法， 它检测当前的线程是否被中断。 而且， 调用 interrupted 方法会清除该线程的中断状态。另一方面，islnterrupted 方法是一个实例方法，可用来检验是否有线程被中断。调用这个方法不会改变中断状态。 123456789void interrupt()实例方法，针对线程对象。向线程发送中断请求。线程的中断状态将被设置为 true。如果目前该线程被一个sleep调用阻塞，那么，InterruptedException 异常被抛出。•static boolean interrupted()静态方法，针对当前线程。测试当前线程（即正在执行这一命令的线程）是否被中断。注意，这是一个静态方法。这一调用会产生副作用—它将当前线程的中断状态重置为 false。• boolean islnterrupted()实例方法，针对线程对象。测试线程是否被终止。不像静态的中断方法，这一调用不改变线程的中断状态。•static Thread currentThread()返回代表当前执行线程的 Thread 对象。 扩展当对一个线程调用interrupt方法时，线程的中断状态将被置位。这是每一个线程都具有的 boolean标志。每个线程都应该不时地检査这个标志，以判断线程是否被中断。 要想弄清中断状态是否被置位，首先调用静态的 Thread.currentThread 方法获得当前线程，然后调用 islnterrupted 方法： 1234while (!Thread.currentThread().islnterrupted() &amp;&amp; more work to do)&#123;do more work&#125; 但是，如果线程被阻塞，就无法检测中断状态。这是产生 InterruptedExceptioii 异常的地方。当在一个被阻塞的线程（调用 sleep 或 wait) 上调用 interrupt 方法时，阻塞调用将会被Interrupted Exception 异常中断。 中断一个线程不过是引起它的注意。被中断的线程可以决定如何响应中断。某些线程是如此重要以至于应该处理完异常后， 继续执行，而不理会中断。这种线程的 run 方法具有如下形式： 12345678910111213Runnable r = () -&gt; &#123; try&#123; while (!Thread.currentThread().islnterrupted0 &amp;&amp; more work to do)&#123; do more work Thread,sleep(delay); &#125; &#125;catch(InterruptedException e)&#123;// thread was interr叩ted during sleep or wait &#125;finally&#123; cleanup, ifrequired &#125;// exiting the run method terminates the thread&#125;； 如果在每次工作迭代之后都调用 sleep 方法（或者其他的可中断方法)islnterrupted 检测既没有必要也没有用处。如果在中断状态被置位时调用 sleep 方法，它不会休眠。相反，它将清除这一状态并拋出 IntemiptedException。因此,如果你的循环调用 sleep，不会检测中断状态。]]></content>
      <categories>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>Java并发编程</tag>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java并发编程艺术 - 多线程构造和启动]]></title>
    <url>%2Fposts%2F58008%2F</url>
    <content type="text"><![CDATA[构造线程在运行线程之前首先要构造一个线程对象，线程对象在构造的时候需要提供线程所需要的属性，如线程所属的线程组、线程优先级、是否是Daemon线程等信息。 线程启动线程对象在初始化完成之后，调用start()方法就可以启动这个线程。 线程start()方法的含当前线程（即parent线程）同步告知Java虚拟机，只要线程规划器空闲，应立即启动调用()方法的线程。 注意 启动一个线程前，最好为这个线程设置线程名称，因为这样在使用jstack分析或者进行问题排查时，就会给开发人员提供一些提示，自定义的线程最好能够起个名字。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152public class ThreadTest &#123; Runnable target; char[] name; boolean daemon; int priority; public Thread init(Runnable target, String name) &#123; if (name == null) &#123; throw new NullPointerException("name cannot be null"); &#125; // 当前线程就是该线程的父线程 Thread parent = currentThread(); // 将daemon、priority属性设置为父线程的对应属性 this.daemon = parent.isDaemon(); this.priority = parent.getPriority(); this.name = name.toCharArray(); this.target = target; //构造线程组，便于统一管控 ThreadGroup g = new ThreadGroup(name + "Group"); g.setDaemon(daemon); g.setMaxPriority(priority); //构造线程 Thread thread = new Thread(g, target, name); return thread; &#125; public void run(Thread thread) &#123; //处于就绪（可运行）状态，并没有运行，一旦得到cpu时间片，就开始执行相应线程的run()方法 thread.start(); //run()就和普通的成员方法一样，可以被重复调用 //thread.run(); &#125; public static void main(String[] args) &#123; //执行方法 Runnable runnable = () -&gt; &#123; System.out.println("Test"); &#125;; ThreadTest threadTest = new ThreadTest(); while (true) &#123; threadTest.run(threadTest.init(runnable, "Test")); &#125; &#125;&#125; 实现并启动线程有两种方法 写一个类继承自Thread类，重写run方法。用start方法启动线程 写一个类实现Runnable接口，实现run方法。用new Thread(Runnable target).start()方法来启动 start()和run() start启动线程，无需等待run方法体代码执行完毕，可以直接继续执行下面的代码；start()方法来启动一个线程， 这时此线程是处于就绪状态， 并没有运行。 然后通过此Thread类调用方法run()来完成其运行操作的， 这里方法run()称为线程体，它包含了要执行的这个线程的内容， Run方法运行结束， 此线程终止。然后CPU再调度其它线程。 run方法当作普通方法的方式调用。程序还是要顺序执行，要等待run方法体执行完毕后，才可继续执行下面的代码。]]></content>
      <categories>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>Java并发编程</tag>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Maven自定义打包脚本]]></title>
    <url>%2Fposts%2F26061%2F</url>
    <content type="text"><![CDATA[利用Maven脚本，实现以下需求: 将第三方lib单独打包 将脚本单独打包 将执行jar单独打包 将配置文件单独打包 自动关闭和启动进程 assembly目录123456789101112131415161718192021222324252627282930313233343536373839404142434445464748&lt;assembly&gt; &lt;id&gt;bin&lt;/id&gt; &lt;formats&gt; &lt;format&gt;zip&lt;/format&gt; &lt;/formats&gt; &lt;dependencySets&gt; &lt;dependencySet&gt; &lt;!--不使用项目的artifact，第三方jar不要解压，打包进zip文件的lib目录--&gt; &lt;useProjectArtifact&gt;false&lt;/useProjectArtifact&gt; &lt;outputDirectory&gt;lib&lt;/outputDirectory&gt; &lt;unpack&gt;false&lt;/unpack&gt; &lt;/dependencySet&gt; &lt;/dependencySets&gt; &lt;fileSets&gt; &lt;!-- 把项目脚本文件，打包进zip文件的根目录 --&gt; &lt;fileSet&gt; &lt;directory&gt;$&#123;project.basedir&#125;/bin&lt;/directory&gt; &lt;outputDirectory&gt;&lt;/outputDirectory&gt; &lt;includes&gt; &lt;include&gt;*.sh&lt;/include&gt; &lt;/includes&gt; &lt;/fileSet&gt; &lt;!-- 把配置文件，打包进zip文件的config目录 --&gt; &lt;fileSet&gt; &lt;directory&gt;$&#123;project.basedir&#125;/src/main/resources&lt;/directory&gt; &lt;outputDirectory&gt;config&lt;/outputDirectory&gt; &lt;includes&gt; &lt;include&gt;**/*&lt;/include&gt; &lt;include&gt;*.xml&lt;/include&gt; &lt;include&gt;*.properties&lt;/include&gt; &lt;include&gt;*.yml&lt;/include&gt; &lt;include&gt;*.key&lt;/include&gt; &lt;/includes&gt; &lt;/fileSet&gt; &lt;!-- 把jar，打进zip文件的根目录 --&gt; &lt;fileSet&gt; &lt;directory&gt;$&#123;project.build.directory&#125;&lt;/directory&gt; &lt;outputDirectory&gt;&lt;/outputDirectory&gt; &lt;includes&gt; &lt;include&gt;*.jar&lt;/include&gt; &lt;/includes&gt; &lt;/fileSet&gt; &lt;/fileSets&gt;&lt;/assembly&gt; bin目录123456789101112131415#!/bin/bashset -xcat xx.pid | xargs kill -9sleep 1nohup java -jar xx.jar &gt;nohup.log 2&gt;&amp;1 &amp;pid=$!echo $pid &gt; xx.pidtail -200f nohup.info 12345678910111213141516171819202122232425262728293031323334353637&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;executions&gt; &lt;execution&gt; &lt;goals&gt; &lt;goal&gt;repackage&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;!-- The configuration of maven-assembly-plugin --&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-assembly-plugin&lt;/artifactId&gt; &lt;version&gt;3.1.0&lt;/version&gt; &lt;!-- The configuration of the plugin --&gt; &lt;configuration&gt; &lt;descriptors&gt; &lt;!-- 配置 assembly 的路径 --&gt; &lt;descriptor&gt;assembly/assembly.xml&lt;/descriptor&gt; &lt;/descriptors&gt; &lt;/configuration&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;make-assembly&lt;/id&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;single&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt;]]></content>
      <categories>
        <category>工具利器</category>
      </categories>
      <tags>
        <tag>Maven</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java Collection Sort之IllegalArgumentException]]></title>
    <url>%2Fposts%2F63757%2F</url>
    <content type="text"><![CDATA[java.lang.IllegalArgumentException: Comparison method violates its general contract!在 JDK 7 版本以上， Comparator 要满足自反性，传递性，对称性，不然Arrays.sort、Collections.sort会报 IllegalArgumentException 异常。 说明：1 ） 自反性： x ， y 的比较结果和 y ， x 的比较结果相反。2 ） 传递性： x &gt; y , y &gt; z ,则 x &gt; z 。3 ） 对称性： x = y ,则 x , z 比较结果和 y ， z 比较结果相同。 反例： 下例中没有处理相等的情况，实际使用中可能会出现异常 123456new Comparator&lt;Student&gt;() &#123; @Override public int compare(Student o1, Student o2) &#123; return o1.getId() &gt; o2.getId() ? 1 : -1; &#125;&#125; 正例: 12345678910111213/** * 基于某种 Comparable 接口实现一个关键码类，并将所有通常的比较方法封装起来，以支持关键码之间的比较。 */public interface Comparator &#123; /** * 若a&gt;（=或&lt;）b，返回正数、零或负数 * * @param a * @param b * @return */ public int compare(Object a, Object b);&#125;]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Sort</tag>
        <tag>Comparator</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java双份对象数据热切换]]></title>
    <url>%2Fposts%2F42352%2F</url>
    <content type="text"><![CDATA[1234567//当前副本public List&lt;String&gt; r1 = null;//第二个副本public List&lt;String&gt; r2 = null;public AtomicBoolean replicationIsEmpty = new AtomicBoolean(); 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051private void initCurrent() &#123; r1 = new ArrayList&lt;String&gt;(10);&#125;private void initReplication() &#123; r2 = new ArrayList&lt;String&gt;(10);&#125;/** * 更新数据至副本，同时切换副本状态 * * @param keys */private void addKeys(List&lt;String&gt; keys) &#123; //replicationIsEmpty为true，表示可用 if (replicationIsEmpty.get()) &#123; r2.addAll(keys); replicationIsEmpty.set(false); try &#123; //等其他正在引用该数据方法处理完成 Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; initCurrent(); &#125; else &#123; r1.addAll(keys); //先改状态，运行两份数据并存 replicationIsEmpty.set(true); try &#123; //等其他正在引用该数据方法处理完成 Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; //后清空 initReplication(); &#125;&#125;/** * 根据副本状态，返回引用对象 * * @return */private List&lt;String&gt; getIdList() &#123; if (!replicationIsEmpty.get()) &#123; return r2; &#125; else &#123; return r1; &#125;&#125;]]></content>
      <categories>
        <category>架构</category>
      </categories>
      <tags>
        <tag>数据切换</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[WatchService监控目录和文件变化]]></title>
    <url>%2Fposts%2F34381%2F</url>
    <content type="text"><![CDATA[两种监控文件和目录方式Commons-io 在Apache的Commons-io提供文件的监控功能。 由文件监控类FileAlterationMonitor中的线程不停的扫描文件观察器FileAlterationObserver。 如果有文件的变化，则根据相关的文件比较器，判断文件时新增，还是删除，还是更改。（默认为1000毫秒执行一次扫描） WatchService Java1.7中提供了NIO WatchService来监控系统中文件的变化。 该监控是基于操作系统的文件系统监控器，可以监控系统是所有文件的变化，这种监控是无需遍历、无需比较的，是一种基于信号收发的监控。 整个监控目录文件操作的流程大致如下： 获取 WatchService 注册指定目录的监视器 等待目录下的文件发生变化 对发生变化的文件进行操作 WatchService文件监控1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283@Slf4jpublic class FileWatchTask implements Runnable &#123; private String fileDirectory; private List&lt;String&gt; monitorFileNameList = new ArrayList&lt;&gt;(); private ParseIF parseIF; /** * @param fileDirectory 监控目录 * @param monitorFileNameList 监控文件名 * @param parseIF 处理函数 */ public FileWatchTask(String fileDirectory, List&lt;String&gt; monitorFileNameList, ParseIF parseIF) &#123; this.fileDirectory = fileDirectory; if (monitorFileNameList != null) &#123; this.monitorFileNameList = monitorFileNameList; &#125; this.parseIF = parseIF; &#125; @Override public void run() &#123; WatchService service = null; try &#123; //获取当前文件系统的监控对象 service = FileSystems.getDefault().newWatchService(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; try &#123; //获取文件目录下的Path对象注册到 watchService中。 //监听的事件类型，有创建，删除，以及修改 Paths.get(fileDirectory) .register(service, StandardWatchEventKinds.ENTRY_CREATE, StandardWatchEventKinds.ENTRY_DELETE, StandardWatchEventKinds.ENTRY_MODIFY); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; while (true) &#123; //WatchKey 类代表了这个监听服务的注册，可以用它来获取事件的各个属性。 WatchKey key = null; try &#123; //获取可用key.没有可用的就wait key = service.take(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; for (WatchEvent&lt;?&gt; event : key.pollEvents()) &#123; log.warn(event.context() + "-" + event.kind() + "-" + event.count()); final WatchEvent.Kind&lt;?&gt; kind = event.kind(); if (kind == StandardWatchEventKinds.OVERFLOW) &#123; continue; &#125; // get the filename for the event final WatchEvent&lt;Path&gt; watchEventPath = (WatchEvent&lt;Path&gt;) event; final Path fileName = watchEventPath.context(); if (monitorFileNameList.stream().noneMatch(e -&gt; e.equals(fileName.getFileName().toString()))) &#123; continue; &#125; //创建事件 if (kind == StandardWatchEventKinds.ENTRY_CREATE) &#123; parseIF.parse(FileStatus.CREATE); &#125; //修改事件 if (kind == StandardWatchEventKinds.ENTRY_MODIFY) &#123; parseIF.parse(FileStatus.MODIFY); &#125; //删除事件 if (kind == StandardWatchEventKinds.ENTRY_DELETE) &#123; parseIF.parse(FileStatus.DELETE); &#125; &#125; //重置，这一步很重要，否则当前的key就不再会获取将来发生的事件 boolean valid = key.reset(); //失效状态，退出监听 if (!valid) &#123; break; &#125; &#125; &#125;&#125; 文件类型123public enum FileStatus &#123; CREATE, DELETE, MODIFY&#125; 处理函数@FunctionalInterfacepublic interface ParseIF { boolean parse(FileStatus type);} 线程池123456789101112131415161718192021222324252627282930313233/** * 目录监控 * * @return */private synchronized boolean monitor() &#123; if (monitor) &#123; return false; &#125; monitor = true; //因为是线程安全的所以可以放入ThreadPool中使用 ExecutorService cachedThreadPool = newFixedThreadPool(1); //监控文件 List&lt;String&gt; monitorFileNameList = Arrays.asList("a.txt", "b.txt"); //处理 ParseIF parseIF = (type) -&gt; &#123; if (type == FileStatus.CREATE || type == FileStatus.MODIFY) &#123; reload(filePath); &#125; else &#123; return false; &#125; return true; &#125;; //监控目录、文件及处理 cachedThreadPool.execute(new FileWatchTask(filePath+"/c", monitorFileNameList, parseIF)); return true;&#125;]]></content>
      <categories>
        <category>架构</category>
      </categories>
      <tags>
        <tag>WatchService</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RPC框架 - Thrift协议定义]]></title>
    <url>%2Fposts%2F45936%2F</url>
    <content type="text"><![CDATA[rpcRPC 是远程过程调用（Remote Procedure Call）。 RPC 是指计算机 A 上的进程，调用另外一台计算机 B 上的进程，其中 A 上的调用进程被挂起，而 B 上的被调用进程开始执行，当值返回给 A 时，A 进程继续执行。调用方可以通过使用参数将信息传送给被调用方，而后可以通过传回的结果得到信息。 远程过程调用采用客户机/服务器(C/S)模式。请求程序就是一个客户机，而服务提供程序就是一台服务器。和常规或本地过程调用一样，远程过程调用是同步操作，在远程过程结果返回之前，需要暂时中止请求程序。使用相同地址空间的低权进程或低权线程允许同时运行多个远程过程调用。 编写IDL文件时需要注意的问题 函数的参数要用数字依序标好，序号从1开始，形式为：“序号:参数名” 每个函数的最后要加上“,”，最后一个函数不加 在IDL中可以使用/……/添加注释 IDL支持的数据类型IDL大小写敏感，它共支持以下几种基本的数据类型： string,字符串类型，注意是全部小写形式 i16,16位整形类型，相当于 short 类型 i32，32位整形类型，对应C/C++/java中的int类型 i64，64位整形，对应C/C++/java中的long类型 byte，8位的字符类型，对应C/C++中的char，java中的byte类型 bool, 布尔类型，对应C/C++中的bool，java中的boolean类型 double，双精度浮点类型，对应C/C++/java中的double类型 void，空类型，对应C/C++/java中的void类型；该类型主要用作函数的返回值 注：Thrift 不支持无符号整数类型，因为很多编程语言不存在无符号类型，比如 Java 除上述基本类型外，ID还支持以下类型： map，map类型 set，集合类型 list，列表类型 在Thrift文件中自定义数据类型 枚举类型 结构体类型 thrift定义字段12345- 1:optional a.b c;- 2:required string d;- 3:required i32 e=-1;- 4:optional f g;- 5:optional bool h=false; required: 必须填充，并且会序列化 optional:可以不填充，但是不填充，不会序列化，填充的才会序列化， thrift定义枚举和结构体12345678enum f&#123; x,y,z&#125;struct b&#123; 1:optional i16 o; 2:optional string p; 3:optional double q;&#125; thrift定义接口1234service Service&#123; list&lt;b&gt; getList(1:list&lt;i64&gt; ids); b getInfo(1:i64 id);&#125; 定义类型别名1typedefi32 Integer 就可以为i32类型重新起个名字Integer。 常量12345const string SERVER_IP = "127.0.0.1"const i32 SERVER_PORT = 5900const map&lt;string, string&gt; MAP_CONST = &#123;"hello": "world", "goodnight": "moon"&#125; 异常异常在语法和功能上类似于结构体，差别是异常使用关键字exception，而且异常是继承每种语言的基础异常类。 12345exception Extest &#123;1: i32 errorCode,2: string message,3: StUser userinfo&#125; Namespace和Includes12345namespace java com.xx.xx.xxinclude "xxx.thrift"include "xx.thrift"include "xxx.thrift" Thrift中的命名空间同C++中的namespace和java中的package类似 Thrift允许一个IDL文件包含另一个IDL文件，被包含的文件会在当前目录下查找。在使用被包含文件中的类型时要注意通过文件名前缀来访问。 联合当一个结构体中，field 之间的关系是互斥的，即只能有一个 field 可生效被赋值。我们可以用 union 来声明这个结构体，而不是一堆堆 optional 的 field，语意上也更明确了。例如： 12345678union JavaObjectArg &#123; 1: i32 int_arg; 2: i64 long_arg; 3: string string_arg; 4: bool bool_arg; 5: binary binary_arg; 6: double double_arg;&#125; 序列化和反序列化123456789101112131415161718//序列化TSerializer serializer = new TSerializer(new TJSONProtocol.Factory());//反序列化TDeserializer deserializer = new TDeserializer(new TJSONProtocol.Factory());String json = "";Request request2 = new Request();try &#123; //thrift转json json = serializer.toString(request, "UTF-8"); //string转thrift deserializer.fromString(request2, json);&#125; catch (TException e) &#123; e.printStackTrace();&#125;log.info(json);]]></content>
      <categories>
        <category>架构</category>
      </categories>
      <tags>
        <tag>thrift</tag>
        <tag>rpc</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Lucene利用Hanlp分词索引和检索]]></title>
    <url>%2Fposts%2F49532%2F</url>
    <content type="text"><![CDATA[包引入 pom引入lucene和hanlp lucene版本为7.4 hanlp分词器版本为1.1.6 1234567891011121314151617&lt;dependency&gt; &lt;groupId&gt;org.apache.lucene&lt;/groupId&gt; &lt;artifactId&gt;lucene-core&lt;/artifactId&gt; &lt;version&gt;7.4.0&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.lucene&lt;/groupId&gt; &lt;artifactId&gt;lucene-queryparser&lt;/artifactId&gt; &lt;version&gt;7.4.0&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.hankcs.nlp&lt;/groupId&gt; &lt;artifactId&gt;hanlp-lucene-plugin&lt;/artifactId&gt; &lt;version&gt;1.1.6&lt;/version&gt;&lt;/dependency&gt; 对数据文件进行索引123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354public class DocIndex &#123; // 建立索引文件的目录 public static String indexPath = "/index"; public static void index(String path, Map&lt;String, SugRecord&gt; map, boolean reIndex) &#123; indexPath = path + indexPath; if (!reIndex) &#123; return; &#125; IndexWriter writer = null; try &#123; // 存储索引数据的目录 Directory dir = FSDirectory.open(Paths.get(indexPath)); // 创建分析器 Analyzer analyzer = new HanLPAnalyzer(); IndexWriterConfig iwc = new IndexWriterConfig(analyzer); iwc.setOpenMode(IndexWriterConfig.OpenMode.CREATE); writer = new IndexWriter(dir, iwc); indexDoc(writer, map); writer.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; private static void indexDoc(IndexWriter writer, Map&lt;String, SugRecord&gt; map) &#123; map.forEach((k, v) -&gt; &#123; // 创建一个新的空文档 Document doc = new Document(); //创建索引字段 doc.add(new TextField("id", v.getId(), Field.Store.YES)); doc.add(new TextField("question", v.getQueryNorm(), Field.Store.NO)); doc.add(new TextField("query", v.getQuery(), Field.Store.NO)); // 写文档 try &#123; writer.addDocument(doc); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125;); try &#123; writer.flush(); writer.commit(); writer.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 对索引进行检索1234567891011121314151617181920212223242526272829303132333435363738394041424344@Slf4jpublic class DocSearcher &#123; public static List&lt;SugTerm&gt; search(String content) &#123; IndexReader reader = null; try &#123; reader = DirectoryReader.open(FSDirectory.open(Paths.get(DocIndex.indexPath))); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; IndexSearcher searcher = new IndexSearcher(reader); //或关系，多域检索 String[] fields = &#123;"question", "query"&#125;; BooleanClause.Occur[] clauses = &#123;BooleanClause.Occur.SHOULD, BooleanClause.Occur.SHOULD&#125;; try &#123; //指定分词器 Query query = MultiFieldQueryParser.parse(content, fields, clauses, new HanLPAnalyzer()); return doPagingSearch(searcher, query); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; return null; &#125; private static List&lt;Term&gt; doPagingSearch(IndexSearcher searcher, Query query) throws IOException &#123; // TopDocs保存搜索结果 TopDocs results = null; List&lt;Term&gt; termList = new ArrayList&lt;&gt;(); //分页数 results = searcher.search(query, 10); ScoreDoc[] hits = results.scoreDocs; for (ScoreDoc hit : hits) &#123; Document document = searcher.doc(hit.doc); String id = Objects.requireNonNull(document).get("id"); Term term = new Term(); term.id = id; term.score = hit.score; term.add(sugTerm); &#125; log.info(termList.toString()); return termList; &#125;&#125;]]></content>
      <categories>
        <category>架构</category>
      </categories>
      <tags>
        <tag>lucene</tag>
        <tag>hanlp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java线程池 - ThreadPool自定义封装]]></title>
    <url>%2Fposts%2F33509%2F</url>
    <content type="text"><![CDATA[自定义线程池，便于调试和控制线程 自定义线程数、拒绝策略、关闭等 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164@Slf4jpublic class CustomTaskThreadPool implements CustomThreadPool &#123; /** * 核心大小 */ private static int CORE_POOLSIZE = Runtime.getRuntime().availableProcessors() * 2; /** * 上限 */ private static int MAX_POOLSIZE = CORE_POOLSIZE * 10; //留存时间ms private static long KEEP_ALIVETIME = 300000L; private static long SHUTDOWN_WAIT_TIME = 300000L; /** * 时间单位 */ private static TimeUnit UNIT = TimeUnit.MILLISECONDS; /** * 队列容量 */ private static int CAPACITY = 20; /** * 队列 */ private static BlockingQueue&lt;Runnable&gt; WORK_QUEUE; /** * 线程工厂 */ private static ThreadFactory THREAD_FACTORY; /** * 默认拒绝策略 */ private static RejectedExecutionHandler REJECTED_EXECUTION_HANDLER; private static ThreadPoolExecutor executor = null; private static class CustomTaskThreadPoolFactory &#123; public static CustomTaskThreadPool CustomTaskThreadPool = new CustomTaskThreadPool(); &#125; /** * 线程池单例 * * @return */ public static CustomTaskThreadPool getInstance() &#123; return CustomTaskThreadPoolFactory.CustomTaskThreadPool; &#125; public CustomTaskThreadPool() &#123; if (CORE_POOLSIZE &lt;= 0 || CORE_POOLSIZE &gt; 10) &#123; CORE_POOLSIZE = 4; MAX_POOLSIZE = CORE_POOLSIZE * 10; &#125; THREAD_FACTORY = new CustomThreadFactory(); WORK_QUEUE = new ArrayBlockingQueue&lt;&gt;(CAPACITY); REJECTED_EXECUTION_HANDLER = new AbortPolicy(); executor = new ThreadPoolExecutor( CORE_POOLSIZE, MAX_POOLSIZE, KEEP_ALIVETIME, UNIT, WORK_QUEUE, THREAD_FACTORY, REJECTED_EXECUTION_HANDLER ); &#125; static &#123; Runtime.getRuntime().addShutdownHook(new Thread(new CustomRunnable() &#123; @Override public void run() &#123; close(); &#125; &#125;)); &#125; private static void close() &#123; try &#123; log.warn("即将关闭线程池，等待:&#123;&#125;ms,活跃:&#123;&#125;,未完成:&#123;&#125;,最大完成:&#123;&#125;,总完成:&#123;&#125;", SHUTDOWN_WAIT_TIME, executor.getActiveCount(), executor.getQueue().size(), executor.getLargestPoolSize(), executor.getCompletedTaskCount()); executor.shutdown(); //等待关闭 executor.awaitTermination(SHUTDOWN_WAIT_TIME, UNIT); log.warn("已关闭线程池"); //未完成 List&lt;Runnable&gt; CustomRunnableList = executor.shutdownNow(); if (!CollectionUtil.isEmpty(CustomRunnableList)) &#123; CustomRunnableList.forEach(e -&gt; log.warn("关闭未完成任务:" + e.toString())); &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; @Override public boolean execute(Runnable runnable) &#123; try &#123; executor.execute(new CustomRunnable(runnable)); &#125; catch (Exception e) &#123; log.error(e.getMessage(), e); return false; &#125; return true; &#125; @Override public &lt;T&gt; Future&lt;T&gt; submit(Callable&lt;T&gt; tCallable) &#123; try &#123; return executor.submit(new CustomCallable&lt;T&gt;(tCallable)); &#125; catch (RejectedExecutionException e) &#123; log.error(e.getMessage(), e); &#125; return null; &#125; @Override public void shutDown() &#123; executor.shutdown(); &#125; /** * 拒绝策略，丢弃不作任何处理 */ public static class AbortPolicy implements RejectedExecutionHandler &#123; @Override public void rejectedExecution(Runnable r, ThreadPoolExecutor e) &#123; String info = ""; try &#123; Field field = FutureTask.class.getDeclaredField("callable"); field.setAccessible(true); FutureTask futureTask = (FutureTask) r; Callable callable = (Callable) field.get(futureTask); CustomCallable CustomCallable = (CustomCallable) ((CustomCallable) callable).callable; info = CustomCallable.toString(); &#125; catch (Exception ex) &#123; ex.printStackTrace(); &#125; log.error("AbortPolicy: " + info + " rejected from " + e.toString()); &#125; &#125;&#125; 注意 计算密集型 线程数 = CPU核数+1，也可以设置成CPU核数*2，但还要看JDK的版本以及CPU配置(服务器的CPU有超线程)。 IO密集型 线程数 = CPU核心数/(1-阻塞系数) 这个阻塞系数一般为0.8~0.9之间，也可以取0.8或者0.9。套用公式，对于双核CPU来说，它比较理想的线程数就是20，当然这都不是绝对的，需要根据实际情况以及实际业务来调整：final int poolSize = (int)(cpuCore/(1-0.9)) 对于阻塞系数，我们可以先试着猜测，抑或采用一些性能分析工具或java.lang.management API 来确定线程花在系统/IO操作上的时间与CPU密集任务所耗的时间比值。 Runtime.getRuntime().availableProcessors() 因为容器不是物理隔离的，使用Runtime.getRuntime().availableProcessors() ，会拿到物理CPU个数，而不是容器申请时的个数。 例如宿主机器是4核CPU16G内存 java 6/7/8/9 docker run –cpus 1 -m 1G -it adoptopenjdk/openjdk9:latest # 给1核 jshell -J-Xmx512M -v # 启动jshell Runtime.getRuntime().availableProcessors() # 结果是不是1！！！ java 10 docker run –cpus 1 -m 1G -it adoptopenjdk/openjdk10:latest # 给1核 jshell -J-Xmx512M -v # 启动jshell Runtime.getRuntime().availableProcessors() # 结果是1]]></content>
      <categories>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>线程池</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java线程池 - ThreadFactory封装]]></title>
    <url>%2Fposts%2F59782%2F</url>
    <content type="text"><![CDATA[自定义ThreadFactory，便于创建自定义线程 自定义ThreadGroup，便于对线程分组管理 ThreadFactory和ThreadGroup封装123456789101112131415161718192021222324252627282930313233343536373839404142@Slf4jpublic class CustomThreadFactory implements ThreadFactory &#123; private AtomicInteger threadNum = new AtomicInteger(1); private final static String prefix = "Custom-thread-"; @Override public Thread newThread(Runnable r) &#123; String name = prefix + threadNum.getAndIncrement(); ThreadGroup threadGroup = new CustomThreadGroup("Custom_GROUP"); //非守护进程 threadGroup.setDaemon(false); //优先执行 threadGroup.setMaxPriority(Thread.MAX_PRIORITY); Thread thread = new Thread(threadGroup, r, name); return thread; &#125; static class CustomThreadGroup extends ThreadGroup &#123; public CustomThreadGroup(String name) &#123; super(name); &#125; public CustomThreadGroup(ThreadGroup parent, String name) &#123; super(parent, name); &#125; /** * 异常处理 * * @param t * @param e */ @Override public void uncaughtException(Thread t, Throwable e) &#123; log.error("线程名称:&#123;&#125;,异常信息:&#123;&#125;,异常栈:&#123;&#125;", t.getName(), e.getMessage(), e); &#125; &#125;&#125; ThreadFactory ThreadFactory的作用就是提供创建线程的功能的线程工厂 它是通过newThread()提供创建线程 newThread()创建的线程对应的任务是Runnable对象 它创建的线程默认都是“非守护线程”而且“线程优先级都是Thread.NORM_PRIORITY”。 ThreadGroup 方便地对加入这个线程组的多个线程进行操作。 重写uncaughtException()来实现自己的线程运行时异常处理逻辑 线程组可以进行复制，快速定位到一个线程 Thread类的enumerate()方法用于将每个活动线程的线程组及其子组复制到指定的数组中 1234567891011121314151617ThreadGroup group = Thread.currentThread().getThreadGroup(); ThreadGroup topGroup = group; // 遍历线程组树，获取根线程组 while (group != null) &#123; topGroup = group; group = group.getParent(); &#125; Thread[] slackList = new Thread[topGroup.activeCount() ]; // 获取根线程组的所有线程 int actualSize = topGroup.enumerate(slackList); // copy into a list that is the exact size Thread[] list = new Thread[actualSize]; System.arraycopy(slackList, 0, list, 0, actualSize); System.out.println("Thread list size == " + list.length); for (Thread thread : list) &#123; System.out.println(thread.getName()); &#125;]]></content>
      <categories>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>线程池</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java线程池 - Callable和Runnable封装]]></title>
    <url>%2Fposts%2F9431%2F</url>
    <content type="text"><![CDATA[对Callable和Runnable封装，提供自定义执行接口 补充异常处理 Runnable123456789101112131415161718192021222324252627282930313233343536373839@Slf4jpublic class CustomRunnable implements Runnable &#123; private Runnable runnable; public CustomRunnable() &#123; &#125; public CustomRunnable(final Runnable runnable) &#123; this.runnable = runnable; &#125; private String taskId; public void setTaskId(String taskId) &#123; this.taskId = taskId; &#125; @Override public void run() &#123; if (runnable == null) &#123; return; &#125; try &#123; runnable.run(); &#125; catch (Exception e) &#123; log.error("任务:&#123;&#125;,错误栈:&#123;&#125;", taskId, e); e.printStackTrace(); &#125; &#125; @Override public String toString() &#123; return Thread.currentThread().getName(); &#125;&#125; Callable1234567891011121314151617181920212223242526272829303132333435@Slf4jpublic class CustomCallable&lt;T&gt; implements Callable &#123; Callable&lt;T&gt; callable; public CustomCallable(Callable&lt;T&gt; callable) &#123; this.callable = callable; &#125; private String taskId; public void setTaskId(String taskId) &#123; this.taskId = taskId; &#125; @Override public T call() throws Exception &#123; if (callable == null) &#123; return null; &#125; try &#123; return callable.call(); &#125; catch (Exception e) &#123; log.error("任务:&#123;&#125;,错误栈:&#123;&#125;", taskId, e); e.printStackTrace(); &#125; return null; &#125; @Override public String toString() &#123; return Thread.currentThread().getName(); &#125;&#125; 区别 模块 Runnable Callable 返回值 否 是 返回对象 无 Future 执行方法 run call 执行超时 无 get(long timeout,TimeUtil unit) 获取结果 无 get、isDone 异常处理 无 throws Exception 线程阻塞 否 是,LockSupport.park]]></content>
      <categories>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>线程池</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Maven配置Profile]]></title>
    <url>%2Fposts%2F52371%2F</url>
    <content type="text"><![CDATA[项目根据环境不同，设置不同参数 实现在代码中无需改动，以防误提交 在pom中添加以下配置 12345678910111213141516171819&lt;profiles&gt; &lt;profile&gt; &lt;id&gt;dev&lt;/id&gt; &lt;properties&gt; &lt;profile.active&gt;dev&lt;/profile.active&gt; &lt;resource.exclude&gt;-&lt;/resource.exclude&gt; &lt;/properties&gt; &lt;/profile&gt; &lt;profile&gt; &lt;id&gt;prod&lt;/id&gt; &lt;activation&gt; &lt;activeByDefault&gt;true&lt;/activeByDefault&gt; &lt;/activation&gt; &lt;properties&gt; &lt;profile.active&gt;prod&lt;/profile.active&gt; &lt;resource.exclude&gt;*.yml&lt;/resource.exclude&gt; &lt;/properties&gt; &lt;/profile&gt; &lt;/profiles&gt; 默认prod 本地开发时，在Idea中Maven插件的Profiles中选择dev即可]]></content>
      <categories>
        <category>架构</category>
      </categories>
      <tags>
        <tag>Maven</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker部署和配置Nginx]]></title>
    <url>%2Fposts%2F29980%2F</url>
    <content type="text"><![CDATA[获取镜像1docker search nginx 安装官方版本name： docker.io/nginxOFFICIAL： ok 123docker pull nginxdocker images nginx 拉取并查看镜像 启动12345mkdir -p ./nginx/www ./nginx/logs ./nginx/confdocker run --name nginx-Custom -p 9803:80 -d -v /home/nginx/www:/usr/share/nginx/html -v /home/nginx/conf/nginx.conf:/etc/nginx/nginx.conf -v /home/nginx/logs:/var/log/nginx nginxdocker ps name: 容器名称。-d:设置容器在在后台一直运行。-p: 端口进行映射，将本地9803端口映射到容器内部的80端口。www: 目录将映射为nginx容器配置的虚拟目录。logs: 目录将映射为nginx容器的日志目录。conf: 目录里的配置文件将映射为nginx容器的配置文件。 配置index.html1234567891011121314cd ./nginx/wwwvi index.html&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt;&lt;meta charset="utf-8"&gt;&lt;title&gt;welcome&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;h1&gt;hello&lt;/h1&gt; &lt;p&gt;world。&lt;/p&gt;&lt;/body&gt;&lt;/html&gt; 配置默认页面 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253vi /home/nginx/conf/nginx.confuser nginx;worker_processes 1;error_log /var/log/nginx/error.log warn;pid /var/run/nginx.pid;events &#123; worker_connections 1024;&#125;http &#123; include /etc/nginx/mime.types; default_type application/octet-stream; log_format main '$remote_addr - $remote_user [$time_local] "$request" ' '$status $body_bytes_sent "$http_referer" ' '"$http_user_agent" "$http_x_forwarded_for"'; access_log /var/log/nginx/access.log main; sendfile on; #tcp_nopush on; keepalive_timeout 65; #gzip on; server&#123; listen 80; server_name localhost; index index.html index.htm; root /usr/share/nginx/html; location /recommend &#123; proxy_pass http://recommend_api; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; &#125; &#125; upstream recommend_api &#123; server 172.16.25.70:9819; server 192.168.1.41:9804 down; &#125; include /etc/nginx/conf.d/*.conf;&#125; 配置nginx文件及反向代理 测试12345docker restart c7d0b0a20287ecurl -l localhost:9803curl -l localhost:9803/recommend/api 说明设备状态 own：表示单前的server暂时不参与负载. weight：默认为1.weight越大，负载的权重就越大。 max_fails：允许请求失败的次数默认为1.当超过最大次数时，返回proxy_next_upstream 模块定义的错误. fail_timeout : max_fails次失败后，暂停的时间。 backup： 其它所有的非backup机器down或者忙的时候，请求backup机器。所以这台机器压力会最轻 分配策略 none（轮询）upstream按照轮询（默认）方式进行负载，每个请求按时间顺序逐一分配到不同的后端服务器，如果后端服务器down掉，能自动剔除。虽然这种方式简便、成本低廉。但缺点是：可靠性低和负载分配不均衡。 weight（权重）指定轮询几率，weight和访问比率成正比，用于后端服务器性能不均的情况。例如 server 192.168.61.22 weight = 6; # 60% 请求 server 192.168.61.23 weight = 4; # 40% 请求 ip_hash（访问ip）每个请求按访问ip的hash结果分配，这样每个访客固定访问一个后端服务器，可以解决session的问题。 配置只需要在upstream中加入ip_hash即可。]]></content>
      <categories>
        <category>架构</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java Lambda Stream原理]]></title>
    <url>%2Fposts%2F42366%2F</url>
    <content type="text"><![CDATA[举例1234567List list = new ArrayList(1); list.add(1); list.add(2); list.stream().forEach( System.out::println ); List.stream方法1234567891011121314default Stream&lt;E&gt; stream() &#123; return StreamSupport.stream(spliterator(), false);&#125;@Overridedefault Spliterator&lt;E&gt; spliterator() &#123; return Spliterators.spliterator(this, 0);&#125;public static &lt;T&gt; Spliterator&lt;T&gt; spliterator(Collection&lt;? extends T&gt; c, int characteristics) &#123; return new IteratorSpliterator&lt;&gt;(Objects.requireNonNull(c), characteristics);&#125; List的stream()接口位于java.util.Collection类中；默认实现输入的参数1是拆分方法spliterator，2是并行默认false。spliterator()接口也在该类中，默认实现调用final Spliterators类的spliterator方法，返回IteratorSpliterator。而static IteratorSpliterator类实现了Spliterator。Spliterator提供了tryAdvance处理每个元素、forEachRemaining、trySplit分割拆分等方法。 也就是说，stream()实际是采用Spliterator对于元素进行遍历、拆分处理。 StreamSupport.stream123456789101112131415public static &lt;T&gt; Stream&lt;T&gt; stream(Spliterator&lt;T&gt; spliterator, boolean parallel) &#123; Objects.requireNonNull(spliterator); return new ReferencePipeline.Head&lt;&gt;(spliterator, StreamOpFlag.fromCharacteristics(spliterator), parallel);&#125;Head(Spliterator&lt;?&gt; source, int sourceFlags, boolean parallel) &#123; super(source, sourceFlags, parallel); &#125;ReferencePipeline(Spliterator&lt;?&gt; source, int sourceFlags, boolean parallel) &#123; super(source, sourceFlags, parallel);&#125; list.stream()方法最终会实例化ReferencePipeline.Head&lt;&gt;对象，Head为pipeline流的头结。Head&lt;E_IN, E_OUT&gt; extends ReferencePipeline&lt;E_IN, E_OUT&gt;，E_IN为上游输入类型，E_OUT为输出类型点。StreamOpFlag.fromCharacteristics(spliterator)，将spliterator字符集转换为带有排序的流标记。ReferencePipeline为继承了AbstractPipeline得抽象类，提供pipeline处理类型的各阶段基类。 AbstractPipeline123456789101112AbstractPipeline(Spliterator&lt;?&gt; source, int sourceFlags, boolean parallel) &#123; this.previousStage = null; this.sourceSpliterator = source; this.sourceStage = this; this.sourceOrOpFlags = sourceFlags &amp; StreamOpFlag.STREAM_MASK; // The following is an optimization of: // StreamOpFlag.combineOpFlags(sourceOrOpFlags, StreamOpFlag.INITIAL_OPS_VALUE); this.combinedFlags = (~(sourceOrOpFlags &lt;&lt; 1)) &amp; StreamOpFlag.INITIAL_OPS_VALUE; this.depth = 0; this.parallel = parallel;&#125; AbstractPipeline为pipeline抽象基类，定义包括前一个、当前、下一个等AbstractPipeline处理流程等。AbstractPipeline继承abstract class PipelineHelper，PipelineHelper定义了流的操作、输出、标记和并行等参数。 forEach1void forEach(Consumer&lt;? super T&gt; action); 对流中的每个元素执行操作。 123456789@Overridepublic void forEach(Consumer&lt;? super E_OUT&gt; action) &#123; if (!isParallel()) &#123; sourceStageSpliterator().forEachRemaining(action); &#125; else &#123; super.forEach(action); &#125;&#125; forEach具体实现位于ReferencePipeline中，执行串行遍历或并行分割处理。 forEach并行1234567891011121314151617181920212223242526@Overridepublic void forEach(Consumer&lt;? super P_OUT&gt; action) &#123; evaluate(ForEachOps.makeRef(action, false));&#125;final &lt;R&gt; R evaluate(TerminalOp&lt;E_OUT, R&gt; terminalOp) &#123; assert getOutputShape() == terminalOp.inputShape(); if (linkedOrConsumed) throw new IllegalStateException(MSG_STREAM_LINKED); linkedOrConsumed = true; return isParallel() ? terminalOp.evaluateParallel(this, sourceSpliterator(terminalOp.getOpFlags())) : terminalOp.evaluateSequential(this, sourceSpliterator(terminalOp.getOpFlags()));&#125;default &lt;P_IN&gt; R evaluateParallel(PipelineHelper&lt;E_IN&gt; helper, Spliterator&lt;P_IN&gt; spliterator) &#123; if (Tripwire.ENABLED) Tripwire.trip(getClass(), &quot;&#123;0&#125; triggering TerminalOp.evaluateParallel serial default&quot;); return evaluateSequential(helper, spliterator);&#125; @Override public &lt;S&gt; Void evaluateSequential(PipelineHelper&lt;T&gt; helper, Spliterator&lt;S&gt; spliterator) &#123; return helper.wrapAndCopyInto(this, spliterator).get(); &#125; forEach并行时，主要采用evaluate方法，在pipeline中采用终止操作处理结果。]]></content>
      <categories>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>Lambda</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java Lambda FunctionalInterface原理]]></title>
    <url>%2Fposts%2F54901%2F</url>
    <content type="text"><![CDATA[123456789101112@FunctionalInterfaceinterface Print&lt;T&gt; &#123; public void print(T x);&#125;public class Lambda &#123; public static void PrintString(String s, Print&lt;String&gt; print) &#123; print.print(s); &#125; public static void main(String[] args) &#123; PrintString("test", (x) -&gt; System.out.println(x)); &#125;&#125; 编译器会根据Lambda表达式生成一个私有的静态函数 123456789101112131415161718192021@FunctionalInterfaceinterface Print&lt;T&gt; &#123; public void print(T x);&#125;public class Lambda &#123; public static void PrintString(String s, Print&lt;String&gt; print) &#123; print.print(s); &#125; private static void lambda$0(String x) &#123; System.out.println(x); &#125; final class $Lambda$1 implements Print&#123; @Override public void print(Object x) &#123; lambda$0((String)x); &#125; &#125; public static void main(String[] args) &#123; PrintString("test", new Lambda().new $Lambda$1()); &#125;&#125;]]></content>
      <categories>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>Lambda</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java8常用文件处理方法]]></title>
    <url>%2Fposts%2F58696%2F</url>
    <content type="text"><![CDATA[获取并解析文件 1234567891011121314151617public void parse() &#123; InputStream resource = Test.class.getResourceAsStream("/a.txt"); try &#123; BufferedReader bufferedReader = new BufferedReader( new InputStreamReader(resource)); // 获取文件 String line; while ((line = bufferedReader.readLine()) != null) &#123; &#125; &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; 获取其及子孙目录下的所有文件和目录 1234567891011public static List&lt;Path&gt; getFileList() &#123; try &#123; return Files.walk(Paths.get(dir)) .filter(Files::isRegularFile) .filter(e -&gt; e.toString().contains("app")) .collect(Collectors.toList()); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; return null;&#125; 写入文件 123456789101112public static void write(StringBuilder stringBuilder) &#123; BufferedWriter bfw = null; try &#123; bfw = Files.newBufferedWriter(Paths.get(dir + "/a.txt")); bfw.write(stringBuilder.toString()); bfw.flush(); bfw.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125;&#125;]]></content>
      <categories>
        <category>工具利器</category>
      </categories>
      <tags>
        <tag>Java8</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker基本操作]]></title>
    <url>%2Fposts%2F5308%2F</url>
    <content type="text"><![CDATA[查看进程docker ps 关闭进程docker kill -s KILL 376ec4b90 docker kill 376ec4b90 docker rm 376ec4b90 docker restart 376ec4b90]]></content>
      <categories>
        <category>架构</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Prometheus与Grafana部署和安装]]></title>
    <url>%2Fposts%2F1379%2F</url>
    <content type="text"><![CDATA[prometheus Prometheus是开源监控报警系统。 多维度数据模型。 灵活的查询语言。 不依赖分布式存储，单个服务器节点是自主的。 通过基于HTTP的pull方式采集时序数据。 可以通过中间网关进行时序列数据推送。 通过服务发现或者静态配置来发现目标服务对象。 支持多种多样的图表和界面展示，比如Grafana等。 概念Prometheus生态系统由多个组件组成，它们中的一些是可选的。多数Prometheus组件是Go语言写的，这使得这些组件很容易编译和部署。 Prometheus Server主要负责数据采集和存储，提供PromQL查询语言的支持。 客户端SDK官方提供的客户端类库有go、java、scala、python、ruby，其他还有很多第三方开发的类库，支持nodejs、php、erlang等。 Push Gateway支持临时性Job主动推送指标的中间网关。 PromDash使用Rails开发可视化的Dashboard，用于可视化指标数据。 ExporterExporter是Prometheus的一类数据采集组件的总称。它负责从目标处搜集数据，并将其转化为Prometheus支持的格式。与传统的数据采集组件不同的是，它并不向中央服务器发送数据，而是等待中央服务器主动前来抓取。 Prometheus提供多种类型的Exporter用于采集各种不同服务的运行状态。目前支持的有数据库、硬件、消息中间件、存储系统、HTTP服务器、JMX等。 alertmanager警告管理器，用来进行报警。 prometheus_cli命令行工具。 其他辅助性工具多种导出工具，可以支持Prometheus存储数据转化为HAProxy、StatsD、Graphite等工具所需要的数据存储格式。 node-exporter下载镜像docker pull prom/node-exporter 运行1234567docker run -d \ -p 9090:9090 \ --net="host" \ --pid="host" \ -v "/:/host:ro,rslave" \ quay.io/prometheus/node-exporter \ --path.rootfs /host redis_exporter下载镜像docker pull oliver006/redis_exporter 运行1234docker run -d \--name redis_exporter \-p 9121:9121 \oliver006/redis_exporter --redis.addr redis://h:password@192.168.1.41:6380 或者 123wget https://github.com/oliver006/redis_exporter/releases/download/v0.13/redis_exporter-v0.13.linux-amd64.tar.gz./redis_exporter -redis.addr 192.168.1.41:6380 -redis.password password &amp; mysqld-exporter下载镜像docker pull prom/mysqld-exporter 运行1234docker run -d \ -p 9101:9104 \ -e DATA_SOURCE_NAME="root:password@(192.168.1.41:3308)/test" \ prom/mysqld-exporter 或者 123456789wget https://github.com/prometheus/mysqld_exporter/releases/download/v0.10.0/mysqld_exporter-0.10.0.linux-amd64.tar.gz -O mysqld_exporter-0.10.0.linux-amd64.tar.gz cat &lt;&lt; EOF &gt; my.cnf[client]user=prompassword=abc123EOF./mysqld_exporter -config.my-cnf=&quot;my.cnf&quot; grafana下载镜像docker pull grafana/grafana 运行1docker run -d --name=grafana -p 3000:3000 grafana/grafana prometheus下载镜像docker pull prom/prometheus 运行12345sudo docker run -d \ -p 9090:9090 \ -v /home/config/prometheus.yml:/home/config/prometheus.yml \ quay.io/prometheus/prometheus \ --config.file=/home/config/prometheus.yml 配置prometheus.yml 12345678910111213141516171819202122crape_configs: - job_name: 'prometheus' static_configs: - targets: ['localhost:9090'] - job_name: 'redis-41' static_configs: - targets: ['192.168.1.41:9121'] labels: instance: redis - job_name: 'linux-41' static_configs: - targets: ['192.168.1.41:9100'] labels: instance: node - job_name: 'mysql-41' static_configs: - targets: ['192.168.1.41:9101'] labels: instance: db 重启服务 123docker psdocker restart `prometheus-processid` 登录验证12prometheus 192.168.1.41:9090grafana 192.168.1.41:3000 admin/admin]]></content>
      <categories>
        <category>工具利器</category>
      </categories>
      <tags>
        <tag>Prometheus</tag>
        <tag>Grafana</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[搭建Http-Server用于文件传输]]></title>
    <url>%2Fposts%2F4544%2F</url>
    <content type="text"><![CDATA[Http-Serverhttp-server 安装npm install http-server -g 启动cd ~/Public/http-server默认是 8080端口，./public文件夹 文件上传./public 文件下载wget http://172.16.25.70:8080/prometheus.yml pm2开机启动github```bashpm2 delete http-localwhich http-serverpm2 start /usr/local/bin/http-server –name http-local – -p 8080pm2 savepm2 startup]]></content>
      <categories>
        <category>工具利器</category>
      </categories>
      <tags>
        <tag>Http-Server</tag>
        <tag>nodejs</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Prometheus集成SpringBoot1.5]]></title>
    <url>%2Fposts%2F42635%2F</url>
    <content type="text"><![CDATA[Prometheus集成SpringBoot1.5pom12345678910111213141516171819202122232425262728&lt;!-- Actuator (with security enabled) --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-security&lt;/artifactId&gt;&lt;/dependency&gt;&lt;!-- Monitoring endpoint - Micrometer + Prometheus --&gt; &lt;dependency&gt; &lt;groupId&gt;io.micrometer&lt;/groupId&gt; &lt;artifactId&gt;micrometer-registry-prometheus&lt;/artifactId&gt; &lt;version&gt;1.0.3&lt;/version&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;artifactId&gt;HdrHistogram&lt;/artifactId&gt; &lt;groupId&gt;org.hdrhistogram&lt;/groupId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.micrometer&lt;/groupId&gt; &lt;artifactId&gt;micrometer-spring-legacy&lt;/artifactId&gt; &lt;version&gt;1.0.3&lt;/version&gt; &lt;/dependency&gt; bootstrap.yml123456789101112131415management: endpoints: web: exposure: include: &apos;*&apos; jmx: exposure: include: &apos;*&apos; shutdown: enabled: true metrics: distribution: percentiles-histogram[http.server.requests]: true security: enabled: false application.java1234567@BeanMeterRegistryCustomizer meterRegistryCustomizer(MeterRegistry meterRegistry) &#123; return meterRegistry1 -&gt; &#123; meterRegistry.config() .commonTags("application", "micrometer-web"); &#125;;&#125; 配置prometheus.yml 1234- job_name: 'app-41' metrics_path: '/mgmt/prometheus' static_configs: - targets: ['192.168.1.41:9915'] 重启服务 123docker psdocker restart `prometheus-processid` 登录验证12prometheus 192.168.1.41:9090grafana 192.168.1.41:3000 admin/admin]]></content>
      <categories>
        <category>工具利器</category>
      </categories>
      <tags>
        <tag>Prometheus</tag>
        <tag>SpringBoot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java Lambda用法]]></title>
    <url>%2Fposts%2F15864%2F</url>
    <content type="text"><![CDATA[特点 函数传递 函数编程 闭包 Java 中的 Lambda 表达式通常使用 (argument) -&gt; (body) 语法书写，例如： (arg1, arg2…) -&gt; { body } (type1 arg1, type2 arg2…) -&gt; { body }以下是一些 Lambda 表达式的例子： 123456789(int a, int b) -&gt; &#123; return a + b; &#125;() -&gt; System.out.println("Hello World");(String s) -&gt; &#123; System.out.println(s); &#125;() -&gt; 42() -&gt; &#123; return 3.1415 &#125;; 每个 Lambda 表达式都能隐式地赋值给函数式接口，例如，我们可以通过 Lambda 表达式创建 Runnable 接口的引用。 1Runnable r = () -&gt; System.out.println("hello world"); 当不指明函数式接口时，编译器会自动解释这种转化： 123new Thread( () -&gt; System.out.println("hello world")).start(); @FunctionalInterface 函数式接口只能有一个抽象方法，如果你尝试添加第二个抽象方法，将抛出编译时错误 12345678910111213141516171819202122232425262728//定义一个函数式接口### @FunctionalInterfacepublic interface WorkerInterface &#123; public void doSomeWork();&#125;public class WorkerInterfaceTest &#123;public static void execute(WorkerInterface worker) &#123; worker.doSomeWork();&#125;public static void main(String [] args) &#123; //invoke doSomeWork using Annonymous class execute(new WorkerInterface() &#123; @Override public void doSomeWork() &#123; System.out.println("Worker invoked using Anonymous class"); &#125; &#125;); //invoke doSomeWork using Lambda expression execute( () -&gt; System.out.println("Worker invoked using Lambda expression") );&#125;&#125; 用法区别123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172//Old way:List&lt;Integer&gt; list = Arrays.asList(1, 2, 3, 4, 5, 6, 7);for(Integer n: list) &#123; System.out.println(n);&#125;//New way:List&lt;Integer&gt; list = Arrays.asList(1, 2, 3, 4, 5, 6, 7);list.forEach(n -&gt; System.out.println(n));//or we can use :: double colon operator in Java 8list.forEach(System.out::println);public class Main &#123;public static void main(String [] a) &#123; List&lt;Integer&gt; list = Arrays.asList(1, 2, 3, 4, 5, 6, 7); System.out.println("Print all numbers:"); evaluate(list, (n)-&gt;true); System.out.println("Print no numbers:"); evaluate(list, (n)-&gt;false); System.out.println("Print even numbers:"); evaluate(list, (n)-&gt; n%2 == 0 ); System.out.println("Print odd numbers:"); evaluate(list, (n)-&gt; n%2 == 1 ); System.out.println("Print numbers greater than 5:"); evaluate(list, (n)-&gt; n &gt; 5 );&#125;public static void evaluate(List&lt;Integer&gt; list, Predicate&lt;Integer&gt; predicate) &#123; for(Integer n: list) &#123; if(predicate.test(n)) &#123; System.out.println(n + " "); &#125; &#125;&#125;&#125; //Old way:List&lt;Integer&gt; list = Arrays.asList(1,2,3,4,5,6,7);for(Integer n : list) &#123; int x = n * n; System.out.println(x);&#125;//New way:List&lt;Integer&gt; list = Arrays.asList(1,2,3,4,5,6,7);list.stream().map((x) -&gt; x*x).forEach(System.out::println);//Old way:List&lt;Integer&gt; list = Arrays.asList(1,2,3,4,5,6,7);int sum = 0;for(Integer n : list) &#123; int x = n * n; sum = sum + x;&#125;System.out.println(sum);//New way:List&lt;Integer&gt; list = Arrays.asList(1,2,3,4,5,6,7);int sum = list.stream().map(x -&gt; x*x).reduce((x,y) -&gt; x + y).get();System.out.println(sum); findAny12345 Optional&lt;A&gt; optional = list().stream().filter(e -&gt; (e.getType() == tag.getType())).findAny();if (!optional.isPresent()) &#123; &#125; collect12tagList = list.parallelStream().filter(e -&gt;e.getType() == tag.getType() ).collect(Collectors.toList()); map1List&lt;String&gt; list = tagList.stream().map(Tag::getValue).collect(Collectors.toList()); limit123456789Stream.iterate(0, i -&gt; i + 1).limit(tagList.size()).forEach( i -&gt; &#123; if (i == 0) &#123; &#125; else &#123; &#125; if (i == (tagList.size() - 1)) &#123; &#125; &#125; ); forEach123tagList().forEach(e -&gt; &#123; parse(e);&#125;); comparing1list.sort(Comparator.comparing(e -&gt; e.getPriority())); parallelStream12345public Ele getEle() &#123; return ist().parallelStream() .filter(e -&gt; Objects.equals("", "")) .findAny().orElse(null); &#125; of12345Stream.of("张三","李四","王二","张四五") .filter(x -&gt; x.startsWith("张")) .mapToInt(String::length) .max() .ifPresent(System.out::println); removeIf 移除元素12345678910111213List&lt;String&gt; str1 = new ArrayList&lt;String&gt;();str1.add("A");str1.add("B");str1.add("C");str1.add("D");List&lt;String&gt; str2 = new ArrayList&lt;String&gt;();str2.add("D");str2.add("E");str1.removeIf(x -&gt; str2.contains(x));str1.forEach(System.out::println);]]></content>
      <categories>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>Lambda</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ElasticSearch基本操作]]></title>
    <url>%2Fposts%2F278%2F</url>
    <content type="text"><![CDATA[Dochttps://docs.spring.io/spring-data/elasticsearch/docs/current/reference/html/ 聚合去重http://192.168.1.100:9200/a-b/a_b/_search 123456789101112&#123; &quot;from&quot;: 0, &quot;size&quot;: 0, &quot;aggregations&quot;: &#123; &quot;field1&quot;: &#123; &quot;terms&quot;: &#123; &quot;field&quot;: &quot;xx&quot;, &quot;size&quot;: 21474837 &#125; &#125; &#125; &#125;]]></content>
      <categories>
        <category>架构</category>
      </categories>
      <tags>
        <tag>ElasticSearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[List利用Comparator进行Sort]]></title>
    <url>%2Fposts%2F50004%2F</url>
    <content type="text"><![CDATA[代码123456789101112131415161718public static void main(String[] args) &#123; List&lt;Integer&gt; a = new ArrayList(10); a.add(1); a.add(4); a.add(2); a.add(5); a.add(3); Collections.sort(a, new Comparator&lt;Integer&gt;() &#123; @Override public int compare(Integer o1, Integer o2) &#123; return o2 - o1;//倒叙 &#125; &#125;); a.stream().forEach(x -&gt; System.out.println(x));&#125; 输出： 1234554321 分析Comparator 比较器 java.util包 接口 用于排序和分组 常用于数组和列表 Arrays.sort(T[],Comparator&lt;? super T&gt; c) Collections.sort(List list,Comparator&lt;? super T&gt; c) 原理List.java 123456789default void sort(Comparator&lt;? super E&gt; c) &#123; Object[] a = this.toArray(); Arrays.sort(a, (Comparator) c); ListIterator&lt;E&gt; i = this.listIterator(); for (Object e : a) &#123; i.next(); i.set((E) e); &#125;&#125; 调用List默认接口实现 实际调用Arrays.sort(a, (Comparator) c); Arrays.java 12345678910public static &lt;T&gt; void sort(T[] a, Comparator&lt;? super T&gt; c) &#123; if (c == null) &#123; sort(a); &#125; else &#123; if (LegacyMergeSort.userRequested) legacyMergeSort(a, c); else TimSort.sort(a, 0, a.length, c, null, 0, 0); &#125;&#125; LegacyMergeSort归并排序，默认不使用 TimSort利用合并和插入排序 指定Comparator逆序1Collections.sort(result, Collections.reverseOrder()); 源码 1234567891011121314151617181920212223public static &lt;T&gt; Comparator&lt;T&gt; reverseOrder() &#123; return (Comparator&lt;T&gt;) ReverseComparator.REVERSE_ORDER;&#125;private static class ReverseComparator implements Comparator&lt;Comparable&lt;Object&gt;&gt;, Serializable &#123; private static final long serialVersionUID = 7207038068494060240L; static final ReverseComparator REVERSE_ORDER = new ReverseComparator(); //逆序 public int compare(Comparable&lt;Object&gt; c1, Comparable&lt;Object&gt; c2) &#123; return c2.compareTo(c1); &#125; private Object readResolve() &#123; return Collections.reverseOrder(); &#125; @Override public Comparator&lt;Comparable&lt;Object&gt;&gt; reversed() &#123; return Comparator.naturalOrder(); &#125;&#125;]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Comparator</tag>
        <tag>List</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[IDEA基本配置]]></title>
    <url>%2Fposts%2F49684%2F</url>
    <content type="text"><![CDATA[IDEA通用插件安装Alibaba Java Code Guidelines Preferences &gt;&gt; Plugins &gt;&gt; Marketplace 查询Alibaba Java Code Guidelines并安装后重启 Git Flow Integrationgit flow集成 GitToolBox行代码给与log历史提示 类的注释格式 Preferences &gt;&gt; Editor &gt;&gt; File and Code Templates &gt;&gt; Includes &gt;&gt; File Header 12345/*** @author: Perkins* @date: $&#123;DATE&#125;* @description: todo*/ lombok IDEA插件查询lombok并安装 pom 123456&lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;version&gt;1.16.18&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt;&lt;/dependency&gt; 代码使用注解@Data，@Log 快捷键 左侧缩进：先选中多行，Shift+Tab多次，直至对齐 左侧对齐后的竖着多行选中：Option+光标上下选中 光标最左右侧移动，command+左右方向键 选中光标直至最左、右侧，command+shift+左右方向键 选中右侧第一个单词，command+w]]></content>
      <categories>
        <category>工具利器</category>
      </categories>
      <tags>
        <tag>IDEA</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Maven基本操作]]></title>
    <url>%2Fposts%2F725%2F</url>
    <content type="text"><![CDATA[Maven环境变量配置 创建文件 123cd ~touch .bash_profileopen -e .bash_profile 写入bash_profile 12345M2_HOME=/Users/work/apache-maven-3.5.0/PATH=$M2_HOME/bin:$PATHexport M2_HOMEexport PATH 执行 1source .bash_profile 测试 1mvn -v 安装jar和源码至本地仓库 jarmvn install:install-file -Dfile=/Users/xx-1.0.1.jar -DgroupId=xx -DartifactId=xx -Dversion=1.0.1 -Dpackaging=jar sourcemvn install:install-file -Dfile=/Users/xx-1.0.1-sources.jar -DgroupId=xx -DartifactId=xx -Dversion=1.0.1 -Dpackaging=jar -Dclassifier=sources scope12345&lt;dependency&gt; &lt;groupId&gt;xx.xx.xx&lt;/groupId&gt; &lt;artifactId&gt;xx-xx&lt;/artifactId&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; 值 说明 provided 打包时不包含，认为容器会提供 compile 默认，在编译、测试和打包阶段均有效 runtime 跳过编译，直接参与运行和测试 test 依赖性参与测试工作，包括测试代码的编译和运行，例如junit system 包来自本地系统文件 打包命令 值 说明 package 测试、打包 install 测试、打包并安装至本地仓库 deploy 测试、打包并安装至本地仓库，且上传至Maven中央服务器 打包指定项目-N，–Non-recursive，表示不递归子模块-pl Module，–projects，选项后可跟随{groupId}:{artifactId}或者所选模块的相对路径(多个模块以逗号分隔)-am，–also-make，表示同时处理选定模块所依赖的模块]]></content>
      <categories>
        <category>工具利器</category>
      </categories>
      <tags>
        <tag>Maven</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mac下用iterm2免密码]]></title>
    <url>%2Fposts%2F49300%2F</url>
    <content type="text"><![CDATA[安装Homebrew1/usr/bin/ruby -e "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)" 安装sshpass123brew install http://git.io/sshpass.rbwhich sshpass 输出/usr/local/bin/sshpass Item2配置1/usr/local/bin/sshpass -p 123456 ssh -p22 root@192.168.1.41 操作先用本地终端连接第一次，再用item2]]></content>
      <categories>
        <category>工具利器</category>
      </categories>
      <tags>
        <tag>iterm2</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS7安装部署 - Redis]]></title>
    <url>%2Fposts%2F85%2F</url>
    <content type="text"><![CDATA[redis 拉取 1wget http://download.redis.io/releases/redis-3.2.6.tar.gz 解压 1tar -zxvf redis-3.2.6.tar.gz 编译 12cd redis-3.2.6make 修改数据目录vi redis.conf 1234567891011121314#指定日志目录logfile /root/data/soft/redis-3.2.6/data/logs/redis.log#指定数据目录dir /root/data/soft/redis-3.2.6/data#修改后台启动daemonize yes#允许外网访问protected-mode no #允许ip访问#bind 127.0.0.1#修改绑定端口port 6380#密码访问requirepass root123 启动 123cd redis-3.2.6/src #启动./redis-server ../redis.conf 测试 1234./redis-cli -p 6380dbsizeflushallexit 客户端安装Redis Desktop Manager输入连接ip、端口、密码]]></content>
      <categories>
        <category>安装部署</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS7安装部署 - MongoDB]]></title>
    <url>%2Fposts%2F277%2F</url>
    <content type="text"><![CDATA[mogo 下载12345wget https://fastdl.mongodb.org/linux/mongodb-linux-x86_64-rhel70-4.0.6.tgz ./tar xzvf mongodb-linux-x86_64-rhel70-4.0.6.tgzmkdir -p data/mongo_data data/logs 配置 1234567891011121314touch mongo.conf#数据目录dbpath=/home/admin/soft/mongodb/data/mongo_datalogpath=/home/admin/soft/mongodb/data/logs/mongo.log#后台允许fork=truequiet=truejournal=truelogappend=true#可以外网访问bind_ip=0.0.0.0#修改端口port=27018 启动： 1/bin/mongod -f mongo.conf 创建管理员 123456789mongo localhost:27018&gt;use admin db.createUser( &#123; user: "root", pwd: "root123", roles: [ &#123; role: "userAdminAnyDatabase", db: "admin" &#125;, "readWriteAnyDatabase" ] &#125; ) exit 开启权限vi /etc/mongod.conf 123#security security: authorization: enabled 重启mongodb： 12pkill mongod/bin/mongod -f mongo.conf 安装GUI 123456789#先安装nodebrew install nodegit clone https://github.com/mrvautin/adminMongo cd adminMongonpm installnpm start#测试地址：http://127.0.0.1:1234 后台进程 1234#指定name启动pm2 start app.js --name adminMongo#删除pm2 delete adminMongo GUI连接打开http://127.0.0.1:1234地址：mongodb://root:root123@192.168.1.41:27018/admin pm21234567npm install pm2 -gpm2 listpm2 restartpm2 monitpm2 start app.js --name adminMongopm2 delete adminMongoMon 安装service 12yum list | grep initscriptsyum install initscripts -y docker不能启动问题Failed to get D-Bus connection: Operation not permitted解决： 1docker run -d -it --privileged ContainerId /usr/sbin/init]]></content>
      <categories>
        <category>安装部署</category>
      </categories>
      <tags>
        <tag>MongoDB</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Centos7安装部署 - MySQL]]></title>
    <url>%2Fposts%2F21810%2F</url>
    <content type="text"><![CDATA[mysql5.7 下载并安装源123wget 'https://dev.mysql.com/get/mysql57-community-release-el7-11.noarch.rpm'sudo rpm -Uvh mysql57-community-release-el7-11.noarch.rpmyum repolist all | grep mysql 安装 1sudo yum install mysql-community-server 更改数据目录 123456789chown -R mysql:mysql /root/data/soft/mysql vi /etc/my.cnf#修改数据目录#datadir=/var/lib/mysql#socket=/var/lib/mysql/mysql.sockdatadir=/root/data/soft/mysqlsocket=/root/data/soft/mysql/mysql.sock 启动 123456789service mysqld start#查看错误日志tail -200 /var/log/mysqld.log#因为修改了目录 需要再初始化cd /root/data/soft/mysqlrm -rf *chown -R mysql:mysql .mysqld --initialize --user=mysql --consoleservice mysqld start 登录和修改密码 12345678#获取密码grep 'temporary password' /var/log/mysqld.logmysql -uroot -P3308 -p select @@log_error;set password for 'root'@'localhost'=password('root@123'); 授权登录 12GRANT ALL PRIVILEGES ON *.* TO 'root'@'%' IDENTIFIED BY 'root@123' WITH GRANT OPTION;FLUSH PRIVILEGES; 客户端workbench 解决中文乱码 123set global character_set_server=utf8;set global character_set_database=utf8;show variables like '%char%';]]></content>
      <categories>
        <category>安装部署</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java并发编程艺术 - 多线程]]></title>
    <url>%2Fposts%2F24227%2F</url>
    <content type="text"><![CDATA[启动Java应用程序则是一个进程，一个进程可以启动多个线程，线程是操作系统调度最小单元。线程拥有独立的计数器、栈和局部变量，可以共享堆内存。 一个Java程序入口是main主线程，线程优先级从1-10，优先级越高分配时间片越长。 为什么使用多线程 更多的处理器核心 使用多线程技术，将计算逻辑分配到多个处理器核心上，就会显著减少程序的处理时间，并且随着更多处理器核心的加入而变得更有效率。 更快的响应时间 使用多线程技术，即将数据一致性不强的操作派发给其他线程处理（也可以使用消息队列），如生成订单快照、发送邮件等。这样做的好处是响应用户请求的线程能够尽可能快地处理完成，缩短了响应时间，提升了用户体验。 更好的编程模型 Java为多线程编程提供了良好、考究并且一致的编程模型，使开发人员能够更加专注于问题的解决，即为所遇到的问题建立合适的模型，而不是绞尽脑汁地考虑如何将其多线程化。一旦开发人员建立好了模型，稍做修改总是能够方便地映射到Java提供的多线程编程模型上。 线程状态 NEW 新建 Thread.start(); RUNNABLE 运行，包括就绪和运行 Thread.run(); BLOCKED 阻塞 synchronized WAITING 等待，等待其他线程通知和中断 Object.wait() Object.join() LockSupport.park(Thread) TIME_WAITTING 等待，等待指定时间超时 Thread.sleep(long) Object.wait(long) Object.join(long) LockSupport.parkNanos() LockSupport.parkUntil() TERMINATED 终止 interrupt(),isInterrupted()和interrupted() suspend()、resume()和stop()线程在自身的生命周期中，并不是固定地处于某个状态，而是随着代码的执行在不同的状态之间进行切换 线程创建之后，调用start()方法开始运行。 当线程执行wait()方法之后，线程进入等待状态。 进入等待状态的线程需要依靠其他线程的通知才能够返回到运行状态 而超时等待状态相当于在等待状态的基础上增加了超时限制，也就是超时时间到达时将会返回到运行状态。 当线程调用同步方法时，在没有获取到锁的情况下，线程将会进入到阻塞状态。 线程在执行Runnable的run()方法之后将会进入到终止状态。 Java将操作系统中的运行和就绪两个状态合并称为运行状态。 阻塞状态是线程阻塞在进入synchronized关键字修饰的方法或代码块（获取锁）时的状态。 但是阻塞在java.concurrent包中Lock接口的线程状态却是等待状态，因为java.concurrent包中Lock接口对于阻塞的实现均使用了LockSupport类中的相关方法。 线程优先级123Thread thread = new Thread(job, "Thread:" + i);thread.setPriority(priority);thread.start(); 在Java线程中，通过一个整型成员变量priority来控制优先级，优先级的范围从1~10，在线程构建的时候可以通过setPriority(int)方法来修改优先级，默认优先级是5，优先级高的线程分配时间片的数量要多于优先级低的线程。 设置线程优先级时，针对频繁阻塞（休眠或者I/O操作）的线程需要设置较高优先级，而偏重计算（需要较多CPU时间或者偏运算）的线程则设置较低的优先级，确保处理器不会被独占。在不同的JVM以及操作系统上，线程规划会存在差异，有些操作系统甚至会忽略对线程优先级的设定。 线程优先级不能作为程序正确性的依赖，因为操作系统可以完全不用理会Java线程对于优先级的设定。 Daemon线程守护线程，为非Daemon线程提供后台调度和服务，例如GC线程。 123Thread thread = new Thread(new DaemonRunner(), "DaemonRunner");thread.setDaemon(true);thread.start(); Daemon线程是一种支持型线程，因为它主要被用作程序中后台调度以及支持性工作。这意味着，当一个Java虚拟机中不存在非Daemon线程的时候，Java虚拟机将会退出。可以通过调用Thread.setDaemon(true)将线程设置为Daemon线程。 Daemon属性需要在启动线程之前设置，不能在启动线程之后设置。 线程中断其他线程调用该线程的interrupt()方法进行中断，线程本身调用isInterrupted(()判断是否中断，也可以调用Thread.interrupted()对当前线程的中断标识位进行复位。 123456789101112131415161718192021222324252627282930313233343536373839404142public class Thread2 &#123; public static void main(String[] args) throws Exception &#123; Runner one = new Runner(); Thread countThread = new Thread(one, "CountThread1"); countThread.start(); // 睡眠1秒，main线程对CountThread进行中断，使CountThread能够感知中断而结束 TimeUnit.SECONDS.sleep(1); countThread.interrupt(); Runner two = new Runner(); countThread = new Thread(two, "CountThread2"); countThread.start(); // 睡眠1秒，main线程对Runner two进行取消，使CountThread能够感知on为false而结束 TimeUnit.SECONDS.sleep(1); two.cancel(); &#125; private static class Runner implements Runnable &#123; private long i; private volatile boolean on = true; @Override public void run() &#123; while (on &amp;&amp; !Thread.currentThread().isInterrupted()) &#123; try &#123; i++; Thread.sleep(100); &#125; catch (InterruptedException e) &#123; Thread.currentThread().interrupt();//重新设置中断标示 &#125; &#125; System.out.println("Count i = " + i + ",Name:" + Thread.currentThread().getName()); &#125; public void cancel() &#123; on = false; &#125; &#125;&#125; 线程等待和通知 notify() 随机通知在对象上等待的另一个线程，使其在wait()状态上尝试获取锁，如获取锁成功则返回 notifyAll() 通知在对象上等待的所有线程，竞争锁 wait() 进入WAITING状态，等待通知或中断，会释放锁 wait(long) 进入TIME_WAITTING状态，等待超时 join() 进入WAITING状态，等待其他线程终止后返回，不释放锁 join(long) 进入TIME_WAITTING状态，等待其他线程终止后返回，不释放锁]]></content>
      <categories>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>Java并发编程</tag>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java并发编程艺术 - 延迟加载与双重检查锁定double check lock]]></title>
    <url>%2Fposts%2F31866%2F</url>
    <content type="text"><![CDATA[类延迟初始化常采用单例模式。 方法1： 12345678910public class Singleton &#123; private static Singleton singleton = null; public static Singleton getInstance() &#123; if (singleton == null) &#123;//1 singleton=new Singleton();//2 &#125; return singleton; &#125;&#125; 多线程中，步骤1可以同步执行，导致步骤2多次执行。 方法2： 12345678910public class Singleton &#123; private static Singleton singleton = null; public static synchronized Singleton getInstance() &#123; if (singleton == null) &#123;//1 singleton=new Singleton();//2 &#125; return singleton; &#125;&#125; 多线程中，singleton只会实例一次，但每次获取getInstance都会加锁导致性能下降。 方法3： 12345678910111213141516public class Singleton &#123; private static Singleton singleton = null; public static Singleton getInstance() &#123; //one check if (singleton == null) &#123;//1 synchronized (Singleton.class) &#123;//2 //two check if (singleton == null) &#123;//3 singleton = new Singleton();//4 &#125; &#125; &#125; return singleton; &#125;&#125; 步骤4分解为3条指令执行，包括1-先分配内存，2-标记对象指向内存地址，3-初始化构造；如果指令12重排导致先赋值，多线程并发中步骤1不为null，但获取的singleton仍未初始化。 方法4： 1234567891011121314151617public class Singleton &#123; //防止重排 private volatile static Singleton singleton = null;//5 public static Singleton getInstance() &#123; //one check if (singleton == null) &#123;//1 synchronized (Singleton.class) &#123;//2 //two check if (singleton == null) &#123;//3 singleton = new Singleton();//4 &#125; &#125; &#125; return singleton; &#125;&#125; 步骤5使用volatile防止指令重排，是标准的DCL实例方案。 方法5： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public class Singleton implements Serializable&#123;//序列化 //防止重排 private volatile static Singleton singleton = null;//5 private static boolean flag = false; private Singleton() &#123;//6 //防止反射漏洞 synchronized (Singleton.class) &#123; if (flag) &#123; System.out.println("init twice"); &#125; else &#123; flag = true; System.out.println("init once"); &#125; &#125; &#125; public static Singleton getInstance() &#123; //one check if (singleton == null) &#123;//1 synchronized (Singleton.class) &#123;//2 //two check if (singleton == null) &#123;//3 singleton = new Singleton();//4 &#125; &#125; &#125; return singleton; &#125; //防止反序列化漏洞，替换反序列化对象 private Object readResolve() &#123; return singleton; &#125; public static void main(String[] args) throws Exception &#123; Class&lt;Singleton&gt; clazz = (Class&lt;Singleton&gt;) Class.forName("Singleton"); Constructor&lt;Singleton&gt; singletonConstructor = clazz.getDeclaredConstructor(null); singletonConstructor.setAccessible(true);//反射打开访问权限 Singleton singleton = singletonConstructor.newInstance();//第一次实例化 singleton.say(); System.out.println(singleton); singleton = singletonConstructor.newInstance();//第二次实例化 singleton.say(); &#125;&#125; 步骤6对构造函数进行私有化，防止多次被实例化；同时，为防止反射多次实例，使用全局变量flag；也支持单例模式的序列化和反序列化。在执行类的初始化期间，JVM会去获取一个锁。这个锁可以同步多个线程对同一个类的初始化。 方法6： 1234567891011public class Singleton &#123; private static Singleton singleton = null; private static class SingletonFactory &#123; public static Singleton singleton2 = new Singleton(); &#125; public static Singleton getInstance() &#123; return SingletonFactory.singleton2; &#125;&#125; 利用类加载机制来实现，延迟初始化,类加载分为加载-&gt;验证-&gt;准备-&gt;解析-&gt;初始化-&gt;使用-&gt;卸载等步骤，Java中当类的静态域或静态方法被引用的时候，必须对声明这个静态域或方法的类进行初始化。 方法7： 123456789101112public enum SingletonEnum &#123; INSTANCE_ENUM; DataSource dataSource; private SingletonEnum() &#123; dataSource = null; &#125; public DataSource getDataSource() &#123; return dataSource; &#125;&#125; 利用枚举类实现单例模式。SingletonEnum会被编译成public final class SingletonEnum extends Enum，INSTANCE_ENUM会编译成public static final SingletonEnum INSTANCE_ENUM，根据类加载机制，初始化是线程安全的；同时，枚举序列化和反序列化禁止writeObject、readObject，不采用反射而是根据name属性和valueOf方法，防止破坏单例。]]></content>
      <categories>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>Java并发编程</tag>
        <tag>单例模式</tag>
        <tag>双重检测锁定</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java并发编程艺术 - 重排序]]></title>
    <url>%2Fposts%2F35014%2F</url>
    <content type="text"><![CDATA[重排序是编译器和处理器为优化程序性能而对指令进行重新排序的手段。 数据依赖性 写后写;a=1,a=2 写后读;a=1,b=a 读后写;a=b,b=1 以上三种情况存在数据依赖，重排将会引起结果改变。 as-if-serial不管怎么重排序，但不能影响结果，编译器、runtime和处理器都必须遵守这个语义，即可以对不存在数据依赖关系的指令进行重排。 例如 123int a=1;//操作1int b=2;//操作2int c=a+b;//操作3 以上操作1和2可以重排。 重排对多线程的影响1234567891011121314class ReorderExample &#123; int a = 0; boolean flag = false; public void writer() &#123; a = 1; // 1 flag = true; // 2 &#125; public void reader() &#123; if (flag) &#123; // 3 int i = a * a; // 4 …… &#125; &#125;&#125; 在多线程开发中： 如果线程1对操作1和2进行重排，线程2执行reader的操作3时，变量a可能没有及时同步，结果可能为0而不是1。 如果线程1对操作3和4进行重排，先将操作4结果暂存缓存，等待操作3决定是否缓存写入i；在单线程没有问题，但多线程操作3可能会被改变。 因此，多线程开发需要考虑程序执行的顺序性，可以采用同步原语，包括valatile、synchronized和final。]]></content>
      <categories>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>Java并发编程</tag>
        <tag>重排序</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java并发编程艺术 - Java内存模型基础]]></title>
    <url>%2Fposts%2F49164%2F</url>
    <content type="text"><![CDATA[并发编程的两个关键性问题 线程通信 线程同步 线程通信 通信是指线程间的信息交换，主要有两种：共享内存和消息传递。 共享内存是线程利用内存的公共状态进行隐私通信。 在Java中主要利用堆内存变量实现共享内存，包括静态域、数据、实例。 12345678910111213141516public class ThreadShare &#123; //利用内存静态变量进行状态传递 static int num = 0; private void increase() &#123; num++; System.out.println(num); &#125; public static void main(String[] args) &#123; ThreadShare threadShare = new ThreadShare(); new Thread(threadShare::increase).start(); new Thread(threadShare::increase).start(); &#125;&#125; 消息传递是利用管道消息进行显示通信。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364public class Consumer implements Runnable &#123; private PipedInputStream pis; public Consumer(PipedInputStream pis) &#123; this.pis = pis; &#125; @Override public void run() &#123; // 将数据保存在byte数组中 byte[] bytes = new byte[100]; try &#123; // 从数组中得到实际大小。 int length = pis.read(bytes); System.out.println(new String(bytes, 0, length)); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; finally &#123; try &#123; pis.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125;public class Producer implements Runnable &#123; private PipedOutputStream pos; public Producer(PipedOutputStream pos) &#123; this.pos = pos; &#125; @Override public void run() &#123; try &#123; pos.write("Hello World".getBytes()); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; finally &#123; try &#123; pos.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125;public class TestPipedStream &#123; public static void main(String[] args) &#123; PipedOutputStream pos = new PipedOutputStream(); PipedInputStream pis = new PipedInputStream(); try &#123; // 连接管道 pos.connect(pis); new Thread(new Producer(pos)).start(); new Thread(new Consumer(pis)).start(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 线程同步 在共享内存中必须显式指定某个方法或代码段进行线程互斥，在消息传递中隐式说明消息接收需在消息发送前。 互斥锁主要有Lock，synchronized。 JMM内存结构线程AB间要通信，需要经过两步： A将共享变量X的本地内存刷新到主存 B到主存更新本地内存的共享变量X 实质上是线程A在向线程B发送消息，而且这个通信过程必须要经过主内存。 JMM通过控制主内存与每个线程的本地内存之间的交互，提供内存可见性保证。 指令重排执行程序为提高性能，编译器和处理器会进行指令重排，主要有3种。 编译器在不影响单线程结果的前提下，进行指令重排。 指令并行重排。多条指令不存在数据依赖性，处理器可以改变机器指令执行顺序。 内存重排。处理器使用缓存和读写缓冲区进行加载和存储。 JMM通过插入内存屏障防止指令重排。 happens-beforeJMM中，如果一个操作执行结果需要对另一个操作可见，两个操作需要存在happens-before关系。 该两个操作可以是一个线程也可以是不同线程。 happens-before规则如下： 程序顺序规则：一个线程每个操作，happens-before线程后续操作 监视器锁规则：一个监视器锁的解锁，happens-before锁的加锁 volatile变量规则：一个volatile的写，happens-before任意对此域的读 传递性：如果A happens-before B，且B happens-before C，那么A happens-before C 两个操作存在happens-before关系，并不意味着一个操作必须在另一个之前，而是第一个操作的结果对第二个可见。]]></content>
      <categories>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>Java内存模型</tag>
        <tag>Java并发编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java并发编程艺术 - 原子性及CAS使用和原理]]></title>
    <url>%2Fposts%2F28363%2F</url>
    <content type="text"><![CDATA[原子性处理器保障从系统内存中读取和写入字节是原子的，即其他处理器不能访问该字节地址。 总线锁保障原子性处理器发出Lock#信号到总线上，其他处理器阻塞，该处理器独享内存。 缓存锁保障原子性总线锁把CPU和内存通信锁住，其他CPU无法访问其他内存地址，开销较大。 可以在缓存中，锁定内存地址，保障原子性。 缓存锁定缓存行时，回写内存不声明LOCK#，而是修改内部内存地址，同时通过缓存一致性阻止其他处理器修改；当其他处理器回写，将会无效缓存行，从内存重新加载数据。 JAVA实现原子操作通过锁实现原子操作锁机制保障只有获取锁的线程才能操作内存区域，常见的JVM锁有偏向锁、轻量锁和互斥锁。 除偏向锁外，其他锁实现都采用CAS进行锁的获取和释放。 通过CAS实现原子操作CAS通过Compare And Swap可以实现原子操作；原子操作即不能被进一步分割的最小粒子。 CAS需要输入两个参数，old值和expect值；若old值未发生变化，则替换old为expect，否则不交换。实际上是三个参数，第三个参数无需输入，可使用局部变量或者由操作指令维护，是old的origin值，用于和输入的old比较。 JVM中的CAS操作正是利用了处理器的CMPXCHG指令实现，自旋CAS实现的就是循环CAS直到成功。 从Java 1.5开始，JDK的JUC包里提供了原子操作，如AtomicBoolean（用原子方式更新的boolean值）、AtomicInteger（用原子方式更新的int值）和AtomicLong（用原子方式更新的long值）。这些原子包装类还提供了以原子的方式将当前值自增1和自减1。 CAS产生的问题ABA问题假如old和expect值相同，虽然交换了，但结果貌似没有变化，而且也不知道是否真的交换成功。 因此需要引入版本号，假如每次交换后版本加1，则可以明显确定是否交换成功，例如AtomicStampedReference。 长时间自旋如果长时间CAS自旋失败，则浪费CPU。 可以提供暂停操作，实现自旋延迟效果。 只能支持单个变量的原子性多个变量原子性操作通常需要用锁，或者采用把多个共享变量合并成一个共享变量。 AtomicReference支持对象的原子性，可以将多个变量放在一个对象中进行CAS。]]></content>
      <categories>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>Java并发编程</tag>
        <tag>CAS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java并发编程艺术 - synchronized使用和原理]]></title>
    <url>%2Fposts%2F43888%2F</url>
    <content type="text"><![CDATA[synchronized属于重量级锁，实现代码同步。 Java SE1.6优化引入了偏向锁和轻量级锁，同时支持锁升级，以减少获取锁和释放锁的性能消耗。 锁的对象synchronized可以修饰Java非空对象，常见3种形式： 锁当前实例修饰普通方法，例如: 12synchronized void add()&#123;&#125; 那么该对象实例将会在执行该方法时阻塞，以保持同步执行，不可并行执行；但是不同对象可以并行执行。 锁类所以对象修饰静态方法、全局变量、类，例如: 12synchronized static void add()&#123;&#125; 12synchronized (Singleton.class)&#123;&#125; 该类所有操作及类实例均会在执行时阻塞，以保持同步执行，不同对象也不可并行执行。 锁方法块 修饰实例或变量 12synchronized (this) &#123;&#125; 12synchronized (var) &#123;&#125; 该类所有操作及类实例均会在执行该代码块时阻塞，以保持同步执行，不同对象也不可并行执行；但对其他代码块不产生影响。 锁的实现synchronized由JVM实现，通过在代码块前后添加monitorenter和monitorexit指令。 线程执行到monitorenter尝试获取对象对应的monitor，即对象锁；如持有monitor锁，则对象处于锁定状态。 Java对象头synchronized锁信息存储在对象头中。 对象头包含Mark Word，存储对象HashCode、分代年龄和锁状态。 锁状态包括轻量锁、重量锁、偏向锁和GC标记。 锁升级锁的4种状态，由低到高： 无锁 偏向锁 轻量锁 重量锁 锁因为竞争可以由低到高升级，不可由高到低降级，以提高锁获取和释放效率。 偏向锁大多数情况，锁是同一线程多次获取，因此引入偏向锁。 在线程获取锁后，在对象头和栈帧中记录线程ID；后续该线程进入和退出代码同步块时不需要CAS获取和释放锁。 偏向锁释放当出现线程竞争偏向锁时，持有偏向锁的线程需要释放偏向锁。 释放偏向锁时，需要等待安全点，即该线程没有正在执行的字节码。 然后暂停拥有偏向锁的线程，若该线程处于不活动状态，将对象头设置为无锁状态；若活着，则重新偏向其他线程。 偏向锁优化偏向锁在程序启动后会延迟激活，-XX:BiasedLockingStartupDelay=0可以关闭延迟。 如果程序通常处于竞争状态，可以通过-XX:-UseBiasedLocking=false关闭偏向锁，那么程序默认会进入轻量级锁状态。 轻量锁轻量锁加锁JVM在执行同步代码块前，先在线程栈帧创建锁记录空间，并将对象头Mark Word复制到锁记录空间。 线程通过CAS将对象头的Mark Word替换为锁记录空间地址；若成功，则获取锁成功。 如失败，则存在锁竞争，线程通过自旋来获取锁。 轻量锁解锁在解锁时，线程采用CAS将锁记录空间信息替换回对象头的Mark Word；若成功，则释放锁。 若失败，则说明存在锁竞争，则升级为重量级锁。 重量锁因为自旋需要消耗CPU，所以轻量锁升级到重量锁后不能降级。 处于重量级锁状态，其他线程获取锁将被阻塞，指导当前线程释放锁并唤醒其他线程竞争。 锁比较 锁 优点 缺点 说明 偏向锁 速度快，和非同步方法执行效率差不多 出现锁竞争时，需要额外释放锁 适合一个线程并发访问同步块 轻量锁 无阻塞，响应速度快 始终得不到锁的线程会自旋消耗CPU 适合方法块执行块，追求响应速度 重量级锁 无自旋，不消耗CPU 阻塞，响应慢 适合同步块执行慢，追求吞吐量]]></content>
      <categories>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>Java并发编程</tag>
        <tag>synchronized</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java并发编程艺术 - volatile使用和原理]]></title>
    <url>%2Fposts%2F34733%2F</url>
    <content type="text"><![CDATA[Java代码经过Java编译器编译成字节码，并由类加载器加载到JVM运行时数据区，最终由JVM执行引擎执行字节码，转换为汇编指令在CPU内执行。 Java并发机制主要依赖JVM实现和CPU指令。 volatilevolatile修饰变量，提供多处理器并发中共享变量的可见性，是轻量的synchronized。 volatile由CPU指令实现，不会引起上下文切换，性能比synchronized高。 可见性问题可见性问题是受Java内存模型的影响。 从上图可知，多线程对共享变量在本地内存进行处理，虽然提高执行效率，但是将带来可见性和数据同步问题。 多线程编程中，对于volatile共享变量，一个线程进行了修改，对于其他线程能及时读取修改后的值，以做到资源同步。 volatile定义如果一个变量被声明为volatile，那么该变量在多线程中将互相可见，保障准确和一致性。 内存屏障/内存栅栏一系列CPU指令，控制内存操作的顺序，可以解决指令重排和可见性问题。 其中，指令重排是JIT对代码的优化。 内存屏障插入策略： 在volatile写前插入storestore，禁止上面普通写与volatile写重排 在volatile写后插入storeload，禁止下面volatile读/写与volatile写重排 在volatile读后插入loadload，禁止下面普通读与volatile写读重排 在volatile读后插入loadstore，禁止下面普通写与volatile读重排 volatile实现原理在共享变量写前，CPU新增Lock操作指令，实现以下效果： 将当期缓存行回写系统内存 其他CPU缓存该内存地址数据无效 为提高处理速度，CPU不和主存直接交互，而是将主存数据读取到缓存，但缓存写回内存时间未知。 通过volatile将通过Lock指令实现写回操作，其他处理器通过总线检查缓存值是否过期；若发现缓存行地址变更，则将缓存行置为无效。 当处理器处理数据时，发现无效标志则会从主存中重新加载数据至缓存。 说明 Lock前缀指令会引起处理器缓存写回内存。Lock可以锁定缓存区域，实现原子操作。 处理器缓存写回操作将引起其他处理的该缓存无效。处理器嗅探缓存地址，若处于共享状态，无效缓存行后，下次访问进行强制缓存行填充。 volatile优化 JDK7追加64字节能够提高LinkedTransferQueue并发编程的效率 缓存的最小单位是缓存行，常见CPU的缓存行是64字节宽(8字节)，不支持部分缓存行。 不满64字节，则缓存队列头和尾至同一缓存行。 当CPU修改头节点，需要锁定缓存行，导致其他CPU不能处理缓存，影响队列入队和出队效率。 追加至64位，填满缓存行，避免队列的头和尾节点被同一缓存行同时锁定。 volatile使用12345678910111213141516171819202122232425262728293031323334public class VolatileTest &#123; //原子变量，缓存无效直接取主存 private volatile int num = 0; //检测值变化 private void test() &#123; while (true) &#123; //测试在一行代码中，num是否会有多个值情况 if (num == 1 &amp;&amp; num == 2 &amp;&amp; num == 3) &#123; System.out.println("不一致"); &#125; &#125; &#125; //修改值 private void change() &#123; while (true) &#123; //频繁修改num值 for (int i = 0; i &lt; 4; i++) &#123; num = i; &#125; &#125; &#125; public void start() &#123; new Thread(this::test).start(); new Thread(this::change).start(); &#125; public static void main(String[] args) &#123; new VolatileTest().start(); &#125;&#125; 结果频繁出现：不一致若不使用volatile，因为线程执行速度快，偶尔会出现不一致但不频繁说明volatile可以实时同步各线程共享变量 volatile修饰用法 volatile 基本变量int\boolean等，例如volatile int a=1；保障可见性 volatile 对象，例如volatile Singleton singleton；防止指令重排 注意 volatile保障变量在线程间的可见性，但不保障操作原子性]]></content>
      <categories>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>Java并发编程</tag>
        <tag>volatile</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Cloud - 如何利用Zuul实现接口限流]]></title>
    <url>%2Fposts%2F33184%2F</url>
    <content type="text"><![CDATA[以下为Zuul利用ratelimit在网关进行接口限流。 限流方案 方案 说明 基于用户id 根据用户标识或匿名 基于用户角色 根据用户角色 基于用户源IP 请求源IP 基于请求URL 下游服务地址 基于请求方法类型 HTTP请求方法，GET、POST等 基于请求服务 下游服务 POM引入123456&lt;!-- 请求限流 --&gt;&lt;dependency&gt; &lt;groupId&gt;com.marcosbarbero.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-zuul-ratelimit&lt;/artifactId&gt; &lt;version&gt;2.0.4.RELEASE&lt;/version&gt;&lt;/dependency&gt; 参数配置1234567891011121314151617181920212223242526272829303132333435#60秒内允许10个访问，并且要求总请求时间小于1000秒#seviceA在120秒内允许20个访问，并且要求总请求时间小于2000秒#seviceA针对匿名用户，IP为10.10.10.10，角色为用户，请求URL为/api/，请求方法为GETzuul: ratelimit: key-prefix: your-prefix #缓存key的前缀 enabled: true #开启限流 repository: REDIS #key存储方式为redis behind-proxy: true # 当前网关是代理后的请求，需要获取Header中的X-FORWARDED-FOR以便获取源IP add-response-headers: true #在response header中添加限流信息 default-policy-list: # 默认策略 - limit: 10 #每个刷新窗口请求数 quota: 1000 #每个刷新窗口总请求时间(秒) refresh-interval: 60 #刷新窗口时间(秒),默认60秒 type: - user #基于用户标识，默认匿名anonymous - origin #基于用户IP - url #基于下游服务URL - httpmethod #基于请求方法 policy-list: #指定服务策略，优先默认 seviceA: #微服务ID - limit: 20 quota: 2000 refresh-interval: 120 type: - user - origin - url - type: #每种类型值设定 - user=anonymous #指定用户,匿名用户 - origin=10.10.10.10 #指定源URL - url=/api #指定下游请求URL前缀 - role=user #指定用户角色 - httpmethod=get #指定请求方法类型，大小写不敏感 其中，user=anonymous和role=user采用Shiro或者Spring Security进行维护，或者自定义request域UserPrincipal。 数据存储 InMemory(ConcurrentHashMap) Redis Consul Spring Data JPA JCache Infinispan Hazelcast Ignite 将会对服务集群的请求情况同步至选择的存储中，以做到数据共享和实时存储。 源码及原理分析自定义key1234567891011121314151617@Bean public RateLimitKeyGenerator ratelimitKeyGenerator(RateLimitProperties properties, RateLimitUtils rateLimitUtils) &#123; return new DefaultRateLimitKeyGenerator(properties, rateLimitUtils) &#123; @Override public String key(HttpServletRequest request, Route route, RateLimitProperties.Policy policy) &#123; //super.key()为默认实现 //keyPrefix+serviceId+(type1Key+...+typenKey) String key= super.key(request, route, policy) ; //":" + request.getMethod() 为自定义策略 key += ":" + request.getMethod(); //实现对key的重写，限流策略是以key为标识依据 return key; &#125; &#125;; &#125; 自定义错误12345678910111213141516171819@Bean public RateLimiterErrorHandler rateLimitErrorHandler() &#123; return new DefaultRateLimiterErrorHandler() &#123; @Override public void handleSaveError(String key, Exception e) &#123; // 处理存储key异常 &#125; @Override public void handleFetchError(String key, Exception e) &#123; // 处理查询key异常 &#125; @Override public void handleError(String msg, Exception e) &#123; // 处理异常信息 &#125; &#125; &#125; 自定义用户和角色SecuredRateLimitUtils.java 12345678@Overridepublic Set&lt;String&gt; getUserRoles() &#123; Authentication authentication = SecurityContextHolder.getContext().getAuthentication(); if (authentication == null) &#123; return emptySet(); &#125; return AuthorityUtils.authorityListToSet(authentication.getAuthorities());&#125; SecurityContextHolder为Spring Security框架，可获取用户角色和标识。 Spring Security样例如下： 12345678@Override protected void configure(AuthenticationManagerBuilder auth) throws Exception &#123; auth .inMemoryAuthentication() .withUser("user") .password("password") .roles("USER"); &#125;]]></content>
      <categories>
        <category>微服务</category>
      </categories>
      <tags>
        <tag>Spring Cloud</tag>
        <tag>Zuul</tag>
        <tag>ratelimit</tag>
        <tag>限流</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Cloud - 如何利用Zuul进行网关开发]]></title>
    <url>%2Fposts%2F33205%2F</url>
    <content type="text"><![CDATA[Zuul介绍Zuul是Spring Cloud全家桶一员，用于微服务网关开发，实现对外服务请求的白黑名单控制、代理转发、限流、权鉴认证、灰度测试等。 Zuul POM引入1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;!-- spring-boot版本 --&gt; &lt;version&gt;2.0.5.RELEASE&lt;/version&gt; &lt;relativePath/&gt;&lt;/parent&gt;&lt;properties&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;!-- Spring Cloud版本 --&gt; &lt;spring-cloud.version&gt;Finchley.RELEASE&lt;/spring-cloud.version&gt;&lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-ribbon&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-zuul&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.retry&lt;/groupId&gt; &lt;artifactId&gt;spring-retry&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;$&#123;spring-cloud.version&#125;&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt; 开启ZuulApplication.java 1234567891011//开启Zuul@EnableZuulProxy@EnableEurekaClient@SpringBootApplicationpublic class Application &#123; public static void main(String[] args) &#123; SpringApplication.run(Application.class,args); &#125;&#125; Zuul配置bootstrap.yml 1234567891011121314151617181920212223242526272829303132333435#路由方式是serviceIdribbon: #对所有操作请求都进行重试 OkToRetryOnAllOperations: true #切换实例的重试次数 MaxAutoRetriesNextServer: 2 #对当前实例的重试次数 MaxAutoRetries: 1 #请求链接的超时时间 ConnectTimeout: 6000 #请求处理的超时时间 ReadTimeout: 8000 eureka: enable: falsezuul: sensitive-headers: #自动重试 retryable: true routes: client-api: #过滤headers，不进入下游 sensitiveHeaders: Cookie,Set-Cookie,Authorization #服务名称 a: #转发匹配规则 path: /api/a/** #直接转发，不过滤前缀 stripPrefix: false #转发到服务ID serviceId: a-service b: path: /api/b/** stripPrefix: false serviceId: b-server Zuul开发在网关统一完成请求过滤和用户认证AccessFilter.java 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113@Component//实现ZuulFilterpublic class AccessFilter extends ZuulFilter &#123; //实现run逻辑 @Override public Object run() &#123; return exec(); &#125; private Object exec() &#123; RequestContext ctx = RequestContext.getCurrentContext(); //获取HttpServletRequest HttpServletRequest request = ctx.getRequest(); //解析ip String ip = getIpAddr(request); //补充到header，可以带入下游 ctx.addZuulRequestHeader("ip", ip); //接口的白名单和黑名单 String url = request.getRequestURI(); //白名单可以直接进入下游 if (isWhite(url)) &#123; return null; &#125; //黑名单禁止访问 if (isBlack(url)) &#123; setBlack(ctx, url); return null; &#125; //token解析 validToken(ctx, url); return null; &#125; /** * 获取用户id，检验token真实性 * * @param ctx * @param url * @return */ void validToken(RequestContext ctx, String url) &#123; // 获取请求的参数 String token = ctx.getRequest().getHeader(Constant.TOKEN); //解析token业务，获取用户信息 String userId = parseToken(token); //传入下游 ctx.addZuulRequestHeader("userId", userId); &#125; public static boolean setBlack(RequestContext ctx, String requestUrl) &#123; logger.error("无权限请求：&#123;&#125;", requestUrl); setStatus(ctx, EnumStatus.ERROR, false); return true; &#125; public static void setStatus(RequestContext ctx, EnumStatus enumStatus, boolean flag) &#123; ctx.getResponse().setContentType("application/json; charset=utf-8"); //令zuul过滤该请求，不对其进行路由，直接返回客户端错误信息， ctx.setSendZuulResponse(false); ctx.setResponseBody("&#123;\"msg\":\"" + enumStatus.getInfo() + "\",\"code\":" + enumStatus.getValue() + "&#125;"); ctx.set("isSuccess", flag); &#125; /** * 是否是白名单 * * @param url * @return */ boolean isWhite(String url) &#123; return Arrays.stream(Constant.WHITE_LIST).anyMatch(s -&gt; url.contains(s)); &#125; /** * 是否是白名单 * * @param url * @return */ boolean isBlack(String url) &#123; return Arrays.stream(Constant.BLACK_LIST).anyMatch(s -&gt; url.contains(s)); &#125; @Override public boolean shouldFilter() &#123; // 是否执行该过滤器，此处为true，说明需要过滤 return true; &#125; @Override public int filterOrder() &#123; // 数字越大，优先级越低 return 0; &#125; @Override public String filterType() &#123; // 前置过滤器 return "pre"; &#125;&#125; 在网关统一处理异常ErrorFilter.java 12345678910111213141516171819202122232425262728293031@Componentpublic class ErrorFilter extends ZuulFilter &#123; private static Logger log = LoggerFactory.getLogger(ErrorFilter.class); @Override public String filterType() &#123; //异常过滤器 return "error"; &#125; @Override public int filterOrder() &#123; //优先级，数字越大，优先级越低 return 30; &#125; @Override public boolean shouldFilter() &#123; //是否执行该过滤器，true代表需要过滤 return true; &#125; @Override public Object run() &#123; RequestContext ctx = RequestContext.getCurrentContext(); setError(ctx, ctx.getRequest().getRequestURL().toString()); return null; &#125;&#125;]]></content>
      <categories>
        <category>微服务</category>
      </categories>
      <tags>
        <tag>Spring Cloud</tag>
        <tag>Zuul</tag>
        <tag>网关</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Cloud - Ribbon在Zuul上实现灰度和版本测试]]></title>
    <url>%2Fposts%2F25628%2F</url>
    <content type="text"><![CDATA[本文依赖ribbon实现在Spring Cloud中的灰度测试。 POM引入Zuul及下游服务中均引入包 123456&lt;!-- 实现灰度测试关键包 --&gt; &lt;dependency&gt; &lt;groupId&gt;io.jmnarloch&lt;/groupId&gt; &lt;artifactId&gt;ribbon-discovery-filter-spring-cloud-starter&lt;/artifactId&gt; &lt;version&gt;2.1.0&lt;/version&gt; &lt;/dependency&gt; Zuul服务开发12345678910111213private void fixGray(UserInfo userInfo) &#123; // 配置转发渠道，例如用户id if (isGrayer(userInfo.getUserId())) &#123; RibbonFilterContextHolder.clearCurrentContext(); //灰度标识 RibbonFilterContextHolder.getCurrentContext().add("prod", "2"); RibbonFilterContextHolder.getCurrentContext().add("prod", "1.0"); &#125; else &#123; RibbonFilterContextHolder.clearCurrentContext(); RibbonFilterContextHolder.getCurrentContext().add("prod", "1"); RibbonFilterContextHolder.getCurrentContext().add("prod", "1.1"); &#125;&#125; 下游服务开发添加版本拦截器 12345678910@Configurationpublic class WebMvcConfig extends WebMvcConfigurerAdapter &#123; @Override public void addInterceptors(InterceptorRegistry registry) &#123; super.addInterceptors(registry); registry.addInterceptor(new VersionInterceptor()); &#125;&#125; 实现拦截器 123456789101112131415public class VersionInterceptor extends HandlerInterceptorAdapter &#123; @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123; //清除现有数据，防止干扰 RibbonFilterContextHolder.clearCurrentContext(); String prod = request.getHeader("prod"); String version = request.getHeader("version"); if (!StringUtils.isEmpty(prod)&amp;&amp;!StringUtils.isEmpty(version)) &#123; RibbonFilterContextHolder.getCurrentContext().add("prod", prod); RibbonFilterContextHolder.getCurrentContext().add("version", version); &#125; return true; &#125;&#125; 下游服务配置12345678910eureka: instance: preferIpAddress: true instance-id: $&#123;spring.cloud.client.ip-address&#125;:$&#123;server.port&#125; metadataMap: #元信息 prod: 2 #灰度标识，1生产服务,2为灰度服务 version: 1.1 #服务版本标识 client: registerWithEureka: true fetchRegistry: true 注意事项 通过以上配置，启动各服务，可以实现灰度测试和版本测试 在网关依据灰度和版本请求标识，Ribbon利用各服务的元信息进行匹配，以实现过滤和负载 服务中必须配置相应的请求标识，否则该请求无法负载，将会报错 关闭组件，ribbon.filter.metadata.enabled=false #默认true 源码及原理分析 元信息筛选 123456789101112131415161718public class MetadataAwarePredicate extends DiscoveryEnabledPredicate &#123; /** * &#123;@inheritDoc&#125; */ @Override protected boolean apply(DiscoveryEnabledServer server) &#123; //当前请求上下文 final RibbonFilterContext context = RibbonFilterContextHolder.getCurrentContext(); //当前请求属性 final Set&lt;Map.Entry&lt;String, String&gt;&gt; attributes = Collections.unmodifiableSet(context.getAttributes().entrySet()); //当前服务元信息 final Map&lt;String, String&gt; metadata = server.getInstanceInfo().getMetadata(); //服务元信息是否完全包含请求属性 return metadata.entrySet().containsAll(attributes); &#125;&#125; 注册实例 123456789101112131415@Configuration@ConditionalOnClass(DiscoveryEnabledNIWSServerList.class)@AutoConfigureBefore(RibbonClientConfiguration.class)@ConditionalOnProperty(value = "ribbon.filter.metadata.enabled", matchIfMissing = true)public class RibbonDiscoveryRuleAutoConfiguration &#123; //在Spring application context注册DiscoveryEnabledRule @Bean @ConditionalOnMissingBean @Scope(ConfigurableBeanFactory.SCOPE_PROTOTYPE) public DiscoveryEnabledRule metadataAwareRule() &#123; //使用自定义元信息过滤 return new MetadataAwareRule(); &#125;&#125; 配置请求信息 RibbonFilterContextHolder.getCurrentContext().add(&quot;version&quot;, &quot;1.1&quot;).add(&quot;variant&quot;, &quot;A&quot;); 在zuul中配置，以便调取下游 在下游拦截器中配置，以便当前服务继续调用下游服务 也可以在RestTemplate的ClientHttpRequestInterceptor中配置]]></content>
      <categories>
        <category>微服务</category>
      </categories>
      <tags>
        <tag>Spring Cloud</tag>
        <tag>Zuul</tag>
        <tag>Ribbon</tag>
        <tag>灰度测试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Cloud - Nacos与Eureka区别及如何选型]]></title>
    <url>%2Fposts%2F35353%2F</url>
    <content type="text"><![CDATA[Nacos与Eureka均提供注册中心和服务治理功能，以下为两者差异和选型方案。 功能差异 模块 Nacos Eureka 说明 注册中心 是 是 服务治理基本功能，负责服务中心化注册 配置中心 是 否 Eureka需要配合Config实现配置中心，且不提供管理界面 动态刷新 是 否 Eureka需要配合MQ实现配置动态刷新，Nacos采用Netty保持TCP长连接实时推送 可用区AZ 是 是 对服务集群划分不同区域，实现区域隔离，并提供容灾自动切换 分组 是 否 Nacos可用根据业务和环境进行分组管理 元数据 是 是 提供服务标签数据，例如环境或服务标识 权重 是 否 Nacos默认提供权重设置功能，调整承载流量压力 健康检查 是 是 Nacos支持由客户端或服务端发起的健康检查，Eureka是由客户端发起心跳 负载均衡 是 是 均提供负责均衡策略，Eureka采用Ribion 管理界面 是 否 Nacos支持对服务在线管理，Eureka只是预览服务状态 部署安装 模块 Nacos Eureka 说明 MySql 是 否 Nacos需要采用MySql进行数据进行持久化 MQ 否 是 Eureka需要采用MQ进行配置中心刷新 配置中心 是 否 Eureka结合Config或者Consul实现配置中心 配置文件 在线编辑 本地文件或者Git远程文件 Eureka结合Config或者Consul 集群 是 是 Nacos需要配置集群ip再启动 稳定及扩展性 模块 Nacos Eureka 说明 版本 1.0.0 1.9.9 Eureka2.0已停止开发,Nacos处于1.x-2.0开发 厂商 阿里巴巴 Netflix Netflix已长期用于生产,阿里刚起步 生产建议 否 是 Nacos0.8以前不可用于生产,建议生产采用Nacos1.0,便于节省配置中心集群和服务管理 未来发展 是 否 Nacos 2.0主要关注在统一服务管理、服务共享及服务治理体系的开放的服务平台的建设 选型建议采用Eureka方案的考虑 想用Spring Cloud原生全家桶 想用本地文件和Git作为配置管理的,将配置与服务分开管理 考虑短期的稳定性 采用Nacos方案的考虑 想在线对服务进行上下线和流量管理 不想采用MQ实现配置中心动态刷新 不想新增配置中心生产集群 考虑引入Spring Cloud Alibaba生态]]></content>
      <categories>
        <category>微服务</category>
      </categories>
      <tags>
        <tag>Spring Cloud</tag>
        <tag>Nacos</tag>
        <tag>Eureka</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux运维常用命令]]></title>
    <url>%2Fposts%2F48230%2F</url>
    <content type="text"><![CDATA[以下为Linux开发中常用的命令。 筛选文本并查看指定上下行数常用于筛选日志，并查看上下文 grep [选项] ‘模式’ [文件] 选项: -A 后几行 -B 前几行 -C 前后几行 模式: 待筛选文本 文件: 待筛选源文件举例 123grep -A 20 'cat' info.log # 显示info.log及后20行grep -B 20 'cat' info.log # 显示info.log及前20行grep -C 20 'cat' info.log # 显示info.log文件里匹配cat字串行以及上下20行 zcat用于不真正解压缩文件，就能显示压缩包中文件的内容的场合。 1zcat log.gz |grep '000' 查看linux内存使用情况命令 1free -m 结果 123 total used free shared buff/cache availableMem: 64083 42542 6321 210 15219 20451Swap: 0 0 0 Mem:内存的使用情况总览表 totel:机器总的物理内存 单位为：M used:用掉的内存 free:空闲的物理内存 shared:多个进程共享的内存总和，当前废弃不用 buffers:缓存内存数 cached:缓存内存数注： 物理内存(totel)=系统看到的用掉的内存(used)+系统看到空闲的内存(free) 程序预留的内存=buffers+cached buffer是即将要写入磁盘的，而cache是被从磁盘中读出来的 进程查看器htop 1yum install htop 界面划分成了四个区域，其中： 上左区：显示了CPU、物理内存和交换分区的信息； 上右区：显示了任务数量、平均负载和连接运行时间等信息；平均负载表示的是过去的5分钟、10分钟和15分钟系统的平均负载； 进程区域：显示出当前系统中的所有进程； 123456789101112PID：进程标志号，是非零正整数USER：进程所有者的用户名PR：进程的优先级别NI：进程的优先级别数值VIRT：进程占用的虚拟内存值RES：进程占用的物理内存值SHR：进程使用的共享内存值S：进程的状态，其中S表示休眠，R表示正在运行，Z表示僵死状态，N表示该进程优先值是负数%CPU：该进程占用的CPU使用率%MEM：该进程占用的物理内存和总内存的百分比TIME+：该进程启动后占用的总的CPU时间COMMAND：进程启动的启动命令名称 操作提示区：显示了当前界面中F1-F10功能键中定义的快捷功能。 压缩解压.gz 123解压1：gunzip FileName.gz解压2：gzip -d FileName.gz压缩：gzip FileName tar 压缩多个包为1个 1tar czvf xx.tar xx-2019-10-1*.log.gz 查看系统负载CPU的负载情况(load average)，uptime、w和top等命令都可以看到load average指标，从左至右三个数字分别表示1分钟、5分钟、15分钟的load average。 Load Average指的是在一段时间内CPU正在处理以及等待CPU处理的进程数之和的统计信息，也就是CPU使用队列的长度的统计信息。 Load Average反映了CPU的使用情况和申请情况. 系统的load是指正在运行running one和准备好运行runnable one的进程的总数。比如现在系统有2个正在运行的进程，3个可运行进程，那么系统的load就是5。load average就是一定时间内的load数量。 load average计算： 1234static unsigned long count_active_tasks(void)&#123; return (nr_running() + nr_uninterruptible()) * FIXED_1;&#125; count_active_tasks()返回当前的活跃进程数，其中活跃进程包括:1）当前正在运行的进程（nr_running）；2）不可中断的sleeping进程（如正在执行IO操作的被挂起进程）。 uptime 116:36 up 3 days, 8:08, 4 users, load averages: 2.56 2.50 2.36 单核满载是 1，有 n 核满载是 n。两个相同的系统，一个负载是 3，一个负载是 6，如果只看 CPU 占用率，大家都是 100% ，能看出哪个系统当前的压力大吗？高负载时一般 CPU 都是 100%，要了解系统的压力，负载指标就比 CPU百分比更有意义。 Load Average所包含的信息不是CPU的使用率状况。多任务环境下，系统分配时间片以后，是否使用完全使用时间片取决于进程，因此完全可能出现低CPU利用率而高Load Average的情况 load是从/proc/loadavg中读取的。 12cat /proc/loadavg2.18 2.49 2.50 3/3491 15317 每个值的含义依次为：lavg_1 (2.18) 1-分钟平均负载lavg_5 (2.49) 5-分钟平均负载lavg_15(2.50) 15-分钟平均负载nr_running (3) 在采样时刻，运行队列的任务的数目，与/proc/stat的procs_running表示相同意思nr_threads (3491) 在采样时刻，系统中活跃的任务的个数（不包括运行已经结束的任务）last_pid(15317) 最大的pid值，包括轻量级进程，即线程。假设当前有2个CPU，则每个CPU的当前任务数为2.18/2=1.09 所以“Load值&lt;=CPU核数”，这是最理想的状态，没有任何竞争，一个任务分配一个核。一般认为负载为0.7是警戒线。 top123456789101112top - 01:06:48 up 1:22, 1 user, load average: 0.06, 0.60, 0.48Tasks: 29 total, 1 running, 28 sleeping, 0 stopped, 0 zombieCpu(s): 0.3% us, 1.0% sy, 0.0% ni, 98.7% id, 0.0% wa, 0.0% hi, 0.0% siMem: 191272k total, 173656k used, 17616k free, 22052k buffersSwap: 192772k total, 0k used, 192772k free, 123988k cachedPID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND1379 root 16 0 7976 2456 1980 S 0.7 1.3 0:11.03 sshd14704 root 16 0 2128 980 796 R 0.7 0.5 0:02.72 top1 root 16 0 1992 632 544 S 0.0 0.3 0:00.90 init2 root 34 19 0 0 0 S 0.0 0.0 0:00.00 ksoftirqd/03 root RT 0 0 0 0 S 0.0 0.0 0:00.00 watchdog/0 123456789统计信息区前五行是系统整体的统计信息。第一行是任务队列信息，同 uptime 命令的执行结果。其内容如下：01:06:48 当前时间up 1:22 系统运行时间，格式为时:分1 user 当前登录用户数load average: 0.06, 0.60, 0.48 系统负载，即任务队列的平均长度。三个数值分别为 1分钟、5分钟、15分钟前到现在的平均值。 123456789101112131415161718192021第二、三行为进程和CPU的信息。当有多个CPU时，这些内容可能会超过两行。内容如下：Tasks: 29 total 进程总数1 running 正在运行的进程数28 sleeping 睡眠的进程数0 stopped 停止的进程数0 zombie 僵尸进程数Cpu(s): 0.3% us 用户空间占用CPU百分比1.0% sy 内核空间占用CPU百分比0.0% ni 用户进程空间内改变过优先级的进程占用CPU百分比98.7% id 空闲CPU百分比0.0% wa 等待输入输出的CPU时间百分比 123456789最后两行为内存信息。内容如下： Mem: 191272k total 物理内存总量 173656k used 使用的物理内存总量 17616k free 空闲内存总量 22052k buffers 用作内核缓存的内存量 Swap: 192772k total 交换区总量 0k used 使用的交换区总量 192772k free 空闲交换区总量 123988k cached 缓冲的交换区总量。 123456789101112131415161718192021222324252627282930313233进程信息区统计信息区域的下方显示了各个进程的详细信息。首先来认识一下各列的含义。列名 含义PID 进程idPPID 父进程idRUSER Real user nameUID 进程所有者的用户idUSER 进程所有者的用户名GROUP 进程所有者的组名TTY 启动进程的终端名。不是从终端启动的进程则显示为 ?PR 优先级NI nice值。负值表示高优先级，正值表示低优先级P 最后使用的CPU，仅在多CPU环境下有意义%CPU 上次更新到现在的CPU时间占用百分比TIME 进程使用的CPU时间总计，单位秒TIME+ 进程使用的CPU时间总计，单位1/100秒%MEM 进程使用的物理内存百分比VIRT 进程使用的虚拟内存总量，单位kb。VIRT=SWAP+RESSWAP 进程使用的虚拟内存中，被换出的大小，单位kb。RES 进程使用的、未被换出的物理内存大小，单位kb。RES=CODE+DATACODE 可执行代码占用的物理内存大小，单位kbDATA 可执行代码以外的部分(数据段+栈)占用的物理内存大小，单位kbSHR 共享内存大小，单位kbnFLT 页面错误次数nDRT 最后一次写入到现在，被修改过的页面数。S 进程状态。 D=不可中断的睡眠状态 R=运行 S=睡眠 T=跟踪/停止 Z=僵尸进程COMMAND 命令名/命令行WCHAN 若该进程在睡眠，则显示睡眠中的系统函数名Flags 任务标志，参考 sched.h]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java并发编程艺术 - 死锁产生及优化]]></title>
    <url>%2Fposts%2F20463%2F</url>
    <content type="text"><![CDATA[本文介绍死锁产生的条件及优化方案。 死锁产生 线程互相等待 常见的死锁有JDK死锁和数据库死锁。 以JDK死锁为例： 12345678910111213141516171819202122232425262728293031323334353637383940public class Deadlock &#123; static class Friend &#123; private final String name; public Friend(String name) &#123; this.name = name; &#125; public String getName() &#123; return this.name; &#125; //同步锁bow public synchronized void bow(Friend bower) &#123; System.out.format("%s: %s" + " has bowed to me!%n", this.name, bower.getName()); //调用同步锁bowBack bower.bowBack(this); &#125; //同步锁bowBack public synchronized void bowBack(Friend bower) &#123; System.out.format("%s: %s" + " has bowed back to me!%n", this.name, bower.getName()); &#125; &#125; public static void main(String[] args) &#123; final Friend alphonse = new Friend("Alphonse"); final Friend gaston = new Friend("Gaston"); new Thread(new Runnable() &#123; public void run() &#123; alphonse.bow(gaston); &#125; &#125;).start(); new Thread(new Runnable() &#123; public void run() &#123; gaston.bow(alphonse); &#125; &#125;).start(); &#125;&#125; 输出： 12Alphonse: Gaston has bowed to me!Gaston: Alphonse has bowed to me! 分析： 执行程序期望是alphonse向gaston鞠躬，并等待gaston还礼；gaston向alphonse鞠躬，并等待alphonse还礼。 两个线程，分别是alphonse线程和gaston线程；alphonse线程传入gaston对象，gaston传入alphonse对象，均执行执行bowBack。 问题是：如果单线程执行，例如alphonse线程执行，结果会是： 12Alphonse: Gaston has bowed to me!Gaston: Alphonse has bowed back to me! 多线程执行时，alphonse和gaston互相鞠躬，但是均等待对方回礼，则在bowBack产生等待死锁。 alphonse和gaston均为对象锁，但是内部进行了互相调用bowBack(Friend bower)。 alphonse获得对象锁，gaston获得对象锁。 alphonse同步调用bow，gaston同步调用bow；没有问题，不会死锁。 alphonse同步锁继续，使用gaston对象调用bowBack，但是gaston也在使用alphonse对象调用bowBack，产生问题。 alphonse-&gt;gaston-&gt;bowBack;gaston-&gt;alphonse-&gt;bowBack;因此alphonse和gaston对象锁都互相加锁且等待对方释放锁，导致死锁。 死锁查看 查看进程执行情况： 1jstack -l 69733 或者采用VisualVM，查看两个对象锁处于等待状态 除了死锁还有活锁、饥饿锁 Oracle说明 避免死锁方法 避免一个线程操作获取多个锁，例如上例中一个方法内获取两个对象锁 避免一个线程在锁内占用多个资源，尽量保证每个锁占用一个，例如上例一个方法期望锁定两个对象 采用定时锁，即lock.tryLock(timeout)，即在限定时间内获取锁，获取不到则放弃，防止死锁等待 123456789/** * @return &#123;@code true&#125; 如果当前线程请求到锁或者本来就拥有锁 * @throws InterruptedException if the current thread is interrupted * @throws NullPointerException if the time unit is null */ public boolean tryLock(long timeout, TimeUnit unit) throws InterruptedException &#123; return sync.tryAcquireNanos(1, unit.toNanos(timeout)); &#125; 对于数据库锁，加锁和解锁在一个数据库连接，否则解锁失败。同一个对象锁进行加锁和解锁操作。 123456789try &#123; //关闭事务自动提交(开启事务) this.connection.setAutoCommit(false); //无异常，手动提交 this.connection.commit();&#125; catch(Exception e) &#123; //当前；连接回滚 this.connection.rollback();&#125; 并发包JUC使用 参考Orace文档]]></content>
      <categories>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>Java并发编程</tag>
        <tag>多线程</tag>
        <tag>死锁</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[搭建GitHub博客教程 - Hexo及Next主题优化]]></title>
    <url>%2Fposts%2F60068%2F</url>
    <content type="text"><![CDATA[本文为针对Hexo博客和Next主题的优化和配置。 标题配置vi _config_yml 1234567title: xxx的技术博客subtitle: xxxdescription: xxkeywords: xxxauthor: xxlanguage: zh-CNtimezone: Asia/Chongqing 首页文章预览限制字数cd themes/next vi _config.yml 123auto_excerpt: enable: true length: 150 文章内使用&lt;!--more--&gt;作为预览分割 修改文章内链接文本样式./themes/next/source/css/_common/components/post/post.styl 末尾添加： 1234567891011// 文章内链接文本样式.post-body p a&#123; color: #0593d3; border-bottom: none; border-bottom: 1px solid #0593d3; &amp;:hover &#123; color: #fc6423; border-bottom: none; border-bottom: 1px solid #fc6423; &#125;&#125; 样式优化cd themes/next vi _config.yml 12345678910111213141516171819202122232425262728293031323334scheme: Piscesgithub_banner: enable: true permalink: https://github.com/xxxx title: Follow me on GitHubback2top: enable: true # Back to top in sidebar. sidebar: true # Scroll percent label in b2t button. scrollpercent: true //加载条pace: true//阅读统计busuanzi_count: enable: true//头像avatar: # In theme directory (source/images): /images/avatar.gif # In site directory (source/uploads): /uploads/avatar.gif # You can also use other linking images. url: http://xx/xxx.jpeg # If true, the avatar would be dispalyed in circle. rounded: true # The value of opacity should be choose from 0 to 1 to set the opacity of the avatar. opacity: 1 # If true, the avatar would be rotated with the cursor. rotated: true favicon.ico 放入/themes/next/source/images 123favicon: small: /images/favicon.png medium: /images/favicon.png 开启标签和分类主要是设置页面类型及关闭评论 创建 12hexo new page tagshexo new page categories 修改主题配置vi ./source/tags/index.md 1234title: tagsdate: 2019-04-20 14:24:27type: "tags"comments: false vi ./source/tags/index.md 1234title: tagsdate: 2019-04-20 14:24:27type: "tags"comments: false 菜单修改主要是打开菜单及统计 vi ./themes/next/_config.yml 123456789menu: home: / || home tags: /tags/ || tags categories: /categories/ || th archives: /archives/ || archive menu_settings: icons: true badges: true RSS、搜索、永久链接1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859npm install hexo-generator-feed --savenpm install hexo-generator-searchdb --savenpm install hexo-symbols-count-time --savenpm i --save hexo-wordcountnpm install hexo-abbrlink --savevi _config.ymlpermalink: posts/:abbrlink/feed: type: atom path: atom.xml limit: 20 hub: content: content_limit: 140 content_limit_delim: ' '# 搜索search: path: search.xml field: post format: html limit: 10000# 时间统计symbols_count_time: count: Symbols count in article count_total: Symbols count total time: Reading time time_total: Reading time total time_minutes: mins.# 字数统计post_wordcount: item_text: true #字数统计 wordcount: true #预览时间 min2read: true #总字数,显示在页面底部 totalcount: false separated_meta: true vi ./themes/next/_config.ymlrss: /atom.xmllocal_search: enable: true symbols_count_time: separated_meta: true item_text_post: true item_text_total: true awl: 4 wpm: 275 pm2 restart allhexo shexo cleanhexo g 本文结束在路径/themes/next/layout/_macro中新建 passage-end-tag.swig 文件,并添加以下内容： 12345&lt;div&gt; &#123;% if not is_index %&#125; &lt;div style="text-align:center;color: #ccc;font-size:14px;"&gt;------ 本文结束------&lt;/div&gt; &#123;% endif %&#125;&lt;/div&gt; 打开themes/next/layout/_macro/下的post.swig文件,添加： 12345678&#123;#####################&#125;&#123;### END POST BODY ###&#125;&#123;#####################&#125;&lt;div&gt; &#123;% if not is_index %&#125; &#123;% include 'passage-end-tag.swig' %&#125; &#123;% endif %&#125; &lt;/div&gt; 注意添加位置 vi ./themes/next/_config.yml,在末尾添加： 123# 文章末尾添加“本文结束”标记passage_end_tag: enabled: true SEO安装与配置1234567npm install hexo-generator-sitemap --savenpm install hexo-generator-baidu-sitemap --savesitemap: path: sitemap.xmlbaidusitemap: path: baidusitemap.xml 在hexo-site\source中新建文件robots.txt,内容如下，请自行替换 123456789101112131415User-agent: *Allow: /Allow: /archives/Allow: /categories/Allow: /tags/ Allow: /about/ Disallow: /vendors/Disallow: /js/Disallow: /css/Disallow: /fonts/Disallow: /vendors/Disallow: /fancybox/Sitemap: https://xxx.github.com/sitemap.xmlSitemap: https://xxx.github.com/baidusitemap.xml google登录https://search.google.com/search-console/welcome 网址前缀-&gt;其他验证方法-&gt;HTML标记，复制meta代码。 百度123vi themes/next/_config.ymlbaidu_push: true 登录https://ziyuan.baidu.com/linksubmit/url 站点管理-&gt;新建站点 HTML标签验证-&gt;复制meta代码 验证1vi ./themes/next/layout/_partials/head/head.swig 在meta下添加google的meta代码。 1hexo clean &amp;&amp; hexo g &amp;&amp; hexo d 然后分别点击刚才 百度、谷歌 验证页面的 验证 按钮进行站点验证。 提交sitemap谷歌 在https://search.google.com/search-console中添加新的站点地图 输入/sitemap.xml 百度 在https://ziyuan.baidu.com/linksubmit/index链接提交-&gt;自动提交-&gt;sitemap 输入:https://xxxx.github.io/baidusitemap.xml 坑：GitHub Pages 禁止百度爬虫，且需要HTTPS认证，提供自定义域名。 百度站点统计访问注册https://tongji.baidu.com/web/welcome/login Baidu Analytics ID: hm.src = https://hm.baidu.com/hm.js?`81b7a9fddbd9b9470364a87a43991a67`; 12vi themes/next/_config.ymlbaidu_analytics: 81b7a9fddbd9b9470364a87a43991a67 评论注册OAuth Application在GitHub上注册新应用, 链接:https://github.com/settings/applications/new 12345Application name 应用名称, 可以任意填入Homepage URL 网站URL, 注意用https://开头, 开头如https://vonsdite.cnApplication description 应用描述, 可以任意填入Authorization callback URL 网站URL, 注意用https://开头, 如https://vonsdite.cn注册后记下Client ID和Client Secret, 后续要使用到 修改主题配置文件_config.yml 在主题配置文件themes/next/_config.yml中添加如下内容: 12345678gitalk: enable: true githubID: github帐号 # 例：vonsdite 注意必须小写 repo: 仓库名称 # 例：vonsdite.github.io ClientID: Client ID # 上文注册 OAuth Application后得到的值 ClientSecret: Client Secret # 上文注册 OAuth Application后得到的值 adminUser: github帐号 # 指定可初始化评论账户, 例：vonsdite 注意必须小写 distractionFreeMode: true 版权声明主题配置文件 12345creative_commons: license: by-nc-sa sidebar: false post: true language: 相关文章npm install hexo-related-popular-posts --save 主题配置 123456related_posts: enable: true title: # custom header, leave empty to use the default one display_in_home: false params: maxCount: 5 图片大小配置下载 存储路径:./themes/next/source/js/hexo_resize_image.js 修改./themes/next/layout/_partials/head/head.swig 添加 1&lt;script src=&quot;&#123;&#123; url_for(theme.js) &#125;&#125;/hexo_resize_image.js?v=&#123;&#123; version &#125;&#125;&quot;&gt;&lt;/script&gt; 使用语法： url?&lt;width&gt;x&lt;height&gt;，指定宽高，例如/image/test.jpg?200x200 url?&lt;width&gt;x&lt;height&gt;，指定宽，高等比缩放，例如/image/test.jpg?200x url?&lt;width&gt;x&lt;height&gt;，指定高，宽等比缩放，例如/image/test.jpg?x200 url?缩放比例，指定缩放例如，例如/image/test.jpg?50 进度条1234567cd themes/nextgit clone https://github.com/theme-next/theme-next-pace source/lib/pacevi _config.ymlpace: true]]></content>
      <categories>
        <category>工具利器</category>
      </categories>
      <tags>
        <tag>工具</tag>
        <tag>Hexo</tag>
        <tag>GitHub</tag>
        <tag>Next</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Cloud - Nacos集群配置和集成]]></title>
    <url>%2Fposts%2F57096%2F</url>
    <content type="text"><![CDATA[本文介绍生产环境中Nacos集群的安装配置，及与Spring Cloud的集成。 Nacos介绍类似于Spring Cloud Eureka和Spring Cloud Config，Nacos提供了服务注册管理和配置中心的功能；其中配置中心实现动态刷新，无需MQ。 相对于Eureka，Nacos是由阿里提供的开源服务，可以兼容Spring Cloud，也支持其他语言例如python服务的注册管理。 Nacos安装 环境要求： 64 bit JDK 1.8+ MySql 5.6.5+ 安装包下载当前版本 1.0.0 解压unzip nacos-server-$version.ziptar -xvf nacos-server-$version.tar.gz Nacos配置 MySql内执行sql/nacos/conf/nacos-mysql.sql 数据源配置/nacos/conf/application.properties 12345spring.datasource.platform=mysqldb.num=1db.url.0=jdbc:mysql://xxx:3306/nacos_config?characterEncoding=utf8&amp;connectTimeout=1000&amp;socketTimeout=3000&amp;autoReconnect=truedb.user=xxxdb.password=xxx 集群配置/nacos/conf/cluster.conf 123192.168.1.100:8848192.168.1.101:8848192.168.1.102:8848 在100-102机器上，复制存储nacos文件。 Nginx负载均衡部署集群后，由3台集群提供管理界面，可以配置Nginx进行负载。 123456789101112131415161718upstream nacos_cluster &#123; server 192.168.1.100:8848; server 192.168.1.101:8848; server 192.168.1.102:8848;&#125;server&#123; listen 80; server_name localhost; location / &#123; proxy_pass http://nacos_cluster; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; &#125;&#125; 8848为管理系统端口访问localhost,可以进入Nacos管理界面默认用户名和密码是nacos/nacosusers表存储的是用户名、密码，可以进行修改new BCryptPasswordEncoder().encode(“nacos”)修改密码 启动和关闭 /nacos/bin 启动 sh startup.sh 启动后打印的关键参数 -server -Xms2g -Xmx2g -Xmn1g -XX:MetaspaceSize=128m -XX:MaxMetaspaceSize=320m -XX:-OmitStackTraceInFastThrow -XX:+HeapDumpOnOutOfMemoryError -XX:-UseLargePages -verbose:gc -XX:+PrintGCDetails -XX:+PrintGCDateStamps -XX:+PrintGCTimeStamps -XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles=10 -XX:GCLogFileSize=100M关闭 sh shutdown.sh Spring Cloud集成Nacospom引入12345678910111213141516171819202122232425262728293031323334353637383940414243&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.0.5.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;/parent&gt;&lt;properties&gt; &lt;spring-cloud-alibaba-dependencies.version&gt;0.2.1.RELEASE&lt;/spring-cloud-alibaba-dependencies.version&gt; &lt;spring-cloud.version&gt;Finchley.RELEASE&lt;/spring-cloud.version&gt;&lt;/properties&gt;&lt;dependencies&gt; &lt;!-- nacos服务注册与发现 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- nacos分布式配置 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-config&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt;&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;$&#123;spring-cloud.version&#125;&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-alibaba-dependencies&lt;/artifactId&gt; &lt;version&gt;$&#123;spring-cloud-alibaba-dependencies.version&#125;&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt; 配置参数Application.java 123456789@EnableDiscoveryClient@SpringBootApplication@RefreshScope@EnableFeignClientspublic class Application&#123; public static void main(String[] args) &#123; SpringApplication.run(Application.class, args); &#125;&#125; bootstrap.yml 1234567891011spring: application: name: xxxx profiles: active: dev cloud: nacos: discovery: server-addr: 192.168.1.100:8848,192.168.1.101:8848,192.168.1.102:8848 #注册中心地址集群 config: server-addr: 192.168.1.100:8848,192.168.1.101:8848,192.168.1.102:8848 #配置中心地址集群 fegin测试1234567@FeignClient(value = "xxxx")public interface XXXServer &#123; // 获取主码描述 @RequestMapping(path = "/api/xxxx", method = RequestMethod.POST) String getInfo();&#125;]]></content>
      <categories>
        <category>微服务</category>
      </categories>
      <tags>
        <tag>Spring Cloud</tag>
        <tag>Nacos</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java并发编程艺术 - 多线程与资源限制]]></title>
    <url>%2Fposts%2F10420%2F</url>
    <content type="text"><![CDATA[文本介绍多线程和资源的关系。 是否多线程越多速度越快？ 结论：并发编程中采用多线程，并非线程越多执行效率越高。 线程执行是由CPU分配较短的时间片，线程在得到时间片时执行，并在时间片后挂起，并切换其他线程执行。 线程切换时先会保存上一个线程状态，并加载当前线程的历史状态。 因为线程的上下文切换需要时间，影响多线程执行速度。 在执行某些简单、快速任务情况下，多线程执行效率还不如单线程执行。假如单核采用单线程执行任务仅需要20ms，但单核采用多线程，并发100，可能创建线程时间就超出20ms，再加上单核只能执行单线程，需要多线程频繁挂起、上下文切换肯定慢。 在低核时，不建议采用多线程进行CPU密集型计算；建议采用多线程执行监听输入、读取文件、网络通信等IO密集型操作。 如何减少上下文切换 采用无锁的并发编程，即不进行锁竞争；例如根据ID进行Hash取模，多线程进行分段处理数据。我们常见的JDK1.7中ConcurrentHashMap就是锁分段技术，对key进行hashcode，然后取桶位置，默认1/16；在更新数据时锁数据所在桶，不影响其他桶并发操作，以提高并发处理数据速度。 12345678910111213141516public V put(K key, V value) &#123; if (value == null) throw new NullPointerException(); // 计算键对应的散列码 int hash = hash(key.hashCode()); // 根据散列码找到对应的 Segment return segmentFor(hash).put(key, hash, value, false);&#125;/*** 使用 key 的散列码来得到 segments 数组中对应的 Segment*/final Segment&lt;K,V&gt; segmentFor(int hash) &#123; // 最后根据下标值返回散列码对应的 Segment 对象 return segments[(hash &gt;&gt;&gt; segmentShift) &amp; segmentMask];&#125; CAS算法，JAVA采用Atomic的CAS算法进行乐观锁更新数据，不进行加锁。所谓CAS其实就是compareAndSwap即比较并交换，参数有3个为old、expect和update；即如果old和expect仍然一致，没有因为并发和内存不可见性被修改，则修改old为update。 例如AtomicInteger中进行变量自增： 123456789101112131415161718192021/** * 通过当前值进行原子递增. * * @return 更新值 */public final int incrementAndGet() &#123; return unsafe.getAndAddInt(this, valueOffset, 1) + 1;&#125;public final int getAndAddInt(Object var1, long var2, int var4) &#123; int var5; do &#123; var5 = this.getIntVolatile(var1, var2); &#125; while(!this.compareAndSwapInt(var1, var2, var5, var5 + var4));//cas操作 return var5;&#125;public final boolean compareAndSet(int expect, int update) &#123; return unsafe.compareAndSwapInt(this, valueOffset, expect, update);&#125; 采用最小线程。避免不必要的线程，处于等待状态。 例如JUC包Executors类创建线程池参数，corePoolSize为核心线程数量，如allowCoreThreadTimeOut不设置，可以认为corePoolSize是最小线程数。 如果设置和maximumPoolSize一样大，则表示即使达到keepAliveTime空闲时间也不回收，均处于waiting状态。 123456789101112131415161718192021222324252627282930313233343536373839404142/** * 创建单个线程 * * @param threadFactory 线程工厂 * * @return 单线程执行器 * @throws NullPointerException if threadFactory is null */public static ExecutorService newSingleThreadExecutor(ThreadFactory threadFactory) &#123; return new FinalizableDelegatedExecutorService (new ThreadPoolExecutor(1, 1, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;(), threadFactory));&#125;/** * 根据参数和配置，创建线程池. * * @param corePoolSize 池中核心线程数 * @param maximumPoolSize 池中最大线程数 * @param keepAliveTime 线程数大于核心线程数时, 多余的待回收线程最大空闲时间 * @param unit 时间单位 * @param workQueue 任务执行队列 * @param threadFactory 创建线程的工厂 * @throws IllegalArgumentException if one of the following holds:&lt;br&gt; * &#123;@code corePoolSize &lt; 0&#125;&lt;br&gt; * &#123;@code keepAliveTime &lt; 0&#125;&lt;br&gt; * &#123;@code maximumPoolSize &lt;= 0&#125;&lt;br&gt; * &#123;@code maximumPoolSize &lt; corePoolSize&#125; * @throws NullPointerException if &#123;@code workQueue&#125; * or &#123;@code threadFactory&#125; is null */public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory) &#123; this(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue, threadFactory, defaultHandler);&#125; 协程。在单线程中实现多任务的调度，并在单线程中维持多任务的切换。 资源限制的挑战 并发编程受限与机器硬件或软件资源。例如带宽、硬盘读写速度等硬件资源和数据库连接数、socket连接数等软件资源。 并发编程为加快执行速度，将串行任务并发执行，受资源影响，实际仍在串行切换执行，切换上下文和资源调度反而降低执行速度。 解决资源限制，采用集群执行，改单机为多机。对数据id取机器数模，在该机器处理该数据；软件资源考虑资源池复用，NIO等。 在资源限制下并发编程，根据资源调整并发度，例如读写分离，读写锁等。]]></content>
      <categories>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>Java并发编程</tag>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[IDEA开发快捷键 - Mac]]></title>
    <url>%2Fposts%2F10018%2F</url>
    <content type="text"><![CDATA[本文介绍IDEA中进行Java开发的常用快捷键。 编辑撤销： ⌘+Z切换大小写： ⇧+⌘+U上一个位置： ⌥+⌘+←下一个位置： ⌥+⌘+→(反)注释行： ⌘+/(反)注释块： ⌥+⌘+/格式化： ⌥+⌘+L生成构造器： ⌘+N查看方法实现： ⌥+⌘+B删除当前或者选中块行： ⌘+⌫查找全局查找： ⇧+⇧]]></content>
      <categories>
        <category>工具利器</category>
      </categories>
      <tags>
        <tag>IDEA</tag>
        <tag>工具</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[快速搭建GitHub博客教程 - Hexo及Next主题安装]]></title>
    <url>%2Fposts%2F17587%2F</url>
    <content type="text"><![CDATA[本文为在Mac上利用Hexo搭建GitHub博客过程，选择主题为Next。 Git安装和配置Git安装 下载地址：downloads 选择Mac版本并安装 确认安装成功 1git --version Git GUI安装 下载地址：git-scm 建议：命令行用git bash，工具用SourceTree git常用命令：gittutorial Git私钥公钥配置 生成公钥和私钥 Github配置注册 地址:注册 创建Respository new Repository name:[username].github.io 配置公钥 settings 新建SSH Keys，输入本地公钥 查看本地公钥：cd ~ cd .ssh/cat id_rsa.pub拷贝结果至github的SSH Keys Hexo安装和配置Hexo安装 安装：npm install -g hexo-cli 初始化目录 hexo init [folder] hexo Next主题安装 cd hexo git clone https://github.com/theme-next/hexo-theme-next themes/next hexo-theme-next Hexo主题配置 vi _config.yml 修改theme: next Hexo配置Github部署地址 安装插件 npm install hexo-deployer-git –save 修改Hexo vi _config.yml，修改内容如下: 1234deploy: type: git repo: git@github.com:username/username.github.io.git brach: master deployment hexo-deployer-git Hexo操作12345hexo s，启动hexo d -g，生成并发布hexo new ’title‘，新建文章 参考文档 Mac后台启动Hexo服务准备工作 安装pm2 npm install -g pm2 编辑脚本代码 在hexo博客的根目录下新建run.js文件 12345678910//run.jsconst &#123; exec &#125; = require('child_process')exec('hexo s',(error, stdout, stderr) =&gt; &#123; if(error)&#123; console.log(`exec error: $&#123;error&#125;`) return &#125; console.log(`stdout: $&#123;stdout&#125;`); console.log(`stderr: $&#123;stderr&#125;`);&#125;) 运行 pm2 start run.js 重启pm2 restart all]]></content>
      <categories>
        <category>工具利器</category>
      </categories>
      <tags>
        <tag>工具</tag>
        <tag>Hexo</tag>
        <tag>GitHub</tag>
        <tag>Next</tag>
      </tags>
  </entry>
</search>
