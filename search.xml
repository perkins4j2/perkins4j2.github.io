<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Java Lambda Stream原理]]></title>
    <url>%2Fposts%2F42366%2F</url>
    <content type="text"><![CDATA[举例1234567List list = new ArrayList(1); list.add(1); list.add(2); list.stream().forEach( System.out::println ); List.stream方法1234567891011121314default Stream&lt;E&gt; stream() &#123; return StreamSupport.stream(spliterator(), false);&#125;@Overridedefault Spliterator&lt;E&gt; spliterator() &#123; return Spliterators.spliterator(this, 0);&#125;public static &lt;T&gt; Spliterator&lt;T&gt; spliterator(Collection&lt;? extends T&gt; c, int characteristics) &#123; return new IteratorSpliterator&lt;&gt;(Objects.requireNonNull(c), characteristics);&#125; List的stream()接口位于java.util.Collection类中；默认实现输入的参数1是拆分方法spliterator，2是并行默认false。spliterator()接口也在该类中，默认实现调用final Spliterators类的spliterator方法，返回IteratorSpliterator。而static IteratorSpliterator类实现了Spliterator。Spliterator提供了tryAdvance处理每个元素、forEachRemaining、trySplit分割拆分等方法。 也就是说，stream()实际是采用Spliterator对于元素进行遍历、拆分处理。 StreamSupport.stream123456789101112131415public static &lt;T&gt; Stream&lt;T&gt; stream(Spliterator&lt;T&gt; spliterator, boolean parallel) &#123; Objects.requireNonNull(spliterator); return new ReferencePipeline.Head&lt;&gt;(spliterator, StreamOpFlag.fromCharacteristics(spliterator), parallel);&#125;Head(Spliterator&lt;?&gt; source, int sourceFlags, boolean parallel) &#123; super(source, sourceFlags, parallel); &#125;ReferencePipeline(Spliterator&lt;?&gt; source, int sourceFlags, boolean parallel) &#123; super(source, sourceFlags, parallel);&#125; list.stream()方法最终会实例化ReferencePipeline.Head&lt;&gt;对象，Head为pipeline流的头结。Head&lt;E_IN, E_OUT&gt; extends ReferencePipeline&lt;E_IN, E_OUT&gt;，E_IN为上游输入类型，E_OUT为输出类型点。StreamOpFlag.fromCharacteristics(spliterator)，将spliterator字符集转换为带有排序的流标记。ReferencePipeline为继承了AbstractPipeline得抽象类，提供pipeline处理类型的各阶段基类。 AbstractPipeline123456789101112AbstractPipeline(Spliterator&lt;?&gt; source, int sourceFlags, boolean parallel) &#123; this.previousStage = null; this.sourceSpliterator = source; this.sourceStage = this; this.sourceOrOpFlags = sourceFlags &amp; StreamOpFlag.STREAM_MASK; // The following is an optimization of: // StreamOpFlag.combineOpFlags(sourceOrOpFlags, StreamOpFlag.INITIAL_OPS_VALUE); this.combinedFlags = (~(sourceOrOpFlags &lt;&lt; 1)) &amp; StreamOpFlag.INITIAL_OPS_VALUE; this.depth = 0; this.parallel = parallel;&#125; AbstractPipeline为pipeline抽象基类，定义包括前一个、当前、下一个等AbstractPipeline处理流程等。AbstractPipeline继承abstract class PipelineHelper，PipelineHelper定义了流的操作、输出、标记和并行等参数。 forEach1void forEach(Consumer&lt;? super T&gt; action); 对流中的每个元素执行操作。 123456789@Overridepublic void forEach(Consumer&lt;? super E_OUT&gt; action) &#123; if (!isParallel()) &#123; sourceStageSpliterator().forEachRemaining(action); &#125; else &#123; super.forEach(action); &#125;&#125; forEach具体实现位于ReferencePipeline中，执行串行遍历或并行分割处理。 forEach并行1234567891011121314151617181920212223242526@Overridepublic void forEach(Consumer&lt;? super P_OUT&gt; action) &#123; evaluate(ForEachOps.makeRef(action, false));&#125;final &lt;R&gt; R evaluate(TerminalOp&lt;E_OUT, R&gt; terminalOp) &#123; assert getOutputShape() == terminalOp.inputShape(); if (linkedOrConsumed) throw new IllegalStateException(MSG_STREAM_LINKED); linkedOrConsumed = true; return isParallel() ? terminalOp.evaluateParallel(this, sourceSpliterator(terminalOp.getOpFlags())) : terminalOp.evaluateSequential(this, sourceSpliterator(terminalOp.getOpFlags()));&#125;default &lt;P_IN&gt; R evaluateParallel(PipelineHelper&lt;E_IN&gt; helper, Spliterator&lt;P_IN&gt; spliterator) &#123; if (Tripwire.ENABLED) Tripwire.trip(getClass(), &quot;&#123;0&#125; triggering TerminalOp.evaluateParallel serial default&quot;); return evaluateSequential(helper, spliterator);&#125; @Override public &lt;S&gt; Void evaluateSequential(PipelineHelper&lt;T&gt; helper, Spliterator&lt;S&gt; spliterator) &#123; return helper.wrapAndCopyInto(this, spliterator).get(); &#125; forEach并行时，主要采用evaluate方法，在pipeline中采用终止操作处理结果。]]></content>
      <categories>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>Lambda</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java Lambda FunctionalInterface原理]]></title>
    <url>%2Fposts%2F54901%2F</url>
    <content type="text"><![CDATA[123456789101112@FunctionalInterfaceinterface Print&lt;T&gt; &#123; public void print(T x);&#125;public class Lambda &#123; public static void PrintString(String s, Print&lt;String&gt; print) &#123; print.print(s); &#125; public static void main(String[] args) &#123; PrintString("test", (x) -&gt; System.out.println(x)); &#125;&#125; 编译器会根据Lambda表达式生成一个私有的静态函数 123456789101112131415161718192021@FunctionalInterfaceinterface Print&lt;T&gt; &#123; public void print(T x);&#125;public class Lambda &#123; public static void PrintString(String s, Print&lt;String&gt; print) &#123; print.print(s); &#125; private static void lambda$0(String x) &#123; System.out.println(x); &#125; final class $Lambda$1 implements Print&#123; @Override public void print(Object x) &#123; lambda$0((String)x); &#125; &#125; public static void main(String[] args) &#123; PrintString("test", new Lambda().new $Lambda$1()); &#125;&#125;]]></content>
      <categories>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>Lambda</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java8常用文件处理方法]]></title>
    <url>%2Fposts%2F58696%2F</url>
    <content type="text"><![CDATA[获取并解析文件 1234567891011121314151617public void parse() &#123; InputStream resource = Test.class.getResourceAsStream("/a.txt"); try &#123; BufferedReader bufferedReader = new BufferedReader( new InputStreamReader(resource)); // 获取文件 String line; while ((line = bufferedReader.readLine()) != null) &#123; &#125; &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; 获取其及子孙目录下的所有文件和目录 1234567891011public static List&lt;Path&gt; getFileList() &#123; try &#123; return Files.walk(Paths.get(dir)) .filter(Files::isRegularFile) .filter(e -&gt; e.toString().contains("app")) .collect(Collectors.toList()); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; return null;&#125; 写入文件 123456789101112public static void write(StringBuilder stringBuilder) &#123; BufferedWriter bfw = null; try &#123; bfw = Files.newBufferedWriter(Paths.get(dir + "/a.txt")); bfw.write(stringBuilder.toString()); bfw.flush(); bfw.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125;&#125;]]></content>
      <categories>
        <category>工具利器</category>
      </categories>
      <tags>
        <tag>Java8</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker基本操作]]></title>
    <url>%2Fposts%2F5308%2F</url>
    <content type="text"><![CDATA[查看进程docker ps 关闭进程docker kill -s KILL 376ec4b90 docker kill 376ec4b90 docker rm 376ec4b90 docker restart 376ec4b90]]></content>
      <categories>
        <category>架构</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Prometheus与Grafana部署和安装]]></title>
    <url>%2Fposts%2F1379%2F</url>
    <content type="text"><![CDATA[prometheus Prometheus是开源监控报警系统。 多维度数据模型。 灵活的查询语言。 不依赖分布式存储，单个服务器节点是自主的。 通过基于HTTP的pull方式采集时序数据。 可以通过中间网关进行时序列数据推送。 通过服务发现或者静态配置来发现目标服务对象。 支持多种多样的图表和界面展示，比如Grafana等。 概念Prometheus生态系统由多个组件组成，它们中的一些是可选的。多数Prometheus组件是Go语言写的，这使得这些组件很容易编译和部署。 Prometheus Server主要负责数据采集和存储，提供PromQL查询语言的支持。 客户端SDK官方提供的客户端类库有go、java、scala、python、ruby，其他还有很多第三方开发的类库，支持nodejs、php、erlang等。 Push Gateway支持临时性Job主动推送指标的中间网关。 PromDash使用Rails开发可视化的Dashboard，用于可视化指标数据。 ExporterExporter是Prometheus的一类数据采集组件的总称。它负责从目标处搜集数据，并将其转化为Prometheus支持的格式。与传统的数据采集组件不同的是，它并不向中央服务器发送数据，而是等待中央服务器主动前来抓取。 Prometheus提供多种类型的Exporter用于采集各种不同服务的运行状态。目前支持的有数据库、硬件、消息中间件、存储系统、HTTP服务器、JMX等。 alertmanager警告管理器，用来进行报警。 prometheus_cli命令行工具。 其他辅助性工具多种导出工具，可以支持Prometheus存储数据转化为HAProxy、StatsD、Graphite等工具所需要的数据存储格式。 node-exporter下载镜像docker pull prom/node-exporter 运行1234567docker run -d \ -p 9090:9090 \ --net="host" \ --pid="host" \ -v "/:/host:ro,rslave" \ quay.io/prometheus/node-exporter \ --path.rootfs /host redis_exporter下载镜像docker pull oliver006/redis_exporter 运行1234docker run -d \--name redis_exporter \-p 9121:9121 \oliver006/redis_exporter --redis.addr redis://h:password@192.168.1.41:6380 或者 123wget https://github.com/oliver006/redis_exporter/releases/download/v0.13/redis_exporter-v0.13.linux-amd64.tar.gz./redis_exporter -redis.addr 192.168.1.41:6380 -redis.password password &amp; mysqld-exporter下载镜像docker pull prom/mysqld-exporter 运行1234docker run -d \ -p 9101:9104 \ -e DATA_SOURCE_NAME="root:password@(192.168.1.41:3308)/test" \ prom/mysqld-exporter 或者 123456789wget https://github.com/prometheus/mysqld_exporter/releases/download/v0.10.0/mysqld_exporter-0.10.0.linux-amd64.tar.gz -O mysqld_exporter-0.10.0.linux-amd64.tar.gz cat &lt;&lt; EOF &gt; my.cnf[client]user=prompassword=abc123EOF./mysqld_exporter -config.my-cnf=&quot;my.cnf&quot; grafana下载镜像docker pull grafana/grafana 运行1docker run -d --name=grafana -p 3000:3000 grafana/grafana prometheus下载镜像docker pull prom/prometheus 运行12345sudo docker run -d \ -p 9090:9090 \ -v /home/config/prometheus.yml:/home/config/prometheus.yml \ quay.io/prometheus/prometheus \ --config.file=/home/config/prometheus.yml 配置prometheus.yml 12345678910111213141516171819202122crape_configs: - job_name: 'prometheus' static_configs: - targets: ['localhost:9090'] - job_name: 'redis-41' static_configs: - targets: ['192.168.1.41:9121'] labels: instance: redis - job_name: 'linux-41' static_configs: - targets: ['192.168.1.41:9100'] labels: instance: node - job_name: 'mysql-41' static_configs: - targets: ['192.168.1.41:9101'] labels: instance: db 重启服务 123docker psdocker restart `prometheus-processid` 登录验证12prometheus 192.168.1.41:9090grafana 192.168.1.41:3000 admin/admin]]></content>
      <categories>
        <category>工具利器</category>
      </categories>
      <tags>
        <tag>Prometheus</tag>
        <tag>Grafana</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[搭建Http-Server用于文件传输]]></title>
    <url>%2Fposts%2F4544%2F</url>
    <content type="text"><![CDATA[Http-Serverhttp-server 安装npm install http-server -g 文件上传./public 文件下载wget http://172.16.25.70:8080/prometheus.yml]]></content>
      <categories>
        <category>工具利器</category>
      </categories>
      <tags>
        <tag>Http-Server</tag>
        <tag>nodejs</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Prometheus集成SpringBoot1.5]]></title>
    <url>%2Fposts%2F42635%2F</url>
    <content type="text"><![CDATA[Prometheus集成SpringBoot1.5pom12345678910111213141516171819202122232425262728&lt;!-- Actuator (with security enabled) --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-security&lt;/artifactId&gt;&lt;/dependency&gt;&lt;!-- Monitoring endpoint - Micrometer + Prometheus --&gt; &lt;dependency&gt; &lt;groupId&gt;io.micrometer&lt;/groupId&gt; &lt;artifactId&gt;micrometer-registry-prometheus&lt;/artifactId&gt; &lt;version&gt;1.0.3&lt;/version&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;artifactId&gt;HdrHistogram&lt;/artifactId&gt; &lt;groupId&gt;org.hdrhistogram&lt;/groupId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.micrometer&lt;/groupId&gt; &lt;artifactId&gt;micrometer-spring-legacy&lt;/artifactId&gt; &lt;version&gt;1.0.3&lt;/version&gt; &lt;/dependency&gt; bootstrap.yml123456789101112131415management: endpoints: web: exposure: include: &apos;*&apos; jmx: exposure: include: &apos;*&apos; shutdown: enabled: true metrics: distribution: percentiles-histogram[http.server.requests]: true security: enabled: false application.java1234567@BeanMeterRegistryCustomizer meterRegistryCustomizer(MeterRegistry meterRegistry) &#123; return meterRegistry1 -&gt; &#123; meterRegistry.config() .commonTags("application", "micrometer-oceanus-chatbot-web"); &#125;;&#125; 配置prometheus.yml 1234- job_name: 'app-41' metrics_path: '/mgmt/prometheus' static_configs: - targets: ['192.168.1.41:9915'] 重启服务 123docker psdocker restart `prometheus-processid` 登录验证12prometheus 192.168.1.41:9090grafana 192.168.1.41:3000 admin/admin]]></content>
      <categories>
        <category>工具利器</category>
      </categories>
      <tags>
        <tag>Prometheus</tag>
        <tag>SpringBoot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java Lambda用法]]></title>
    <url>%2Fposts%2F15864%2F</url>
    <content type="text"><![CDATA[特点 函数传递 函数编程 闭包 Java 中的 Lambda 表达式通常使用 (argument) -&gt; (body) 语法书写，例如： (arg1, arg2…) -&gt; { body } (type1 arg1, type2 arg2…) -&gt; { body }以下是一些 Lambda 表达式的例子： 123456789(int a, int b) -&gt; &#123; return a + b; &#125;() -&gt; System.out.println("Hello World");(String s) -&gt; &#123; System.out.println(s); &#125;() -&gt; 42() -&gt; &#123; return 3.1415 &#125;; 每个 Lambda 表达式都能隐式地赋值给函数式接口，例如，我们可以通过 Lambda 表达式创建 Runnable 接口的引用。 1Runnable r = () -&gt; System.out.println("hello world"); 当不指明函数式接口时，编译器会自动解释这种转化： 123new Thread( () -&gt; System.out.println("hello world")).start(); @FunctionalInterface 函数式接口只能有一个抽象方法，如果你尝试添加第二个抽象方法，将抛出编译时错误 12345678910111213141516171819202122232425262728//定义一个函数式接口### @FunctionalInterfacepublic interface WorkerInterface &#123; public void doSomeWork();&#125;public class WorkerInterfaceTest &#123;public static void execute(WorkerInterface worker) &#123; worker.doSomeWork();&#125;public static void main(String [] args) &#123; //invoke doSomeWork using Annonymous class execute(new WorkerInterface() &#123; @Override public void doSomeWork() &#123; System.out.println("Worker invoked using Anonymous class"); &#125; &#125;); //invoke doSomeWork using Lambda expression execute( () -&gt; System.out.println("Worker invoked using Lambda expression") );&#125;&#125; 用法区别123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172//Old way:List&lt;Integer&gt; list = Arrays.asList(1, 2, 3, 4, 5, 6, 7);for(Integer n: list) &#123; System.out.println(n);&#125;//New way:List&lt;Integer&gt; list = Arrays.asList(1, 2, 3, 4, 5, 6, 7);list.forEach(n -&gt; System.out.println(n));//or we can use :: double colon operator in Java 8list.forEach(System.out::println);public class Main &#123;public static void main(String [] a) &#123; List&lt;Integer&gt; list = Arrays.asList(1, 2, 3, 4, 5, 6, 7); System.out.println("Print all numbers:"); evaluate(list, (n)-&gt;true); System.out.println("Print no numbers:"); evaluate(list, (n)-&gt;false); System.out.println("Print even numbers:"); evaluate(list, (n)-&gt; n%2 == 0 ); System.out.println("Print odd numbers:"); evaluate(list, (n)-&gt; n%2 == 1 ); System.out.println("Print numbers greater than 5:"); evaluate(list, (n)-&gt; n &gt; 5 );&#125;public static void evaluate(List&lt;Integer&gt; list, Predicate&lt;Integer&gt; predicate) &#123; for(Integer n: list) &#123; if(predicate.test(n)) &#123; System.out.println(n + " "); &#125; &#125;&#125;&#125; //Old way:List&lt;Integer&gt; list = Arrays.asList(1,2,3,4,5,6,7);for(Integer n : list) &#123; int x = n * n; System.out.println(x);&#125;//New way:List&lt;Integer&gt; list = Arrays.asList(1,2,3,4,5,6,7);list.stream().map((x) -&gt; x*x).forEach(System.out::println);//Old way:List&lt;Integer&gt; list = Arrays.asList(1,2,3,4,5,6,7);int sum = 0;for(Integer n : list) &#123; int x = n * n; sum = sum + x;&#125;System.out.println(sum);//New way:List&lt;Integer&gt; list = Arrays.asList(1,2,3,4,5,6,7);int sum = list.stream().map(x -&gt; x*x).reduce((x,y) -&gt; x + y).get();System.out.println(sum); findAny12345 Optional&lt;A&gt; optional = list().stream().filter(e -&gt; (e.getType() == tag.getType())).findAny();if (!optional.isPresent()) &#123; &#125; collect12tagList = list.parallelStream().filter(e -&gt;e.getType() == tag.getType() ).collect(Collectors.toList()); map1List&lt;String&gt; list = tagList.stream().map(Tag::getValue).collect(Collectors.toList()); limit123456789Stream.iterate(0, i -&gt; i + 1).limit(tagList.size()).forEach( i -&gt; &#123; if (i == 0) &#123; &#125; else &#123; &#125; if (i == (tagList.size() - 1)) &#123; &#125; &#125; ); forEach123tagList().forEach(e -&gt; &#123; parse(e);&#125;); comparing1list.sort(Comparator.comparing(e -&gt; e.getPriority())); parallelStream12345public Ele getEle() &#123; return ist().parallelStream() .filter(e -&gt; Objects.equals("", "")) .findAny().orElse(null); &#125; of12345Stream.of("张三","李四","王二","张四五") .filter(x -&gt; x.startsWith("张")) .mapToInt(String::length) .max() .ifPresent(System.out::println);]]></content>
      <categories>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>Lambda</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ElasticSearch基本操作]]></title>
    <url>%2Fposts%2F278%2F</url>
    <content type="text"><![CDATA[Dochttps://docs.spring.io/spring-data/elasticsearch/docs/current/reference/html/ 聚合去重http://192.168.1.100:9200/a-b/a_b/_search 123456789101112&#123; &quot;from&quot;: 0, &quot;size&quot;: 0, &quot;aggregations&quot;: &#123; &quot;field1&quot;: &#123; &quot;terms&quot;: &#123; &quot;field&quot;: &quot;xx&quot;, &quot;size&quot;: 21474837 &#125; &#125; &#125; &#125;]]></content>
      <categories>
        <category>架构</category>
      </categories>
      <tags>
        <tag>ElasticSearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[List利用Comparator进行Sort]]></title>
    <url>%2Fposts%2F50004%2F</url>
    <content type="text"><![CDATA[代码123456789101112131415161718public static void main(String[] args) &#123; List&lt;Integer&gt; a = new ArrayList(10); a.add(1); a.add(4); a.add(2); a.add(5); a.add(3); Collections.sort(a, new Comparator&lt;Integer&gt;() &#123; @Override public int compare(Integer o1, Integer o2) &#123; return o2 - o1;//倒叙 &#125; &#125;); a.stream().forEach(x -&gt; System.out.println(x));&#125; 输出： 1234554321 分析Comparator 比较器 java.util包 接口 用于排序和分组 常用于数组和列表 Arrays.sort(T[],Comparator&lt;? super T&gt; c) Collections.sort(List list,Comparator&lt;? super T&gt; c) 原理List.java 123456789default void sort(Comparator&lt;? super E&gt; c) &#123; Object[] a = this.toArray(); Arrays.sort(a, (Comparator) c); ListIterator&lt;E&gt; i = this.listIterator(); for (Object e : a) &#123; i.next(); i.set((E) e); &#125;&#125; 调用List默认接口实现 实际调用Arrays.sort(a, (Comparator) c); Arrays.java 12345678910public static &lt;T&gt; void sort(T[] a, Comparator&lt;? super T&gt; c) &#123; if (c == null) &#123; sort(a); &#125; else &#123; if (LegacyMergeSort.userRequested) legacyMergeSort(a, c); else TimSort.sort(a, 0, a.length, c, null, 0, 0); &#125;&#125; LegacyMergeSort归并排序，默认不使用 TimSort利用合并和插入排序 TimsortTimsort是先采用插入排序将非常小的run扩充为较大的run，然后再采用归并排序来合并多个run。 定义一个参数minrun，当run长度小于minrun时，我们认为它是非常小的run，否则认为它是较大的run。 过程为： 找到小的run扩充为较大的run 按规则合并run 扩充从左到右处理待排序序列，将其划分为若干个run。从第1个尚未处理的对象开始，找到一个尽可能长的连续严格递减（严格降序）或连续非递减（升序）序列，如果是连续严格递减序列，则可以通过一个简单的“翻转操作”将其变为严格递增序列。 如果这样得到的序列长度等于minrun，则将其作为一个完整的run ，继续生成下一 run；否则用插入排序将后面的元素添加进来，直至其长度达到minrun为止。 待排序序列的前4个数是 3,6,7,53,6,7,5，minrun = 4，则尽可能长的连续非递减序列为 3,6,73,6,7，其长度没有达到4。于是将后面的5插入进来，得到长度为4的 run 3,5,6,73,5,6,7。 待排序序列的前4个数是 9,1,2,79,1,2,7，minrun = 4，则尽可能长的连续递减序列为 9,19,1，其长度没有达到4。于是依次将后面的2和7插入进来，得到长度为4的 run 1,2,7,91,2,7,9。 如果 run 是依次减小的，反转run 合并 避免一个较长的有序片段和一个较小的有序片段进行归并，因为这样的效率比较低： 如果栈中存在已有序的至少三个序列，我们用X，Y，Z依次表示从栈顶向下的三个已有序列片段，当三者的长度满足X+Y&gt;=Z时进行归并。 如果X是三者中长度最大的，先将X，Y，Z出栈，应该先归并Y和Z，然后将Y和Z归并的结果入栈，最后X入栈 否则将X和Y出栈，归并后结果入栈。注意，实际上我们不会真正的出栈，写代码中有一些技巧可以达到相同的效果，而且效率更高。 如果不满足X+Y&gt;=Z的条件或者栈中仅存在两个序列，我们用X，Y依次表示从栈顶向下的两个已有序列的长度，如果X&gt;=Y则进行归并，然后将归并后的有序片段结果入栈。 在归并两个已有序的片段时，采用了所谓的飞奔（gallop）模式 假设需要归并的两个已有序片段分别为X和Y，如果X片段的前m个元素都比Y片段的首元素小，那么这m个元素实际上是不需要参与归并的，因为归并后这m个元素仍然位于原来的位置。同理如果Y片段的最后n个元素都比X的最后一个元素大，那么Y的最后n个元素也不必参与归并。这样就减少了归并数组的长度(简易版没有这么做)，也较少了待排序数组与辅助数组之间数据来回复制的长度，进而提高了归并的效率。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>List</tag>
        <tag>Comparator</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[IDEA基本配置]]></title>
    <url>%2Fposts%2F49684%2F</url>
    <content type="text"><![CDATA[IDEA通用插件安装Alibaba Java Code Guidelines Preferences &gt;&gt; Plugins &gt;&gt; Marketplace 查询Alibaba Java Code Guidelines并安装后重启 Git Flow Integrationgit flow集成 GitToolBox行代码给与log历史提示 类的注释格式 Preferences &gt;&gt; Editor &gt;&gt; File and Code Templates &gt;&gt; Includes &gt;&gt; File Header 12345/*** @author: Perkins* @date: $&#123;DATE&#125;* @description: todo*/ lombok IDEA插件查询lombok并安装 pom 123456&lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;version&gt;1.16.18&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt;&lt;/dependency&gt; 代码使用注解@Data，@Log]]></content>
      <categories>
        <category>工具利器</category>
      </categories>
      <tags>
        <tag>IDEA</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Maven基本操作]]></title>
    <url>%2Fposts%2F725%2F</url>
    <content type="text"><![CDATA[Maven环境变量配置 创建文件 123cd ~touch .bash_profileopen -e .bash_profile 写入bash_profile 12345M2_HOME=/Users/work/apache-maven-3.5.0/PATH=$M2_HOME/bin:$PATHexport M2_HOMEexport PATH 执行 1source .bash_profile 测试 1mvn -v 安装jar和源码至本地仓库 jarmvn install:install-file -Dfile=/Users/xx-1.0.1.jar -DgroupId=xx -DartifactId=xx -Dversion=1.0.1 -Dpackaging=jar sourcemvn install:install-file -Dfile=/Users/xx-1.0.1-sources.jar -DgroupId=xx -DartifactId=xx -Dversion=1.0.1 -Dpackaging=jar -Dclassifier=sources scope12345&lt;dependency&gt; &lt;groupId&gt;xx.xx.xx&lt;/groupId&gt; &lt;artifactId&gt;xx-xx&lt;/artifactId&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; 值 说明 provided 打包时不包含，认为容器会提供 compile 默认，在编译、测试和打包阶段均有效 runtime 跳过编译，直接参与运行和测试 test 依赖性参与测试工作，包括测试代码的编译和运行，例如junit system 包来自本地系统文件 打包命令 值 说明 package 测试、打包 install 测试、打包并安装至本地仓库 deploy 测试、打包并安装至本地仓库，且上传至Maven中央服务器]]></content>
      <categories>
        <category>工具利器</category>
      </categories>
      <tags>
        <tag>Maven</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mac下用iterm2免密码]]></title>
    <url>%2Fposts%2F49300%2F</url>
    <content type="text"><![CDATA[安装Homebrew1/usr/bin/ruby -e "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)" 安装sshpass123brew install http://git.io/sshpass.rbwhich sshpass 输出/usr/local/bin/sshpass Item2配置1/usr/local/bin/sshpass -p 123456 ssh -p22 root@192.168.1.41 操作先用本地终端连接第一次，再用item2]]></content>
      <categories>
        <category>工具利器</category>
      </categories>
      <tags>
        <tag>iterm2</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS7安装部署 - Redis]]></title>
    <url>%2Fposts%2F85%2F</url>
    <content type="text"><![CDATA[redis 拉取 1wget http://download.redis.io/releases/redis-3.2.6.tar.gz 解压 1tar -zxvf redis-3.2.6.tar.gz 编译 12cd redis-3.2.6make 修改数据目录vi redis.conf 1234567891011121314#指定日志目录logfile /root/data/soft/redis-3.2.6/data/logs/redis.log#指定数据目录dir /root/data/soft/redis-3.2.6/data#修改后台启动daemonize yes#允许外网访问protected-mode no #允许ip访问#bind 127.0.0.1#修改绑定端口port 6380#密码访问requirepass root123 启动 123cd redis-3.2.6/src #启动./redis-server ../redis.conf 测试 1234./redis-cli -p 6380dbsizeflushallexit 客户端安装Redis Desktop Manager输入连接ip、端口、密码]]></content>
      <categories>
        <category>安装部署</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS7安装部署 - MongoDB]]></title>
    <url>%2Fposts%2F277%2F</url>
    <content type="text"><![CDATA[mogo 下载12345wget https://fastdl.mongodb.org/linux/mongodb-linux-x86_64-rhel70-4.0.6.tgz ./tar xzvf mongodb-linux-x86_64-rhel70-4.0.6.tgzmkdir -p data/mongo_data data/logs 配置 1234567891011121314touch mongo.conf#数据目录dbpath=/home/admin/soft/mongodb/data/mongo_datalogpath=/home/admin/soft/mongodb/data/logs/mongo.log#后台允许fork=truequiet=truejournal=truelogappend=true#可以外网访问bind_ip=0.0.0.0#修改端口port=27018 启动： 1/bin/mongod -f mongo.conf 创建管理员 123456789mongo localhost:27018&gt;use admin db.createUser( &#123; user: "root", pwd: "root123", roles: [ &#123; role: "userAdminAnyDatabase", db: "admin" &#125;, "readWriteAnyDatabase" ] &#125; ) exit 开启权限vi /etc/mongod.conf 123#security security: authorization: enabled 重启mongodb： 12pkill mongod/bin/mongod -f mongo.conf 安装GUI 123456789#先安装nodebrew install nodegit clone https://github.com/mrvautin/adminMongo cd adminMongonpm installnpm start#测试地址：http://127.0.0.1:1234 后台进程 1234#指定name启动pm2 start app.js --name adminMongo#删除pm2 delete adminMongo GUI连接打开http://127.0.0.1:1234地址：mongodb://root:root123@192.168.1.41:27018/admin pm21234567npm install pm2 -gpm2 listpm2 restartpm2 monitpm2 start app.js --name adminMongopm2 delete adminMongoMon 安装service 12yum list | grep initscriptsyum install initscripts -y docker不能启动问题Failed to get D-Bus connection: Operation not permitted解决： 1docker run -d -it --privileged ContainerId /usr/sbin/init]]></content>
      <categories>
        <category>安装部署</category>
      </categories>
      <tags>
        <tag>MongoDB</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Centos7安装部署 - MySQL]]></title>
    <url>%2Fposts%2F21810%2F</url>
    <content type="text"><![CDATA[mysql5.7 下载并安装源123wget 'https://dev.mysql.com/get/mysql57-community-release-el7-11.noarch.rpm'sudo rpm -Uvh mysql57-community-release-el7-11.noarch.rpmyum repolist all | grep mysql 安装 1sudo yum install mysql-community-server 更改数据目录 123456789chown -R mysql:mysql /root/data/soft/mysql vi /etc/my.cnf#修改数据目录#datadir=/var/lib/mysql#socket=/var/lib/mysql/mysql.sockdatadir=/root/data/soft/mysqlsocket=/root/data/soft/mysql/mysql.sock 启动 123456789service mysqld start#查看错误日志tail -200 /var/log/mysqld.log#因为修改了目录 需要再初始化cd /root/data/soft/mysqlrm -rf *chown -R mysql:mysql .mysqld --initialize --user=mysql --consoleservice mysqld start 登录和修改密码 12345678#获取密码grep 'temporary password' /var/log/mysqld.logmysql -uroot -P3308 -p select @@log_error;set password for 'root'@'localhost'=password('root@123'); 授权登录 12GRANT ALL PRIVILEGES ON *.* TO 'root'@'%' IDENTIFIED BY 'root@123' WITH GRANT OPTION;FLUSH PRIVILEGES; 客户端workbench 解决中文乱码 123set global character_set_server=utf8;set global character_set_database=utf8;show variables like '%char%';]]></content>
      <categories>
        <category>安装部署</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java并发编程艺术 - 多线程]]></title>
    <url>%2Fposts%2F24227%2F</url>
    <content type="text"><![CDATA[启动Java应用程序则是一个进程，一个进程可以启动多个线程，线程是操作系统调度最小单元。线程拥有独立的计数器、栈和局部变量，可以共享堆内存。 一个Java程序入口是main主线程，线程优先级从1-10，优先级越高分配时间片越长。 线程状态 NEW 新建 Thread.start(); RUNNABLE 运行，包括就绪和运行 Thread.run(); BLOCKED 阻塞 synchronized WAITING 等待，等待其他线程通知和中断 Object.wait() Object.join() LockSupport.park(Thread) TIME_WAITTING 等待，等待指定时间超时 Thread.sleep(long) Object.wait(long) Object.join(long) LockSupport.parkNanos() LockSupport.parkUntil() TERMINATED 终止 interrupt(),isInterrupted()和interrupted() suspend()、resume()和stop() 线程优先级123Thread thread = new Thread(job, "Thread:" + i);thread.setPriority(priority);thread.start(); Daemon线程守护线程，为非Daemon线程提供后台调度和服务，例如GC线程。 123Thread thread = new Thread(new DaemonRunner(), "DaemonRunner");thread.setDaemon(true);thread.start(); 线程中断其他线程调用该线程的interrupt()方法进行中断，线程本身调用isInterrupted(()判断是否中断，也可以调用Thread.interrupted()对当前线程的中断标识位进行复位。 123456789101112131415161718192021222324252627282930313233343536373839404142public class Thread2 &#123; public static void main(String[] args) throws Exception &#123; Runner one = new Runner(); Thread countThread = new Thread(one, "CountThread1"); countThread.start(); // 睡眠1秒，main线程对CountThread进行中断，使CountThread能够感知中断而结束 TimeUnit.SECONDS.sleep(1); countThread.interrupt(); Runner two = new Runner(); countThread = new Thread(two, "CountThread2"); countThread.start(); // 睡眠1秒，main线程对Runner two进行取消，使CountThread能够感知on为false而结束 TimeUnit.SECONDS.sleep(1); two.cancel(); &#125; private static class Runner implements Runnable &#123; private long i; private volatile boolean on = true; @Override public void run() &#123; while (on &amp;&amp; !Thread.currentThread().isInterrupted()) &#123; try &#123; i++; Thread.sleep(100); &#125; catch (InterruptedException e) &#123; Thread.currentThread().interrupt();//重新设置中断标示 &#125; &#125; System.out.println("Count i = " + i + ",Name:" + Thread.currentThread().getName()); &#125; public void cancel() &#123; on = false; &#125; &#125;&#125; 线程等待和通知 notify() 随机通知在对象上等待的另一个线程，使其在wait()状态上尝试获取锁，如获取锁成功则返回 notifyAll() 通知在对象上等待的所有线程，竞争锁 wait() 进入WAITING状态，等待通知或中断，会释放锁 wait(long) 进入TIME_WAITTING状态，等待超时 join() 进入WAITING状态，等待其他线程终止后返回，不释放锁 join(long) 进入TIME_WAITTING状态，等待其他线程终止后返回，不释放锁]]></content>
      <categories>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>Java并发编程</tag>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java并发编程艺术 - 延迟加载与双重检查锁定double check lock]]></title>
    <url>%2Fposts%2F31866%2F</url>
    <content type="text"><![CDATA[类延迟初始化常采用单例模式。 方法1： 12345678910public class Singleton &#123; private static Singleton singleton = null; public static Singleton getInstance() &#123; if (singleton == null) &#123;//1 singleton=new Singleton();//2 &#125; return singleton; &#125;&#125; 多线程中，步骤1可以同步执行，导致步骤2多次执行。 方法2： 12345678910public class Singleton &#123; private static Singleton singleton = null; public static synchronized Singleton getInstance() &#123; if (singleton == null) &#123;//1 singleton=new Singleton();//2 &#125; return singleton; &#125;&#125; 多线程中，singleton只会实例一次，但每次获取getInstance都会加锁导致性能下降。 方法3： 12345678910111213141516public class Singleton &#123; private static Singleton singleton = null; public static Singleton getInstance() &#123; //one check if (singleton == null) &#123;//1 synchronized (Singleton.class) &#123;//2 //two check if (singleton == null) &#123;//3 singleton = new Singleton();//4 &#125; &#125; &#125; return singleton; &#125;&#125; 步骤4分解为3条指令执行，包括1-先分配内存，2-标记对象指向内存地址，3-初始化构造；如果指令12重排导致先赋值，多线程并发中步骤1不为null，但获取的singleton仍未初始化。 方法4： 1234567891011121314151617public class Singleton &#123; //防止重排 private volatile static Singleton singleton = null;//5 public static Singleton getInstance() &#123; //one check if (singleton == null) &#123;//1 synchronized (Singleton.class) &#123;//2 //two check if (singleton == null) &#123;//3 singleton = new Singleton();//4 &#125; &#125; &#125; return singleton; &#125;&#125; 步骤5使用volatile防止指令重排，是标准的DCL实例方案。 方法5： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public class Singleton implements Serializable&#123;//序列化 //防止重排 private volatile static Singleton singleton = null;//5 private static boolean flag = false; private Singleton() &#123;//6 //防止反射漏洞 synchronized (Singleton.class) &#123; if (flag) &#123; System.out.println("init twice"); &#125; else &#123; flag = true; System.out.println("init once"); &#125; &#125; &#125; public static Singleton getInstance() &#123; //one check if (singleton == null) &#123;//1 synchronized (Singleton.class) &#123;//2 //two check if (singleton == null) &#123;//3 singleton = new Singleton();//4 &#125; &#125; &#125; return singleton; &#125; //防止反序列化漏洞，替换反序列化对象 private Object readResolve() &#123; return singleton; &#125; public static void main(String[] args) throws Exception &#123; Class&lt;Singleton&gt; clazz = (Class&lt;Singleton&gt;) Class.forName("Singleton"); Constructor&lt;Singleton&gt; singletonConstructor = clazz.getDeclaredConstructor(null); singletonConstructor.setAccessible(true);//反射打开访问权限 Singleton singleton = singletonConstructor.newInstance();//第一次实例化 singleton.say(); System.out.println(singleton); singleton = singletonConstructor.newInstance();//第二次实例化 singleton.say(); &#125;&#125; 步骤6对构造函数进行私有化，防止多次被实例化；同时，为防止反射多次实例，使用全局变量flag；也支持单例模式的序列化和反序列化。在执行类的初始化期间，JVM会去获取一个锁。这个锁可以同步多个线程对同一个类的初始化。 方法6： 1234567891011public class Singleton &#123; private static Singleton singleton = null; private static class SingletonFactory &#123; public static Singleton singleton2 = new Singleton(); &#125; public static Singleton getInstance() &#123; return SingletonFactory.singleton2; &#125;&#125; 利用类加载机制来实现，延迟初始化,类加载分为加载-&gt;验证-&gt;准备-&gt;解析-&gt;初始化-&gt;使用-&gt;卸载等步骤，Java中当类的静态域或静态方法被引用的时候，必须对声明这个静态域或方法的类进行初始化。 方法7： 123456789101112public enum SingletonEnum &#123; INSTANCE_ENUM; DataSource dataSource; private SingletonEnum() &#123; dataSource = null; &#125; public DataSource getDataSource() &#123; return dataSource; &#125;&#125; 利用枚举类实现单例模式。SingletonEnum会被编译成public final class SingletonEnum extends Enum，INSTANCE_ENUM会编译成public static final SingletonEnum INSTANCE_ENUM，根据类加载机制，初始化是线程安全的；同时，枚举序列化和反序列化禁止writeObject、readObject，不采用反射而是根据name属性和valueOf方法，防止破坏单例。]]></content>
      <categories>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>Java并发编程</tag>
        <tag>单例模式</tag>
        <tag>双重检测锁定</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java并发编程艺术 - 重排序]]></title>
    <url>%2Fposts%2F35014%2F</url>
    <content type="text"><![CDATA[重排序是编译器和处理器为优化程序性能而对指令进行重新排序的手段。 数据依赖性 写后写;a=1,a=2 写后读;a=1,b=a 读后写;a=b,b=1 以上三种情况存在数据依赖，重排将会引起结果改变。 as-if-serial不管怎么重排序，但不能影响结果，编译器、runtime和处理器都必须遵守这个语义，即可以对不存在数据依赖关系的指令进行重排。 例如 123int a=1;//操作1int b=2;//操作2int c=a+b;//操作3 以上操作1和2可以重排。 重排对多线程的影响1234567891011121314class ReorderExample &#123; int a = 0; boolean flag = false; public void writer() &#123; a = 1; // 1 flag = true; // 2 &#125; public void reader() &#123; if (flag) &#123; // 3 int i = a * a; // 4 …… &#125; &#125;&#125; 在多线程开发中： 如果线程1对操作1和2进行重排，线程2执行reader的操作3时，变量a可能没有及时同步，结果可能为0而不是1。 如果线程1对操作3和4进行重排，先将操作4结果暂存缓存，等待操作3决定是否缓存写入i；在单线程没有问题，但多线程操作3可能会被改变。 因此，多线程开发需要考虑程序执行的顺序性，可以采用同步原语，包括valatile、synchronized和final。]]></content>
      <categories>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>Java并发编程</tag>
        <tag>重排序</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java并发编程艺术 - Java内存模型基础]]></title>
    <url>%2Fposts%2F49164%2F</url>
    <content type="text"><![CDATA[并发编程的两个关键性问题 线程通信 线程同步 线程通信 通信是指线程间的信息交换，主要有两种：共享内存和消息传递。 共享内存是线程利用内存的公共状态进行隐私通信。 在Java中主要利用堆内存变量实现共享内存，包括静态域、数据、实例。 12345678910111213141516public class ThreadShare &#123; //利用内存静态变量进行状态传递 static int num = 0; private void increase() &#123; num++; System.out.println(num); &#125; public static void main(String[] args) &#123; ThreadShare threadShare = new ThreadShare(); new Thread(threadShare::increase).start(); new Thread(threadShare::increase).start(); &#125;&#125; 消息传递是利用管道消息进行显示通信。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364public class Consumer implements Runnable &#123; private PipedInputStream pis; public Consumer(PipedInputStream pis) &#123; this.pis = pis; &#125; @Override public void run() &#123; // 将数据保存在byte数组中 byte[] bytes = new byte[100]; try &#123; // 从数组中得到实际大小。 int length = pis.read(bytes); System.out.println(new String(bytes, 0, length)); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; finally &#123; try &#123; pis.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125;public class Producer implements Runnable &#123; private PipedOutputStream pos; public Producer(PipedOutputStream pos) &#123; this.pos = pos; &#125; @Override public void run() &#123; try &#123; pos.write("Hello World".getBytes()); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; finally &#123; try &#123; pos.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125;public class TestPipedStream &#123; public static void main(String[] args) &#123; PipedOutputStream pos = new PipedOutputStream(); PipedInputStream pis = new PipedInputStream(); try &#123; // 连接管道 pos.connect(pis); new Thread(new Producer(pos)).start(); new Thread(new Consumer(pis)).start(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 线程同步 在共享内存中必须显式指定某个方法或代码段进行线程互斥，在消息传递中隐式说明消息接收需在消息发送前。 互斥锁主要有Lock，synchronized。 JMM内存结构线程AB间要通信，需要经过两步： A将共享变量X的本地内存刷新到主存 B到主存更新本地内存的共享变量X 实质上是线程A在向线程B发送消息，而且这个通信过程必须要经过主内存。 JMM通过控制主内存与每个线程的本地内存之间的交互，提供内存可见性保证。 指令重排执行程序为提高性能，编译器和处理器会进行指令重排，主要有3种。 编译器在不影响单线程结果的前提下，进行指令重排。 指令并行重排。多条指令不存在数据依赖性，处理器可以改变机器指令执行顺序。 内存重排。处理器使用缓存和读写缓冲区进行加载和存储。 JMM通过插入内存屏障防止指令重排。 happens-beforeJMM中，如果一个操作执行结果需要对另一个操作可见，两个操作需要存在happens-before关系。 该两个操作可以是一个线程也可以是不同线程。 happens-before规则如下： 程序顺序规则：一个线程每个操作，happens-before线程后续操作 监视器锁规则：一个监视器锁的解锁，happens-before锁的加锁 volatile变量规则：一个volatile的写，happens-before任意对此域的读 传递性：如果A happens-before B，且B happens-before C，那么A happens-before C 两个操作存在happens-before关系，并不意味着一个操作必须在另一个之前，而是第一个操作的结果对第二个可见。]]></content>
      <categories>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>Java内存模型</tag>
        <tag>Java并发编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java并发编程艺术 - 原子性及CAS使用和原理]]></title>
    <url>%2Fposts%2F28363%2F</url>
    <content type="text"><![CDATA[原子性处理器保障从系统内存中读取和写入字节是原子的，即其他处理器不能访问该字节地址。 总线锁保障原子性处理器发出Lock#信号到总线上，其他处理器阻塞，该处理器独享内存。 缓存锁保障原子性总线锁把CPU和内存通信锁住，其他CPU无法访问其他内存地址，开销较大。 可以在缓存中，锁定内存地址，保障原子性。 缓存锁定缓存行时，回写内存不声明LOCK#，而是修改内部内存地址，同时通过缓存一致性阻止其他处理器修改；当其他处理器回写，将会无效缓存行，从内存重新加载数据。 JAVA实现原子操作通过锁实现原子操作锁机制保障只有获取锁的线程才能操作内存区域，常见的JVM锁有偏向锁、轻量锁和互斥锁。 除偏向锁外，其他锁实现都采用CAS进行锁的获取和释放。 通过CAS实现原子操作CAS通过Compare And Swap可以实现原子操作；原子操作即不能被进一步分割的最小粒子。 CAS需要输入两个参数，old值和expect值；若old值未发生变化，则替换old为expect，否则不交换。实际上是三个参数，第三个参数无需输入，可使用局部变量或者由操作指令维护，是old的origin值，用于和输入的old比较。 JVM中的CAS操作正是利用了处理器的CMPXCHG指令实现，自旋CAS实现的就是循环CAS直到成功。 从Java 1.5开始，JDK的JUC包里提供了原子操作，如AtomicBoolean（用原子方式更新的boolean值）、AtomicInteger（用原子方式更新的int值）和AtomicLong（用原子方式更新的long值）。这些原子包装类还提供了以原子的方式将当前值自增1和自减1。 CAS产生的问题ABA问题假如old和expect值相同，虽然交换了，但结果貌似没有变化，而且也不知道是否真的交换成功。 因此需要引入版本号，假如每次交换后版本加1，则可以明显确定是否交换成功，例如AtomicStampedReference。 长时间自旋如果长时间CAS自旋失败，则浪费CPU。 可以提供暂停操作，实现自旋延迟效果。 只能支持单个变量的原子性多个变量原子性操作通常需要用锁，或者采用把多个共享变量合并成一个共享变量。 AtomicReference支持对象的原子性，可以将多个变量放在一个对象中进行CAS。]]></content>
      <categories>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>Java并发编程</tag>
        <tag>CAS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java并发编程艺术 - synchronized使用和原理]]></title>
    <url>%2Fposts%2F43888%2F</url>
    <content type="text"><![CDATA[synchronized属于重量级锁，实现代码同步。 Java SE1.6优化引入了偏向锁和轻量级锁，同时支持锁升级，以减少获取锁和释放锁的性能消耗。 锁的对象synchronized可以修饰Java非空对象，常见3种形式： 锁当前实例修饰普通方法，例如: 12synchronized void add()&#123;&#125; 那么该对象实例将会在执行该方法时阻塞，以保持同步执行，不可并行执行；但是不同对象可以并行执行。 锁类所以对象修饰静态方法、全局变量、类，例如: 12synchronized static void add()&#123;&#125; 12synchronized (Singleton.class)&#123;&#125; 该类所有操作及类实例均会在执行时阻塞，以保持同步执行，不同对象也不可并行执行。 锁方法块 修饰实例或变量 12synchronized (this) &#123;&#125; 12synchronized (var) &#123;&#125; 该类所有操作及类实例均会在执行该代码块时阻塞，以保持同步执行，不同对象也不可并行执行；但对其他代码块不产生影响。 锁的实现synchronized由JVM实现，通过在代码块前后添加monitorenter和monitorexit指令。 线程执行到monitorenter尝试获取对象对应的monitor，即对象锁；如持有monitor锁，则对象处于锁定状态。 Java对象头synchronized锁信息存储在对象头中。 对象头包含Mark Word，存储对象HashCode、分代年龄和锁状态。 锁状态包括轻量锁、重量锁、偏向锁和GC标记。 锁升级锁的4种状态，由低到高： 无锁 偏向锁 轻量锁 重量锁 锁因为竞争可以由低到高升级，不可由高到低降级，以提高锁获取和释放效率。 偏向锁大多数情况，锁是同一线程多次获取，因此引入偏向锁。 在线程获取锁后，在对象头和栈帧中记录线程ID；后续该线程进入和退出代码同步块时不需要CAS获取和释放锁。 偏向锁释放当出现线程竞争偏向锁时，持有偏向锁的线程需要释放偏向锁。 释放偏向锁时，需要等待安全点，即该线程没有正在执行的字节码。 然后暂停拥有偏向锁的线程，若该线程处于不活动状态，将对象头设置为无锁状态；若活着，则重新偏向其他线程。 偏向锁优化偏向锁在程序启动后会延迟激活，-XX:BiasedLockingStartupDelay=0可以关闭延迟。 如果程序通常处于竞争状态，可以通过-XX:-UseBiasedLocking=false关闭偏向锁，那么程序默认会进入轻量级锁状态。 轻量锁轻量锁加锁JVM在执行同步代码块前，先在线程栈帧创建锁记录空间，并将对象头Mark Word复制到锁记录空间。 线程通过CAS将对象头的Mark Word替换为锁记录空间地址；若成功，则获取锁成功。 如失败，则存在锁竞争，线程通过自旋来获取锁。 轻量锁解锁在解锁时，线程采用CAS将锁记录空间信息替换回对象头的Mark Word；若成功，则释放锁。 若失败，则说明存在锁竞争，则升级为重量级锁。 重量锁因为自旋需要消耗CPU，所以轻量锁升级到重量锁后不能降级。 处于重量级锁状态，其他线程获取锁将被阻塞，指导当前线程释放锁并唤醒其他线程竞争。 锁比较 锁 优点 缺点 说明 偏向锁 速度快，和非同步方法执行效率差不多 出现锁竞争时，需要额外释放锁 适合一个线程并发访问同步块 轻量锁 无阻塞，响应速度快 始终得不到锁的线程会自旋消耗CPU 适合方法块执行块，追求响应速度 重量级锁 无自旋，不消耗CPU 阻塞，响应慢 适合同步块执行慢，追求吞吐量]]></content>
      <categories>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>Java并发编程</tag>
        <tag>synchronized</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java并发编程艺术 - volatile使用和原理]]></title>
    <url>%2Fposts%2F34733%2F</url>
    <content type="text"><![CDATA[Java代码经过Java编译器编译成字节码，并由类加载器加载到JVM运行时数据区，最终由JVM执行引擎执行字节码，转换为汇编指令在CPU内执行。 Java并发机制主要依赖JVM实现和CPU指令。 volatilevolatile修饰变量，提供多处理器并发中共享变量的可见性，是轻量的synchronized。 volatile由CPU指令实现，不会引起上下文切换，性能比synchronized高。 可见性问题可见性问题是受Java内存模型的影响。 从上图可知，多线程对共享变量在本地内存进行处理，虽然提高执行效率，但是将带来可见性和数据同步问题。 多线程编程中，对于volatile共享变量，一个线程进行了修改，对于其他线程能及时读取修改后的值，以做到资源同步。 volatile定义如果一个变量被声明为volatile，那么该变量在多线程中将互相可见，保障准确和一致性。 内存屏障/内存栅栏一系列CPU指令，控制内存操作的顺序，可以解决指令重排和可见性问题。 其中，指令重排是JIT对代码的优化。 内存屏障插入策略： 在volatile写前插入storestore，禁止上面普通写与volatile写重排 在volatile写后插入storeload，禁止下面volatile读/写与volatile写重排 在volatile读后插入loadload，禁止下面普通读与volatile写读重排 在volatile读后插入loadstore，禁止下面普通写与volatile读重排 volatile实现原理在共享变量写前，CPU新增Lock操作指令，实现以下效果： 将当期缓存行回写系统内存 其他CPU缓存该内存地址数据无效 为提高处理速度，CPU不和主存直接交互，而是将主存数据读取到缓存，但缓存写回内存时间未知。 通过volatile将通过Lock指令实现写回操作，其他处理器通过总线检查缓存值是否过期；若发现缓存行地址变更，则将缓存行置为无效。 当处理器处理数据时，发现无效标志则会从主存中重新加载数据至缓存。 说明 Lock前缀指令会引起处理器缓存写回内存。Lock可以锁定缓存区域，实现原子操作。 处理器缓存写回操作将引起其他处理的该缓存无效。处理器嗅探缓存地址，若处于共享状态，无效缓存行后，下次访问进行强制缓存行填充。 volatile优化 JDK7追加64字节能够提高LinkedTransferQueue并发编程的效率 缓存的最小单位是缓存行，常见CPU的缓存行是64字节宽(8字节)，不支持部分缓存行。 不满64字节，则缓存队列头和尾至同一缓存行。 当CPU修改头节点，需要锁定缓存行，导致其他CPU不能处理缓存，影响队列入队和出队效率。 追加至64位，填满缓存行，避免队列的头和尾节点被同一缓存行同时锁定。 volatile使用12345678910111213141516171819202122232425262728293031323334public class VolatileTest &#123; //原子变量，缓存无效直接取主存 private volatile int num = 0; //检测值变化 private void test() &#123; while (true) &#123; //测试在一行代码中，num是否会有多个值情况 if (num == 1 &amp;&amp; num == 2 &amp;&amp; num == 3) &#123; System.out.println("不一致"); &#125; &#125; &#125; //修改值 private void change() &#123; while (true) &#123; //频繁修改num值 for (int i = 0; i &lt; 4; i++) &#123; num = i; &#125; &#125; &#125; public void start() &#123; new Thread(this::test).start(); new Thread(this::change).start(); &#125; public static void main(String[] args) &#123; new VolatileTest().start(); &#125;&#125; 结果频繁出现：不一致若不使用volatile，因为线程执行速度快，偶尔会出现不一致但不频繁说明volatile可以实时同步各线程共享变量 volatile修饰用法 volatile 基本变量int\boolean等，例如volatile int a=1；保障可见性 volatile 对象，例如volatile Singleton singleton；防止指令重排 注意 volatile保障变量在线程间的可见性，但不保障操作原子性]]></content>
      <categories>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>Java并发编程</tag>
        <tag>volatile</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Cloud - 如何利用Zuul实现接口限流]]></title>
    <url>%2Fposts%2F33184%2F</url>
    <content type="text"><![CDATA[以下为Zuul利用ratelimit在网关进行接口限流。 限流方案 方案 说明 基于用户id 根据用户标识或匿名 基于用户角色 根据用户角色 基于用户源IP 请求源IP 基于请求URL 下游服务地址 基于请求方法类型 HTTP请求方法，GET、POST等 基于请求服务 下游服务 POM引入123456&lt;!-- 请求限流 --&gt;&lt;dependency&gt; &lt;groupId&gt;com.marcosbarbero.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-zuul-ratelimit&lt;/artifactId&gt; &lt;version&gt;2.0.4.RELEASE&lt;/version&gt;&lt;/dependency&gt; 参数配置1234567891011121314151617181920212223242526272829303132333435#60秒内允许10个访问，并且要求总请求时间小于1000秒#seviceA在120秒内允许20个访问，并且要求总请求时间小于2000秒#seviceA针对匿名用户，IP为10.10.10.10，角色为用户，请求URL为/api/，请求方法为GETzuul: ratelimit: key-prefix: your-prefix #缓存key的前缀 enabled: true #开启限流 repository: REDIS #key存储方式为redis behind-proxy: true # 当前网关是代理后的请求，需要获取Header中的X-FORWARDED-FOR以便获取源IP add-response-headers: true #在response header中添加限流信息 default-policy-list: # 默认策略 - limit: 10 #每个刷新窗口请求数 quota: 1000 #每个刷新窗口总请求时间(秒) refresh-interval: 60 #刷新窗口时间(秒),默认60秒 type: - user #基于用户标识，默认匿名anonymous - origin #基于用户IP - url #基于下游服务URL - httpmethod #基于请求方法 policy-list: #指定服务策略，优先默认 seviceA: #微服务ID - limit: 20 quota: 2000 refresh-interval: 120 type: - user - origin - url - type: #每种类型值设定 - user=anonymous #指定用户,匿名用户 - origin=10.10.10.10 #指定源URL - url=/api #指定下游请求URL前缀 - role=user #指定用户角色 - httpmethod=get #指定请求方法类型，大小写不敏感 其中，user=anonymous和role=user采用Shiro或者Spring Security进行维护，或者自定义request域UserPrincipal。 数据存储 InMemory(ConcurrentHashMap) Redis Consul Spring Data JPA JCache Infinispan Hazelcast Ignite 将会对服务集群的请求情况同步至选择的存储中，以做到数据共享和实时存储。 源码及原理分析自定义key1234567891011121314151617@Bean public RateLimitKeyGenerator ratelimitKeyGenerator(RateLimitProperties properties, RateLimitUtils rateLimitUtils) &#123; return new DefaultRateLimitKeyGenerator(properties, rateLimitUtils) &#123; @Override public String key(HttpServletRequest request, Route route, RateLimitProperties.Policy policy) &#123; //super.key()为默认实现 //keyPrefix+serviceId+(type1Key+...+typenKey) String key= super.key(request, route, policy) ; //":" + request.getMethod() 为自定义策略 key += ":" + request.getMethod(); //实现对key的重写，限流策略是以key为标识依据 return key; &#125; &#125;; &#125; 自定义错误12345678910111213141516171819@Bean public RateLimiterErrorHandler rateLimitErrorHandler() &#123; return new DefaultRateLimiterErrorHandler() &#123; @Override public void handleSaveError(String key, Exception e) &#123; // 处理存储key异常 &#125; @Override public void handleFetchError(String key, Exception e) &#123; // 处理查询key异常 &#125; @Override public void handleError(String msg, Exception e) &#123; // 处理异常信息 &#125; &#125; &#125; 自定义用户和角色SecuredRateLimitUtils.java 12345678@Overridepublic Set&lt;String&gt; getUserRoles() &#123; Authentication authentication = SecurityContextHolder.getContext().getAuthentication(); if (authentication == null) &#123; return emptySet(); &#125; return AuthorityUtils.authorityListToSet(authentication.getAuthorities());&#125; SecurityContextHolder为Spring Security框架，可获取用户角色和标识。 Spring Security样例如下： 12345678@Override protected void configure(AuthenticationManagerBuilder auth) throws Exception &#123; auth .inMemoryAuthentication() .withUser("user") .password("password") .roles("USER"); &#125;]]></content>
      <categories>
        <category>微服务</category>
      </categories>
      <tags>
        <tag>Spring Cloud</tag>
        <tag>Zuul</tag>
        <tag>ratelimit</tag>
        <tag>限流</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Cloud - 如何利用Zuul进行网关开发]]></title>
    <url>%2Fposts%2F33205%2F</url>
    <content type="text"><![CDATA[Zuul介绍Zuul是Spring Cloud全家桶一员，用于微服务网关开发，实现对外服务请求的白黑名单控制、代理转发、限流、权鉴认证、灰度测试等。 Zuul POM引入1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;!-- spring-boot版本 --&gt; &lt;version&gt;2.0.5.RELEASE&lt;/version&gt; &lt;relativePath/&gt;&lt;/parent&gt;&lt;properties&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;!-- Spring Cloud版本 --&gt; &lt;spring-cloud.version&gt;Finchley.RELEASE&lt;/spring-cloud.version&gt;&lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-ribbon&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-zuul&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.retry&lt;/groupId&gt; &lt;artifactId&gt;spring-retry&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;$&#123;spring-cloud.version&#125;&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt; 开启ZuulApplication.java 1234567891011//开启Zuul@EnableZuulProxy@EnableEurekaClient@SpringBootApplicationpublic class Application &#123; public static void main(String[] args) &#123; SpringApplication.run(Application.class,args); &#125;&#125; Zuul配置bootstrap.yml 1234567891011121314151617181920212223242526272829303132333435#路由方式是serviceIdribbon: #对所有操作请求都进行重试 OkToRetryOnAllOperations: true #切换实例的重试次数 MaxAutoRetriesNextServer: 2 #对当前实例的重试次数 MaxAutoRetries: 1 #请求链接的超时时间 ConnectTimeout: 6000 #请求处理的超时时间 ReadTimeout: 8000 eureka: enable: falsezuul: sensitive-headers: #自动重试 retryable: true routes: client-api: #过滤headers，不进入下游 sensitiveHeaders: Cookie,Set-Cookie,Authorization #服务名称 a: #转发匹配规则 path: /api/a/** #直接转发，不过滤前缀 stripPrefix: false #转发到服务ID serviceId: a-service b: path: /api/b/** stripPrefix: false serviceId: b-server Zuul开发在网关统一完成请求过滤和用户认证AccessFilter.java 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113@Component//实现ZuulFilterpublic class AccessFilter extends ZuulFilter &#123; //实现run逻辑 @Override public Object run() &#123; return exec(); &#125; private Object exec() &#123; RequestContext ctx = RequestContext.getCurrentContext(); //获取HttpServletRequest HttpServletRequest request = ctx.getRequest(); //解析ip String ip = getIpAddr(request); //补充到header，可以带入下游 ctx.addZuulRequestHeader("ip", ip); //接口的白名单和黑名单 String url = request.getRequestURI(); //白名单可以直接进入下游 if (isWhite(url)) &#123; return null; &#125; //黑名单禁止访问 if (isBlack(url)) &#123; setBlack(ctx, url); return null; &#125; //token解析 validToken(ctx, url); return null; &#125; /** * 获取用户id，检验token真实性 * * @param ctx * @param url * @return */ void validToken(RequestContext ctx, String url) &#123; // 获取请求的参数 String token = ctx.getRequest().getHeader(Constant.TOKEN); //解析token业务，获取用户信息 String userId = parseToken(token); //传入下游 ctx.addZuulRequestHeader("userId", userId); &#125; public static boolean setBlack(RequestContext ctx, String requestUrl) &#123; logger.error("无权限请求：&#123;&#125;", requestUrl); setStatus(ctx, EnumStatus.ERROR, false); return true; &#125; public static void setStatus(RequestContext ctx, EnumStatus enumStatus, boolean flag) &#123; ctx.getResponse().setContentType("application/json; charset=utf-8"); //令zuul过滤该请求，不对其进行路由，直接返回客户端错误信息， ctx.setSendZuulResponse(false); ctx.setResponseBody("&#123;\"msg\":\"" + enumStatus.getInfo() + "\",\"code\":" + enumStatus.getValue() + "&#125;"); ctx.set("isSuccess", flag); &#125; /** * 是否是白名单 * * @param url * @return */ boolean isWhite(String url) &#123; return Arrays.stream(Constant.WHITE_LIST).anyMatch(s -&gt; url.contains(s)); &#125; /** * 是否是白名单 * * @param url * @return */ boolean isBlack(String url) &#123; return Arrays.stream(Constant.BLACK_LIST).anyMatch(s -&gt; url.contains(s)); &#125; @Override public boolean shouldFilter() &#123; // 是否执行该过滤器，此处为true，说明需要过滤 return true; &#125; @Override public int filterOrder() &#123; // 数字越大，优先级越低 return 0; &#125; @Override public String filterType() &#123; // 前置过滤器 return "pre"; &#125;&#125; 在网关统一处理异常ErrorFilter.java 12345678910111213141516171819202122232425262728293031@Componentpublic class ErrorFilter extends ZuulFilter &#123; private static Logger log = LoggerFactory.getLogger(ErrorFilter.class); @Override public String filterType() &#123; //异常过滤器 return "error"; &#125; @Override public int filterOrder() &#123; //优先级，数字越大，优先级越低 return 30; &#125; @Override public boolean shouldFilter() &#123; //是否执行该过滤器，true代表需要过滤 return true; &#125; @Override public Object run() &#123; RequestContext ctx = RequestContext.getCurrentContext(); setError(ctx, ctx.getRequest().getRequestURL().toString()); return null; &#125;&#125;]]></content>
      <categories>
        <category>微服务</category>
      </categories>
      <tags>
        <tag>Spring Cloud</tag>
        <tag>Zuul</tag>
        <tag>网关</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Cloud - Ribbon在Zuul上实现灰度和版本测试]]></title>
    <url>%2Fposts%2F25628%2F</url>
    <content type="text"><![CDATA[本文依赖ribbon实现在Spring Cloud中的灰度测试。 POM引入Zuul及下游服务中均引入包 123456&lt;!-- 实现灰度测试关键包 --&gt; &lt;dependency&gt; &lt;groupId&gt;io.jmnarloch&lt;/groupId&gt; &lt;artifactId&gt;ribbon-discovery-filter-spring-cloud-starter&lt;/artifactId&gt; &lt;version&gt;2.1.0&lt;/version&gt; &lt;/dependency&gt; Zuul服务开发12345678910111213private void fixGray(UserInfo userInfo) &#123; // 配置转发渠道，例如用户id if (isGrayer(userInfo.getUserId())) &#123; RibbonFilterContextHolder.clearCurrentContext(); //灰度标识 RibbonFilterContextHolder.getCurrentContext().add("prod", "2"); RibbonFilterContextHolder.getCurrentContext().add("prod", "1.0"); &#125; else &#123; RibbonFilterContextHolder.clearCurrentContext(); RibbonFilterContextHolder.getCurrentContext().add("prod", "1"); RibbonFilterContextHolder.getCurrentContext().add("prod", "1.1"); &#125;&#125; 下游服务开发添加版本拦截器 12345678910@Configurationpublic class WebMvcConfig extends WebMvcConfigurerAdapter &#123; @Override public void addInterceptors(InterceptorRegistry registry) &#123; super.addInterceptors(registry); registry.addInterceptor(new VersionInterceptor()); &#125;&#125; 实现拦截器 123456789101112131415public class VersionInterceptor extends HandlerInterceptorAdapter &#123; @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123; //清除现有数据，防止干扰 RibbonFilterContextHolder.clearCurrentContext(); String prod = request.getHeader("prod"); String version = request.getHeader("version"); if (!StringUtils.isEmpty(prod)&amp;&amp;!StringUtils.isEmpty(version)) &#123; RibbonFilterContextHolder.getCurrentContext().add("prod", prod); RibbonFilterContextHolder.getCurrentContext().add("version", version); &#125; return true; &#125;&#125; 下游服务配置12345678910eureka: instance: preferIpAddress: true instance-id: $&#123;spring.cloud.client.ip-address&#125;:$&#123;server.port&#125; metadataMap: #元信息 prod: 2 #灰度标识，1生产服务,2为灰度服务 version: 1.1 #服务版本标识 client: registerWithEureka: true fetchRegistry: true 注意事项 通过以上配置，启动各服务，可以实现灰度测试和版本测试 在网关依据灰度和版本请求标识，Ribbon利用各服务的元信息进行匹配，以实现过滤和负载 服务中必须配置相应的请求标识，否则该请求无法负载，将会报错 关闭组件，ribbon.filter.metadata.enabled=false #默认true 源码及原理分析 元信息筛选 123456789101112131415161718public class MetadataAwarePredicate extends DiscoveryEnabledPredicate &#123; /** * &#123;@inheritDoc&#125; */ @Override protected boolean apply(DiscoveryEnabledServer server) &#123; //当前请求上下文 final RibbonFilterContext context = RibbonFilterContextHolder.getCurrentContext(); //当前请求属性 final Set&lt;Map.Entry&lt;String, String&gt;&gt; attributes = Collections.unmodifiableSet(context.getAttributes().entrySet()); //当前服务元信息 final Map&lt;String, String&gt; metadata = server.getInstanceInfo().getMetadata(); //服务元信息是否完全包含请求属性 return metadata.entrySet().containsAll(attributes); &#125;&#125; 注册实例 123456789101112131415@Configuration@ConditionalOnClass(DiscoveryEnabledNIWSServerList.class)@AutoConfigureBefore(RibbonClientConfiguration.class)@ConditionalOnProperty(value = "ribbon.filter.metadata.enabled", matchIfMissing = true)public class RibbonDiscoveryRuleAutoConfiguration &#123; //在Spring application context注册DiscoveryEnabledRule @Bean @ConditionalOnMissingBean @Scope(ConfigurableBeanFactory.SCOPE_PROTOTYPE) public DiscoveryEnabledRule metadataAwareRule() &#123; //使用自定义元信息过滤 return new MetadataAwareRule(); &#125;&#125; 配置请求信息 RibbonFilterContextHolder.getCurrentContext().add(&quot;version&quot;, &quot;1.1&quot;).add(&quot;variant&quot;, &quot;A&quot;); 在zuul中配置，以便调取下游 在下游拦截器中配置，以便当前服务继续调用下游服务 也可以在RestTemplate的ClientHttpRequestInterceptor中配置]]></content>
      <categories>
        <category>微服务</category>
      </categories>
      <tags>
        <tag>Spring Cloud</tag>
        <tag>Zuul</tag>
        <tag>Ribbon</tag>
        <tag>灰度测试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Cloud - Nacos与Eureka区别及如何选型]]></title>
    <url>%2Fposts%2F35353%2F</url>
    <content type="text"><![CDATA[Nacos与Eureka均提供注册中心和服务治理功能，以下为两则差异和选型方案。 功能差异 模块 Nacos Eureka 说明 注册中心 是 是 服务治理基本功能，负责服务中心化注册 配置中心 是 否 Eureka需要配合Config实现配置中心，且不提供管理界面 动态刷新 是 否 Eureka需要配合MQ实现配置动态刷新，Nacos采用Netty保持TCP长连接实时推送 可用区AZ 是 是 对服务集群划分不同区域，实现区域隔离，并提供容灾自动切换 分组 是 否 Nacos可用根据业务和环境进行分组管理 元数据 是 是 提供服务标签数据，例如环境或服务标识 权重 是 否 Nacos默认提供权重设置功能，调整承载流量压力 健康检查 是 是 Nacos支持由客户端或服务端发起的健康检查，Eureka是由客户端发起心跳 负载均衡 是 是 均提供负责均衡策略，Eureka采用Ribion 管理界面 是 否 Nacos支持对服务在线管理，Eureka只是预览服务状态 部署安装 模块 Nacos Eureka 说明 MySql 是 否 Nacos需要采用MySql进行数据进行持久化 MQ 否 是 Eureka需要采用MQ进行配置中心刷新 配置中心 是 否 Eureka结合Config或者Consul实现配置中心 配置文件 在线编辑 本地文件或者Git远程文件 Eureka结合Config或者Consul 集群 是 是 Nacos需要配置集群ip再启动 稳定及扩展性 模块 Nacos Eureka 说明 版本 1.0.0 1.9.9 Eureka2.0已停止开发,Nacos处于1.x-2.0开发 厂商 阿里巴巴 Netflix Netflix已长期用于生产,阿里刚起步 生产建议 否 是 Nacos0.8以前不可用于生产,建议生产采用Nacos1.0,便于节省配置中心集群和服务管理 未来发展 是 否 Nacos 2.0主要关注在统一服务管理、服务共享及服务治理体系的开放的服务平台的建设 选型建议采用Eureka方案的考虑 想用Spring Cloud原生全家桶 想用本地文件和Git作为配置管理的,将配置与服务分开管理 考虑短期的稳定性 采用Nacos方案的考虑 想在线对服务进行上下线和流量管理 不想采用MQ实现配置中心动态刷新 不想新增配置中心生产集群 考虑引入Spring Cloud Alibaba生态]]></content>
      <categories>
        <category>微服务</category>
      </categories>
      <tags>
        <tag>Spring Cloud</tag>
        <tag>Nacos</tag>
        <tag>Eureka</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux运维常用命令 - grep]]></title>
    <url>%2Fposts%2F48230%2F</url>
    <content type="text"><![CDATA[以下为Linux开发中常用的命令。 筛选文本并查看指定上下行数常用于筛选日志，并查看上下文 grep [选项] ‘模式’ [文件] 选项: -A 后几行 -B 前几行 -C 前后几行 模式: 待筛选文本 文件: 待筛选源文件举例 123grep -A 20 'cat' info.log # 显示info.log及后20行grep -B 20 'cat' info.log # 显示info.log及前20行grep -C 20 'cat' info.log # 显示info.log文件里匹配cat字串行以及上下20行]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java并发编程艺术 - 死锁产生及优化]]></title>
    <url>%2Fposts%2F20463%2F</url>
    <content type="text"><![CDATA[本文介绍死锁产生的条件及优化方案。 死锁产生 线程互相等待 常见的死锁有JDK死锁和数据库死锁。 以JDK死锁为例： 12345678910111213141516171819202122232425262728293031323334353637383940public class Deadlock &#123; static class Friend &#123; private final String name; public Friend(String name) &#123; this.name = name; &#125; public String getName() &#123; return this.name; &#125; //同步锁bow public synchronized void bow(Friend bower) &#123; System.out.format("%s: %s" + " has bowed to me!%n", this.name, bower.getName()); //调用同步锁bowBack bower.bowBack(this); &#125; //同步锁bowBack public synchronized void bowBack(Friend bower) &#123; System.out.format("%s: %s" + " has bowed back to me!%n", this.name, bower.getName()); &#125; &#125; public static void main(String[] args) &#123; final Friend alphonse = new Friend("Alphonse"); final Friend gaston = new Friend("Gaston"); new Thread(new Runnable() &#123; public void run() &#123; alphonse.bow(gaston); &#125; &#125;).start(); new Thread(new Runnable() &#123; public void run() &#123; gaston.bow(alphonse); &#125; &#125;).start(); &#125;&#125; 输出： 12Alphonse: Gaston has bowed to me!Gaston: Alphonse has bowed to me! 分析： 执行程序期望是alphonse向gaston鞠躬，并等待gaston还礼；gaston向alphonse鞠躬，并等待alphonse还礼。 两个线程，分别是alphonse线程和gaston线程；alphonse线程传入gaston对象，gaston传入alphonse对象，均执行执行bowBack。 问题是：如果单线程执行，例如alphonse线程执行，结果会是： 12Alphonse: Gaston has bowed to me!Gaston: Alphonse has bowed back to me! 多线程执行时，alphonse和gaston互相鞠躬，但是均等待对方回礼，则在bowBack产生等待死锁。 alphonse和gaston均为对象锁，但是内部进行了互相调用bowBack(Friend bower)。 alphonse获得对象锁，gaston获得对象锁。 alphonse同步调用bow，gaston同步调用bow；没有问题，不会死锁。 alphonse同步锁继续，使用gaston对象调用bowBack，但是gaston也在使用alphonse对象调用bowBack，产生问题。 alphonse-&gt;gaston-&gt;bowBack;gaston-&gt;alphonse-&gt;bowBack;因此alphonse和gaston对象锁都互相加锁且等待对方释放锁，导致死锁。 死锁查看 查看进程执行情况： 1jstack -l 69733 或者采用VisualVM，查看两个对象锁处于等待状态 除了死锁还有活锁、饥饿锁 Oracle说明 避免死锁方法 避免一个线程操作获取多个锁，例如上例中一个方法内获取两个对象锁 避免一个线程在锁内占用多个资源，尽量保证每个锁占用一个，例如上例一个方法期望锁定两个对象 采用定时锁，即lock.tryLock(timeout)，即在限定时间内获取锁，获取不到则放弃，防止死锁等待 123456789/** * @return &#123;@code true&#125; 如果当前线程请求到锁或者本来就拥有锁 * @throws InterruptedException if the current thread is interrupted * @throws NullPointerException if the time unit is null */ public boolean tryLock(long timeout, TimeUnit unit) throws InterruptedException &#123; return sync.tryAcquireNanos(1, unit.toNanos(timeout)); &#125; 对于数据库锁，加锁和解锁在一个数据库连接，否则解锁失败。同一个对象锁进行加锁和解锁操作。 123456789try &#123; //关闭事务自动提交(开启事务) this.connection.setAutoCommit(false); //无异常，手动提交 this.connection.commit();&#125; catch(Exception e) &#123; //当前；连接回滚 this.connection.rollback();&#125; 并发包JUC使用 参考Orace文档]]></content>
      <categories>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>Java并发编程</tag>
        <tag>多线程</tag>
        <tag>死锁</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[搭建GitHub博客教程 - Hexo及Next主题优化]]></title>
    <url>%2Fposts%2F60068%2F</url>
    <content type="text"><![CDATA[本文为针对Hexo博客和Next主题的优化和配置。 标题配置vi _config_yml 1234567title: xxx的技术博客subtitle: xxxdescription: xxkeywords: xxxauthor: xxlanguage: zh-CNtimezone: Asia/Chongqing 首页文章预览限制字数cd themes/next vi _config.yml 123auto_excerpt: enable: true length: 150 文章内使用&lt;!--more--&gt;作为预览分割 修改文章内链接文本样式./themes/next/source/css/_common/components/post/post.styl 末尾添加： 1234567891011// 文章内链接文本样式.post-body p a&#123; color: #0593d3; border-bottom: none; border-bottom: 1px solid #0593d3; &amp;:hover &#123; color: #fc6423; border-bottom: none; border-bottom: 1px solid #fc6423; &#125;&#125; 样式优化cd themes/next vi _config.yml 12345678910111213141516171819202122232425262728293031323334scheme: Piscesgithub_banner: enable: true permalink: https://github.com/xxxx title: Follow me on GitHubback2top: enable: true # Back to top in sidebar. sidebar: true # Scroll percent label in b2t button. scrollpercent: true //加载条pace: true//阅读统计busuanzi_count: enable: true//头像avatar: # In theme directory (source/images): /images/avatar.gif # In site directory (source/uploads): /uploads/avatar.gif # You can also use other linking images. url: http://xx/xxx.jpeg # If true, the avatar would be dispalyed in circle. rounded: true # The value of opacity should be choose from 0 to 1 to set the opacity of the avatar. opacity: 1 # If true, the avatar would be rotated with the cursor. rotated: true favicon.ico 放入/themes/next/source/images 123favicon: small: /images/favicon.png medium: /images/favicon.png 开启标签和分类主要是设置页面类型及关闭评论 创建 12hexo new page tagshexo new page categories 修改主题配置vi ./source/tags/index.md 1234title: tagsdate: 2019-04-20 14:24:27type: "tags"comments: false vi ./source/tags/index.md 1234title: tagsdate: 2019-04-20 14:24:27type: "tags"comments: false 菜单修改主要是打开菜单及统计 vi ./themes/next/_config.yml 123456789menu: home: / || home tags: /tags/ || tags categories: /categories/ || th archives: /archives/ || archive menu_settings: icons: true badges: true RSS、搜索、永久链接1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859npm install hexo-generator-feed --savenpm install hexo-generator-searchdb --savenpm install hexo-symbols-count-time --savenpm i --save hexo-wordcountnpm install hexo-abbrlink --savevi _config.ymlpermalink: posts/:abbrlink/feed: type: atom path: atom.xml limit: 20 hub: content: content_limit: 140 content_limit_delim: ' '# 搜索search: path: search.xml field: post format: html limit: 10000# 时间统计symbols_count_time: count: Symbols count in article count_total: Symbols count total time: Reading time time_total: Reading time total time_minutes: mins.# 字数统计post_wordcount: item_text: true #字数统计 wordcount: true #预览时间 min2read: true #总字数,显示在页面底部 totalcount: false separated_meta: true vi ./themes/next/_config.ymlrss: /atom.xmllocal_search: enable: true symbols_count_time: separated_meta: true item_text_post: true item_text_total: true awl: 4 wpm: 275 pm2 restart allhexo shexo cleanhexo g 本文结束在路径/themes/next/layout/_macro中新建 passage-end-tag.swig 文件,并添加以下内容： 12345&lt;div&gt; &#123;% if not is_index %&#125; &lt;div style="text-align:center;color: #ccc;font-size:14px;"&gt;------ 本文结束------&lt;/div&gt; &#123;% endif %&#125;&lt;/div&gt; 打开themes/next/layout/_macro/下的post.swig文件,添加： 12345678&#123;#####################&#125;&#123;### END POST BODY ###&#125;&#123;#####################&#125;&lt;div&gt; &#123;% if not is_index %&#125; &#123;% include 'passage-end-tag.swig' %&#125; &#123;% endif %&#125; &lt;/div&gt; 注意添加位置 vi ./themes/next/_config.yml,在末尾添加： 123# 文章末尾添加“本文结束”标记passage_end_tag: enabled: true SEO安装与配置1234567npm install hexo-generator-sitemap --savenpm install hexo-generator-baidu-sitemap --savesitemap: path: sitemap.xmlbaidusitemap: path: baidusitemap.xml 在hexo-site\source中新建文件robots.txt,内容如下，请自行替换 123456789101112131415User-agent: *Allow: /Allow: /archives/Allow: /categories/Allow: /tags/ Allow: /about/ Disallow: /vendors/Disallow: /js/Disallow: /css/Disallow: /fonts/Disallow: /vendors/Disallow: /fancybox/Sitemap: https://xxx.github.com/sitemap.xmlSitemap: https://xxx.github.com/baidusitemap.xml google登录https://search.google.com/search-console/welcome 网址前缀-&gt;其他验证方法-&gt;HTML标记，复制meta代码。 百度123vi themes/next/_config.ymlbaidu_push: true 登录https://ziyuan.baidu.com/linksubmit/url 站点管理-&gt;新建站点 HTML标签验证-&gt;复制meta代码 验证1vi ./themes/next/layout/_partials/head/head.swig 在meta下添加google的meta代码。 1hexo clean &amp;&amp; hexo g &amp;&amp; hexo d 然后分别点击刚才 百度、谷歌 验证页面的 验证 按钮进行站点验证。 提交sitemap谷歌 在https://search.google.com/search-console中添加新的站点地图 输入/sitemap.xml 百度 在https://ziyuan.baidu.com/linksubmit/index链接提交-&gt;自动提交-&gt;sitemap 输入:https://xxxx.github.io/baidusitemap.xml 坑：GitHub Pages 禁止百度爬虫，且需要HTTPS认证，提供自定义域名。 百度站点统计访问注册https://tongji.baidu.com/web/welcome/login Baidu Analytics ID: hm.src = https://hm.baidu.com/hm.js?`81b7a9fddbd9b9470364a87a43991a67`; 12vi themes/next/_config.ymlbaidu_analytics: 81b7a9fddbd9b9470364a87a43991a67 评论注册OAuth Application在GitHub上注册新应用, 链接:https://github.com/settings/applications/new 12345Application name 应用名称, 可以任意填入Homepage URL 网站URL, 注意用https://开头, 开头如https://vonsdite.cnApplication description 应用描述, 可以任意填入Authorization callback URL 网站URL, 注意用https://开头, 如https://vonsdite.cn注册后记下Client ID和Client Secret, 后续要使用到 修改主题配置文件_config.yml 在主题配置文件themes/next/_config.yml中添加如下内容: 12345678gitalk: enable: true githubID: github帐号 # 例：vonsdite 注意必须小写 repo: 仓库名称 # 例：vonsdite.github.io ClientID: Client ID # 上文注册 OAuth Application后得到的值 ClientSecret: Client Secret # 上文注册 OAuth Application后得到的值 adminUser: github帐号 # 指定可初始化评论账户, 例：vonsdite 注意必须小写 distractionFreeMode: true 版权声明主题配置文件 12345creative_commons: license: by-nc-sa sidebar: false post: true language: 相关文章npm install hexo-related-popular-posts --save 主题配置 123456related_posts: enable: true title: # custom header, leave empty to use the default one display_in_home: false params: maxCount: 5 图片大小配置下载 存储路径:./themes/next/source/js/hexo_resize_image.js 修改./themes/next/layout/_partials/head/head.swig 添加 1&lt;script src=&quot;&#123;&#123; url_for(theme.js) &#125;&#125;/hexo_resize_image.js?v=&#123;&#123; version &#125;&#125;&quot;&gt;&lt;/script&gt; 使用语法： url?&lt;width&gt;x&lt;height&gt;，指定宽高，例如/image/test.jpg?200x200 url?&lt;width&gt;x&lt;height&gt;，指定宽，高等比缩放，例如/image/test.jpg?200x url?&lt;width&gt;x&lt;height&gt;，指定高，宽等比缩放，例如/image/test.jpg?x200 url?缩放比例，指定缩放例如，例如/image/test.jpg?50 进度条1234567cd themes/nextgit clone https://github.com/theme-next/theme-next-pace source/lib/pacevi _config.ymlpace: true]]></content>
      <categories>
        <category>工具利器</category>
      </categories>
      <tags>
        <tag>工具</tag>
        <tag>Hexo</tag>
        <tag>GitHub</tag>
        <tag>Next</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Cloud - Nacos集群配置和集成]]></title>
    <url>%2Fposts%2F57096%2F</url>
    <content type="text"><![CDATA[本文介绍生产环境中Nacos集群的安装配置，及与Spring Cloud的集成。 Nacos介绍类似于Spring Cloud Eureka和Spring Cloud Config，Nacos提供了服务注册管理和配置中心的功能；其中配置中心实现动态刷新，无需MQ。 相对于Eureka，Nacos是由阿里提供的开源服务，可以兼容Spring Cloud，也支持其他语言例如python服务的注册管理。 Nacos安装 环境要求： 64 bit JDK 1.8+ MySql 5.6.5+ 安装包下载当前版本 1.0.0 解压unzip nacos-server-$version.ziptar -xvf nacos-server-$version.tar.gz Nacos配置 MySql内执行sql/nacos/conf/nacos-mysql.sql 数据源配置/nacos/conf/application.properties 12345spring.datasource.platform=mysqldb.num=1db.url.0=jdbc:mysql://xxx:3306/nacos_config?characterEncoding=utf8&amp;connectTimeout=1000&amp;socketTimeout=3000&amp;autoReconnect=truedb.user=xxxdb.password=xxx 集群配置/nacos/conf/cluster.conf 123192.168.1.100:8848192.168.1.101:8848192.168.1.102:8848 在100-102机器上，复制存储nacos文件。 Nginx负载均衡部署集群后，由3台集群提供管理界面，可以配置Nginx进行负载。 123456789101112131415161718upstream nacos_cluster &#123; server 192.168.1.100:8848; server 192.168.1.101:8848; server 192.168.1.102:8848;&#125;server&#123; listen 80; server_name localhost; location / &#123; proxy_pass http://nacos_cluster; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; &#125;&#125; 8848为管理系统端口访问localhost,可以进入Nacos管理界面默认用户名和密码是nacos/nacosusers表存储的是用户名、密码，可以进行修改new BCryptPasswordEncoder().encode(“nacos”)修改密码 启动和关闭 /nacos/bin 启动 sh startup.sh 启动后打印的关键参数 -server -Xms2g -Xmx2g -Xmn1g -XX:MetaspaceSize=128m -XX:MaxMetaspaceSize=320m -XX:-OmitStackTraceInFastThrow -XX:+HeapDumpOnOutOfMemoryError -XX:-UseLargePages -verbose:gc -XX:+PrintGCDetails -XX:+PrintGCDateStamps -XX:+PrintGCTimeStamps -XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles=10 -XX:GCLogFileSize=100M关闭 sh shutdown.sh Spring Cloud集成Nacospom引入12345678910111213141516171819202122232425262728293031323334353637383940414243&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.0.5.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;/parent&gt;&lt;properties&gt; &lt;spring-cloud-alibaba-dependencies.version&gt;0.2.1.RELEASE&lt;/spring-cloud-alibaba-dependencies.version&gt; &lt;spring-cloud.version&gt;Finchley.RELEASE&lt;/spring-cloud.version&gt;&lt;/properties&gt;&lt;dependencies&gt; &lt;!-- nacos服务注册与发现 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- nacos分布式配置 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-config&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt;&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;$&#123;spring-cloud.version&#125;&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-alibaba-dependencies&lt;/artifactId&gt; &lt;version&gt;$&#123;spring-cloud-alibaba-dependencies.version&#125;&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt; 配置参数Application.java 123456789@EnableDiscoveryClient@SpringBootApplication@RefreshScope@EnableFeignClientspublic class Application&#123; public static void main(String[] args) &#123; SpringApplication.run(Application.class, args); &#125;&#125; bootstrap.yml 1234567891011spring: application: name: xxxx profiles: active: dev cloud: nacos: discovery: server-addr: 192.168.1.100:8848,192.168.1.101:8848,192.168.1.102:8848 #注册中心地址集群 config: server-addr: 192.168.1.100:8848,192.168.1.101:8848,192.168.1.102:8848 #配置中心地址集群 fegin测试1234567@FeignClient(value = "xxxx")public interface XXXServer &#123; // 获取主码描述 @RequestMapping(path = "/api/xxxx", method = RequestMethod.POST) String getInfo();&#125;]]></content>
      <categories>
        <category>微服务</category>
      </categories>
      <tags>
        <tag>Spring Cloud</tag>
        <tag>Nacos</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java并发编程艺术 - 多线程与资源限制]]></title>
    <url>%2Fposts%2F10420%2F</url>
    <content type="text"><![CDATA[文本介绍多线程和资源的关系。 是否多线程越多速度越快？ 结论：并发编程中采用多线程，并非线程越多执行效率越高。 线程执行是由CPU分配较短的时间片，线程在得到时间片时执行，并在时间片后挂起，并切换其他线程执行。 线程切换时先会保存上一个线程状态，并加载当前线程的历史状态。 因为线程的上下文切换需要时间，影响多线程执行速度。 在执行某些简单、快速任务情况下，多线程执行效率还不如单线程执行。假如单核采用单线程执行任务仅需要20ms，但单核采用多线程，并发100，可能创建线程时间就超出20ms，再加上单核只能执行单线程，需要多线程频繁挂起、上下文切换肯定慢。 在低核时，不建议采用多线程进行CPU密集型计算；建议采用多线程执行监听输入、读取文件、网络通信等IO密集型操作。 如何减少上下文切换 采用无锁的并发编程，即不进行锁竞争；例如根据ID进行Hash取模，多线程进行分段处理数据。我们常见的JDK1.7中ConcurrentHashMap就是锁分段技术，对key进行hashcode，然后取桶位置，默认1/16；在更新数据时锁数据所在桶，不影响其他桶并发操作，以提高并发处理数据速度。 12345678910111213141516public V put(K key, V value) &#123; if (value == null) throw new NullPointerException(); // 计算键对应的散列码 int hash = hash(key.hashCode()); // 根据散列码找到对应的 Segment return segmentFor(hash).put(key, hash, value, false);&#125;/*** 使用 key 的散列码来得到 segments 数组中对应的 Segment*/final Segment&lt;K,V&gt; segmentFor(int hash) &#123; // 最后根据下标值返回散列码对应的 Segment 对象 return segments[(hash &gt;&gt;&gt; segmentShift) &amp; segmentMask];&#125; CAS算法，JAVA采用Atomic的CAS算法进行乐观锁更新数据，不进行加锁。所谓CAS其实就是compareAndSwap即比较并交换，参数有3个为old、expect和update；即如果old和expect仍然一致，没有因为并发和内存不可见性被修改，则修改old为update。 例如AtomicInteger中进行变量自增： 123456789101112131415161718192021/** * 通过当前值进行原子递增. * * @return 更新值 */public final int incrementAndGet() &#123; return unsafe.getAndAddInt(this, valueOffset, 1) + 1;&#125;public final int getAndAddInt(Object var1, long var2, int var4) &#123; int var5; do &#123; var5 = this.getIntVolatile(var1, var2); &#125; while(!this.compareAndSwapInt(var1, var2, var5, var5 + var4));//cas操作 return var5;&#125;public final boolean compareAndSet(int expect, int update) &#123; return unsafe.compareAndSwapInt(this, valueOffset, expect, update);&#125; 采用最小线程。避免不必要的线程，处于等待状态。 例如JUC包Executors类创建线程池参数，corePoolSize为核心线程数量，如allowCoreThreadTimeOut不设置，可以认为corePoolSize是最小线程数。 如果设置和maximumPoolSize一样大，则表示即使达到keepAliveTime空闲时间也不回收，均处于waiting状态。 123456789101112131415161718192021222324252627282930313233343536373839404142/** * 创建单个线程 * * @param threadFactory 线程工厂 * * @return 单线程执行器 * @throws NullPointerException if threadFactory is null */public static ExecutorService newSingleThreadExecutor(ThreadFactory threadFactory) &#123; return new FinalizableDelegatedExecutorService (new ThreadPoolExecutor(1, 1, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;(), threadFactory));&#125;/** * 根据参数和配置，创建线程池. * * @param corePoolSize 池中核心线程数 * @param maximumPoolSize 池中最大线程数 * @param keepAliveTime 线程数大于核心线程数时, 多余的待回收线程最大空闲时间 * @param unit 时间单位 * @param workQueue 任务执行队列 * @param threadFactory 创建线程的工厂 * @throws IllegalArgumentException if one of the following holds:&lt;br&gt; * &#123;@code corePoolSize &lt; 0&#125;&lt;br&gt; * &#123;@code keepAliveTime &lt; 0&#125;&lt;br&gt; * &#123;@code maximumPoolSize &lt;= 0&#125;&lt;br&gt; * &#123;@code maximumPoolSize &lt; corePoolSize&#125; * @throws NullPointerException if &#123;@code workQueue&#125; * or &#123;@code threadFactory&#125; is null */public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory) &#123; this(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue, threadFactory, defaultHandler);&#125; 协程。在单线程中实现多任务的调度，并在单线程中维持多任务的切换。 资源限制的挑战 并发编程受限与机器硬件或软件资源。例如带宽、硬盘读写速度等硬件资源和数据库连接数、socket连接数等软件资源。 并发编程为加快执行速度，将串行任务并发执行，受资源影响，实际仍在串行切换执行，切换上下文和资源调度反而降低执行速度。 解决资源限制，采用集群执行，改单机为多机。对数据id取机器数模，在该机器处理该数据；软件资源考虑资源池复用，NIO等。 在资源限制下并发编程，根据资源调整并发度，例如读写分离，读写锁等。]]></content>
      <categories>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>Java并发编程</tag>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[IDEA开发快捷键 - Mac]]></title>
    <url>%2Fposts%2F10018%2F</url>
    <content type="text"><![CDATA[本文介绍IDEA中进行Java开发的常用快捷键。 编辑撤销： ⌘+Z切换大小写： ⇧+⌘+U上一个位置： ⌥+⌘+←下一个位置： ⌥+⌘+→(反)注释行： ⌘+/(反)注释块： ⌥+⌘+/格式化： ⌥+⌘+L生成构造器： ⌘+N查看方法实现： ⌥+⌘+B删除当前或者选中块行： ⌘+⌫查找全局查找： ⇧+⇧]]></content>
      <categories>
        <category>工具利器</category>
      </categories>
      <tags>
        <tag>IDEA</tag>
        <tag>工具</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[快速搭建GitHub博客教程 - Hexo及Next主题安装]]></title>
    <url>%2Fposts%2F17587%2F</url>
    <content type="text"><![CDATA[本文为在Mac上利用Hexo搭建GitHub博客过程，选择主题为Next。 Git安装和配置Git安装 下载地址：downloads 选择Mac版本并安装 确认安装成功 1git --version Git GUI安装 下载地址：git-scm 建议：命令行用git bash，工具用SourceTree git常用命令：gittutorial Git私钥公钥配置 生成公钥和私钥 Github配置注册 地址:注册 创建Respository new Repository name:[username].github.io 配置公钥 settings 新建SSH Keys，输入本地公钥 查看本地公钥：cd ~ cd .ssh/cat id_rsa.pub拷贝结果至github的SSH Keys Hexo安装和配置Hexo安装 安装：npm install -g hexo-cli 初始化目录 hexo init [folder] hexo Next主题安装 cd hexo git clone https://github.com/theme-next/hexo-theme-next themes/next hexo-theme-next Hexo主题配置 vi _config.yml 修改theme: next Hexo配置Github部署地址 安装插件 npm install hexo-deployer-git –save 修改Hexo vi _config.yml，修改内容如下: 1234deploy: type: git repo: git@github.com:username/username.github.io.git brach: master deployment hexo-deployer-git Hexo操作12345hexo s，启动hexo d -g，生成并发布hexo new ’title‘，新建文章 参考文档 Mac后台启动Hexo服务准备工作 安装pm2 npm install -g pm2 编辑脚本代码 在hexo博客的根目录下新建run.js文件 12345678910//run.jsconst &#123; exec &#125; = require('child_process')exec('hexo s',(error, stdout, stderr) =&gt; &#123; if(error)&#123; console.log(`exec error: $&#123;error&#125;`) return &#125; console.log(`stdout: $&#123;stdout&#125;`); console.log(`stderr: $&#123;stderr&#125;`);&#125;) 运行 pm2 start run.js 重启pm2 restart all]]></content>
      <categories>
        <category>工具利器</category>
      </categories>
      <tags>
        <tag>工具</tag>
        <tag>Hexo</tag>
        <tag>GitHub</tag>
        <tag>Next</tag>
      </tags>
  </entry>
</search>
