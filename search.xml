<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Shadowsocks配置]]></title>
    <url>%2Fposts%2F44441%2F</url>
    <content type="text"><![CDATA[更新源如果是新系统，请先刷新软件源及更新软件 1sudo apt-get update &amp;&amp; sudo apt-get upgrade Ubuntu 14.04 和 Ubuntu 16.04 用户需新增 PPA 源 1sudo apt-get install software-properties-common &amp;&amp; sudo add-apt-repository ppa:max-c-lv/shadowsocks-libev &amp;&amp; sudo apt-get update 安装 Shadowsocks-libev1sudo apt install shadowsocks-libev 安装 simple-obfs（依次运行） 123456789sudo apt-get install --no-install-recommends build-essential autoconf libtool libssl-dev libpcre3-dev libc-ares-dev libev-dev asciidoc xmlto automake gitgit clone https://github.com/shadowsocks/simple-obfs.gitcd simple-obfsgit submodule update --init --recursive./autogen.sh./configure &amp;&amp; makesudo make installcd ..rm -rf simple-obfs 配置编辑配置文件 123456789101112sudo vim /etc/shadowsocks-libev/config.json&#123; &quot;server”:”0.0.0.0”, &quot;server_port&quot;:8588, &quot;local_port&quot;:7080, &quot;password&quot;:&quot;xxx&quot;, &quot;timeout&quot;:600, &quot;method&quot;:&quot;chacha20-ietf-poly1305&quot;, &quot;mode&quot;:&quot;tcp_and_udp&quot;, &quot;plugin&quot;:&quot;/usr/local/bin/obfs-server&quot;, &quot;plugin_opts&quot;:&quot;obfs=http&quot;&#125; 客户端查看插件 1~/Library/Application Support/ShadowsocksX-NG/plugins/ 插件配置 12plugin：simple-obfsplugin_opts：obfs=http;obfs-host=www.baidu.com 管理 开启服务 1sudo systemctl start shadowsocks-libev 停止服务 1sudo systemctl stop shadowsocks-libev 重启服务 1sudo systemctl restart shadowsocks-libev 开机启动 1sudo systemctl enable shadowsocks-libev 日志 1systemctl status shadowsocks-libev 测试 1ss-server -c /etc/shadowsocks-libev/config.json start -v ps 1ps -ef | grep -v grep | grep "server"]]></content>
      <categories>
        <category>工具利器</category>
      </categories>
      <tags>
        <tag>Shadowsocks</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[IDEA自定义Archetype]]></title>
    <url>%2Fposts%2F31081%2F</url>
    <content type="text"><![CDATA[创建自定义骨架生成骨架在maven项目下，执行mvn archetype:create-from-project，在target/generated-sources/archetype目录下生成Archetype project 安装骨架到本地cd target/generated-sources/archetype后，mvn install安装archetype project到本地仓库 ps：如果是maven多模块项目，在根目录下执行mvn archetype:create-from-project mvn install后，会在本地的maven仓库，按照maven坐标创建对应的archetype文件 注意：骨架的ArtifactId默认使用当前且添加后缀-archetype 使用自定义模板查看本地在当前的目录下，mvn archetype:generate -DarchetypeCatalog=local，查看本地archetype列表 选择使用choose number，按步骤输入基本参数groupId/artifactId/version/package 随后在当前目录下，以artifactId为目录创建一个新的项目 IDEA使用自定义模板添加到IDEA File-&gt;New-&gt; Project 选择Create from archetype Add Archetype 输入刚创建的骨架 1234GroupId：xx.xx.xxArtifactId：xx-xx-archetypeVersion：1.0-SNAPSHOTRepository(option)：local 随后点击Next 输入新的项目标识,groupId/artifactId/version 修改生成的项目结构为所需]]></content>
      <categories>
        <category>工具利器</category>
      </categories>
      <tags>
        <tag>IDEA</tag>
        <tag>工具</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java8处理空对象之Optional]]></title>
    <url>%2Fposts%2F19687%2F</url>
    <content type="text"><![CDATA[OptionalJava8中引入java.util.Optional，这是一个封装Optional值的类。 举例来说，如果一个人可能有也可能没有车，那么Person类内部的car变量就不应该声明为Car，遭遇某人没有车时不应该把null引用赋值给它，而是应该将其声明为Optional类型。 在代码中始终如一地使用Optional，能非常清晰地界定出变量值的缺失是结构上的问题，还是算法上的缺陷，抑或是数据中的问题。 引入Optional类的意图并非要消除每一个null引用。与此相反，它的目标是帮助更好地设计出普适的API，以便看到方法签名，就能了解它是否接受一个Optional的值。这种强制会积极的将变量从Optional中解包出来，直面缺失的变量值。 创建Optional对象 Optional.empty，创建一个空的Optional对象 1Optional&lt;Car&gt; optCar = Optional.empty(); Optional.of，依据一个非空值创建一个Optional对象 1Optional&lt;Car&gt; optCar = Optional.of(car); 如果car是一个null，这段代码会立即抛出一个NullPointerException，而不是等到试图访问car的属性值时才返回一个错误。 Optional.ofNullable，创建一个允许null值的Optional对象1Optional&lt;Car&gt; optCar = Optional.ofNullable(car); 如果car是null，那么得到的Optional对象就是个空对象。 不过get()方法在遭遇到空的Optional对象时也会抛出异常，所以不按照约定的方式使用它，又会让再度陷入由null引起的代码维护的梦魇。 使用map从Optional对象中提取和转换值map操作会将提供的函数应用于流的每个元素。你可以把Optional对象看成一种特殊的集合数据，它至多包含一个元素。 如果Optional包含一个值，那函数就将该值作为参数传递给map，对该值进行转换。如 果Optional为空，就什么也不做。 1234String name = null;if(insurance != null)&#123; name = insurance.getName();&#125; 优化 123Optional&lt;Insurance&gt; optInsurance = Optional.ofNullable(insurance); Optional&lt;String&gt; name = optInsurance.map(Insurance::getName); 使用flatMap链接Optional对象使用流时，flatMap方法接受一个函数作为参数，这个函数的返回值是另一个流。 这个方法会应用到流中的每一个元素，最终形成一个新的流。但是flagMap会用流的内容替换每个新生成的流。 12345public String getCarInsuranceName(Optional&lt;Person&gt; person) &#123; return person.flatMap(Person::getCar) .flatMap(Car::getInsurance) .map(Insurance::getName) .orElse("Unknown");&#125; 使用Optional解引用串接对象上例中，以Optional封装的Person入手，对其调用flatMap(Person::getCar)。 flatMap将某个Function作为参数，被传递给Optional封装的Person对象，对其进行转换。Function的具体表现是一个方法引用，即对Person对象的getCar方法进行调用。由于该方法返回一个Optional类型的对象，Optional内的Person也被转换成了这种对象的实例，结果就是一个两层的Optional对象，最终它们会被flagMap操作合并。 可以将这种合并操作简单地看成把两个Optional对象结合在一起，如果其中有一个对象为空，就构成一个空的Optional对象。如果你对一个空的Optional对象调用flatMap，结果不会发生任何改变， 返回值也是个空的Optional对象。 如果Optional封装了一个Person对象，传递给flapMap的Function，就会应用到Person上对其进行处理。这个例子中，由于Function的返回值已经是一个Optional对象，flapMap方法就直接将其返回。 如果调用链上的任何一个方法返回一个空的Optional，那么结果就为空，否则返回的值就是你期望的保险公司的名称。 如何读出这个值呢?毕竟最后得到的这个对象还是个Optional，它可能包含保险公司的名称，也可能为空。可以使用了一个名为orElse的方法，当Optional的值为空时，它会为其设定一个默认值。 无法序列化由于Optional类设计时就没特别考虑将其作为类的字段使用，所以它也并未实现Serializable接口。由于这个原因，如果用了某些要求序列化的库或者框架，在模型中使用Optional，有可能引发应用程序故障。 如果你一定要实现序列化的域模型，作为替代方案，建议像下面这个例子那样，提供一个能访问声明为Optional、变量值可能缺失的接口。 123456public class Person &#123; private Car car; public Optional&lt;Car&gt; getCarAsOptional()&#123; return Optional.ofNullable(car); &#125; &#125; 两个Optional对象的组合12345if (person.isPresent() &amp;&amp; car.isPresent())&#123; return Optional.of(findCheapestInsurance(person.get(), car.get())); &#125; else &#123; return Optional.empty();&#125; 以不解包的方式组合两个Optional对象 1return person.flatMap(p -&gt; car.map(c -&gt; findCheapestInsurance(p, c))); 使用filter剔除特定的值filter方法接受一个谓词作为参数。如果Optional对象的值存在，并且它符合谓词的条件，filter方法就返回其值;否则它就返回一个空的Optional对象。 123if(insurance != null &amp;&amp; "CambridgeInsurance".equals(insurance.getName()))&#123;System.out.println("ok");&#125; 优化 12optInsurance.filter(insurance -&gt; "CambridgeInsurance".equals(insurance.getName())) .ifPresent(x -&gt; System.out.println("ok")); 123456return person.filter(p -&gt; p.getAge() &gt;= minAge) .flatMap(Person::getCar) .flatMap(Car::getInsurance) .map(Insurance::getName) .orElse("Unknown");&#125; 用Optional封装可能为null的值1Object value = map.get("key"); 优化 1Optional&lt;Object&gt; value = Optional.ofNullable(map.get("key")); 1234return Optional.ofNullable(props.getProperty(name)) .flatMap(OptionalUtility::stringToInt) .filter(i -&gt; i &gt; 0) .orElse(0); 异常与Optional的对比12345try &#123; return Optional.of(Integer.parseInt(s));&#125; catch (NumberFormatException e) &#123; return Optional.empty();&#125; 建议将多个类似的方法封装到一个工具类中。 基础类型的Optional对象和避免使用基础类型 OptionalInt OptionalLong OptionalDouble 不推荐使用基础类型的Optional，因为基础类型的Optional不支持map、flatMap以及filter方法，而这些却是Optional类最有用的方法。 Optional类方法 get() 是这些方法中最简单但又最不安全的方法。如果变量存在，它直接返回封装的变量值，否则就抛出一个NoSuchElementException异常。所以，除非非常确定Optional变量一定包含值，否则不使用。此外，这种方式即便相对于嵌套式的null检查，也并未体现出多大的改进。 orElse(T other) 允许在Optional对象不包含值时提供一个默认值。 orElseGet(Supplier&lt;? extends T&gt; other) 是orElse方法的延迟调用版，Supplier方法只有在Optional对象不含值时才执行调用。如果创建默认值是件耗时费力的工作，应该考虑采用这种方式(借此提升程序的性能)，或者需要非常确定某个方法仅在 Optional为空时才进行调用，也可以考虑该方式(这种情况有严格的限制条件)。 orElseThrow(Supplier&lt;? extends X&gt; exceptionSupplier) 和get方法非常类似，它们遭遇Optional对象为空时都会抛出一个异常，但是使用orElseThrow你可以定制希望抛出的异常类型。 ifPresent(Consumer&lt;? super T&gt;) 能在变量值存在时执行一个作为参数传入的方法，否则就不进行任何操作。 of 将指定值用Optional封装之后返回，如果该值为null，则抛出一个NullPointerException异常。 ofNullable 将指定值用Optional封装之后返回，如果该值为null，则返回一个空的Optional对象。 flatMap 如果值存在，就对该值执行提供的mapping函数调用，返回一个 Optional 类型的值，否则就返回一个空的Optional对象 map 如果值存在，就对该值执行提供的mapping函数调用将指定值用Optional封装之后返回，如果该值为null，则返回一个空的 Optional对象。]]></content>
      <categories>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>Java8</tag>
        <tag>Lambda</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JVM调试命令]]></title>
    <url>%2Fposts%2F9582%2F</url>
    <content type="text"><![CDATA[GC日志打开GC日志 1-server -XX:+PrintGCTimeStamps -XX:+PrintGCDetails -Xloggc:./logs/gc.log jmap生成 java 程序的 dump 文件， 也可以查看堆内对象示例的统计信息、查看 ClassLoader 的信息以及 finalizer 队列。 命令1、jmap -histo[:live] 通过histo选项，打印当前java堆中各个对象的数量、大小。 如果添加了live，只会打印活跃的对象。 2、jmap -dump:[live,]format=b,file= 通过-dump选项，把java堆中的对象dump到本地文件，然后使用MAT进行分析。 如果添加了live，只会dump活跃的对象。 jmap -histo 19470 | jmap -histo:live 19470 3、jmap -heap 通过-heap选项，打印java堆的配置情况和使用情况，还有使用的GC算法。 jmap -heap 19470 4、jmap -finalizerinfo 通过-finalizerinfo选项，打印那些正在等待执行finalize方法的对象。 5、jmap -permstat 通过-permstat选项，打印java堆永久代的信息，包括class loader相关的信息,和interned Strings的信息。``` 实现原理通过jmap和jvm之间进行通信，有两种实现方式：attach 和 SA。 attach attach方式，简单来说就是客户端和服务端之间的通信，客户端发送请求，主要逻辑在服务端执行，jmap相当于客户端，JVM相当于服务端。 在JVM中，有一个叫”Attach Listener”的线程，专门负责监听attach的请求，并执行对应的操作。 客户端连接到目标JVM，向其发出一个类似“inspectheap”命令 目标JVM接收到命令，执行JVM内相关函数，将收集到的结果以文本形式返回 客户端接收到返回的文本并将其显示出来；SA 假如执行”jmap -heap 5409″，就不会使用attach方式实现了。 在参数解析中，如果参数是”-heap|-heap:format=b|-permstat|-finalizerinfo”中的一种，或者添加了”-F”，比如”jmap -histo -F 5409″，则使用SA的方式。 SA方式，和attach方式不同的是，相关的主要逻辑都在SA中实现，从JVM中获取数据即可。jps只列出系统中所有的 Java 应用程序。 -q：只输出进程 ID -m：输出传入 main 方法的参数 -l：输出完全的包名，应用主类名，jar的完全路径名 -v：输出jvm参数 -V：输出通过flag文件传递到JVM中的参数 jinfo可以用来查看正在运行的 java 应用程序的扩展参数，包括Java System属性和JVM命令行参数；也可以动态的修改正在运行的 JVM 一些参数。当系统崩溃时，jinfo可以从core文件里面知道崩溃的Java应用程序的配置信息。 jinfo 19470 输出当前 jvm 进程的全部参数和系统属性 参数说明pid 对应jvm的进程id executable core 产生core dump文件 [server-id@]remote server IP or hostname 远程的ip或者hostname，server-id标记服务的唯一性id option no option 输出全部的参数和系统属性 -flag name 输出对应名称的参数 -flag [+|-]name 开启或者关闭对应名称的参数 -flag name=value 设定对应名称的参数 -flags 输出全部的参数 -sysprops 输出系统属性 jstack进程所包含线程情况查询 (位于”jdk_home/bin”目录下)，可以实时监测系统资源占用与jvm运行情况。 jstack 19470 查看当前java进程的堆栈状态 参数说明：-l 长列表. 打印关于锁的附加信息,例如属于java.util.concurrent 的 ownable synchronizers列表. -F 当’jstack [-l] pid’没有相应的时候强制打印栈信息 -m 打印java和native c/c++框架的所有栈信息. -h | -help 打印帮助信息 pid 需要被打印配置信息的java进程id,可以用jps查询. jstatjstat命令可以查看堆内存各部分的使用量，以及加载类的数量。命令的格式如下： jstat [-命令选项] [vmid] [间隔时间/毫秒] [查询次数] // 命令语法结构：Usage: jstat -help|-options jstat - [-t] [-h] [ []]// 参数解释：Options — 选项，我们一般使用 -gcutil 查看gc情况vmid — VM的进程号，即当前运行的java进程号interval– 间隔时间，单位为秒或者毫秒count — 打印次数，如果缺省则打印无数次 S0 — Heap上的 Survivor space 0 区已使用空间的百分比S1 — Heap上的 Survivor space 1 区已使用空间的百分比E — Heap上的 Eden space 区已使用空间的百分比O — Heap上的 Old space 区已使用空间的百分比P — Perm space 区已使用空间的百分比YGC — 从应用程序启动到采样时发生 Young GC 的次数YGCT– 从应用程序启动到采样时 Young GC 所用的时间(单位秒)FGC — 从应用程序启动到采样时发生 Full GC 的次数FGCT– 从应用程序启动到采样时 Full GC 所用的时间(单位秒)GCT — 从应用程序启动到采样时用于垃圾回收的总时间(单位秒)//示例jstat -options -class -compiler -gc -gccapacity -gccause -gcmetacapacity -gcnew -gcnewcapacity -gcold -gcoldcapacity -gcutil -printcompilationjstat -class -t 19470Timestamp Loaded Bytes Unloaded Bytes Time6188.4 3898 7178.4 40 58.3 1.78 jstat -gcutil 19470 1000 5 S0 S1 E O M CCS YGC YGCT FGC FGCT GCT0.00 25.00 98.55 15.37 96.94 94.88 21 0.069 7 0.237 0.3060.00 25.00 99.59 15.37 96.94 94.88 21 0.069 7 0.237 0.3060.00 25.00 99.59 15.37 96.94 94.88 21 0.069 7 0.237 0.3060.00 25.00 100.00 15.37 96.94 94.88 21 0.069 7 0.237 0.306]]></content>
      <categories>
        <category>工具利器</category>
      </categories>
      <tags>
        <tag>Java8</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker安装Nginx及配置]]></title>
    <url>%2Fposts%2F65243%2F</url>
    <content type="text"><![CDATA[Docker安装123456789docker search nginx name docker.io/nginx OFFICIAL okdocker pull nginxdocker images nginxdocker run --name nginx-test -p 9803:80 -d nginx 说明： nginx-test 容器名称。 -d设置容器在在后台一直运行。 -p 端口进行映射，将本地 8081 端口映射到容器内部的 80 端口。测试： curl -l localhost:9803 Docker配置创建目录 1mkdir -p ./nginx/www ./nginx/logs ./nginx/conf www: 目录将映射为 nginx 容器配置的虚拟目录。 logs: 目录将映射为 nginx 容器的日志目录。 conf: 目录里的配置文件将映射为 nginx 容器的配置文件。 配置文件 12345docker psCONTAINER ID 988101b6dbcfdocker cp 988101b6dbcf:/etc/nginx/nginx.conf ./nginx/conf 拷贝容器内 Nginx 默认配置文件到本地当前目录下的 conf 目录，容器 ID 可以查看 docker ps 命令输入中的第一列：重启 123456789docker kill 988101b6dbcfdocker rm 988101b6dbcfdocker run --name nginx-test -p 9803:80 -d -v /home/xxx/nginx/www:/usr/share/nginx/html -v /home/xxx/nginx/conf/nginx.conf:/etc/nginx/nginx.conf -v /home/xxx/nginx/logs:/var/log/nginx nginxc7d0b0a20287e46b759ccd73fe6ec3072695f93900b3d04172f1f34bd0104766curl -l localhost:9803 Nginx配置123cd ./nginx/wwwvi index.html 修改首页 1234567891011 &lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt;&lt;meta charset=&quot;utf-8&quot;&gt;&lt;title&gt;welcome&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;h1&gt;hello&lt;/h1&gt; &lt;p&gt;world。&lt;/p&gt;&lt;/body&gt;&lt;/html&gt; 修改配置文件 12345vi /home/xxx/nginx/conf/nginx.confinclude /home/xxx/nginx/conf/conf.d/*.conf;cd conf.dvi default.conf 配置 12345678910111213141516171819server&#123; listen 80; server_name localhost; index index.html index.htm; root /home/cuipeijun/nginx/www;#站点目录 location /recommend &#123; proxy_pass http://recommend; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; &#125;&#125;upstream recommend &#123; server 172.16.25.70:9819; server 192.168.1.41:9804 backup;&#125; 配置说明upstream可以为每个设备设置状态值，这些状态值的含义分别如下： down：表示单前的server暂时不参与负载. weight：默认为1.weight越大，负载的权重就越大。 max_fails：允许请求失败的次数默认为1.当超过最大次数时，返回proxy_next_upstream 模块定义的错误. fail_timeout : max_fails次失败后，暂停的时间。 backup： 其它所有的非backup机器down或者忙的时候，请求backup机器。所以这台机器压力会最轻分配策略none（轮询） upstream按照轮询（默认）方式进行负载，每个请求按时间顺序逐一分配到不同的后端服务器，如果后端服务器down掉，能自动剔除。虽然这种方式简便、成本低廉。但缺点是：可靠性低和负载分配不均衡。weight（权重） 指定轮询几率，weight和访问比率成正比，用于后端服务器性能不均的情况。例如 server 192.168.61.22 weight = 6; # 60% 请求 server 192.168.61.23 weight = 4; # 40% 请求ip_hash（访问ip） 每个请求按访问ip的hash结果分配，这样每个访客固定访问一个后端服务器，可以解决session的问题。 配置只需要在upstream中加入ip_hash;即可。 12345upstream tomcats &#123; ip_hash; server 127.0.0.1:9001; server 127.0.0.1:9002;&#125;fair（第三方） 按后端服务器的响应时间来分配请求，响应时间短的优先分配。与weight分配策略类似。 12345upstream tomcats &#123; server 127.0.0.1:9001; server 127.0.0.1:9002; fair;&#125;url_hash（第三方） 和IP哈希类似，只不过针对请求的url进行hash（基于缓存的server，页面静态化）。模板123456789101112131415161718192021222324252627upstream tomcats &#123; server ip:8080; &#125;server &#123; listen 80; server_name www.xxx.com; location / &#123; proxy_pass http://tomcats; #Proxy Settings proxy_redirect off; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_next_upstream error timeout invalid_header http_500 http_502 http_503 http_504; proxy_max_temp_file_size 0; proxy_connect_timeout 90; proxy_send_timeout 90; proxy_read_timeout 90; proxy_buffer_size 4k; proxy_buffers 4 32k; proxy_busy_buffers_size 64k; proxy_temp_file_write_size 64k; &#125;&#125;]]></content>
      <categories>
        <category>架构</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[解决MySql死锁脚本]]></title>
    <url>%2Fposts%2F10641%2F</url>
    <content type="text"><![CDATA[12345678910111213#!/usr/bin/env bashtmp_file=/tmp/my_process_listHOST='xx-01'USER='xxx'PASS='xxxxxx'mysql -u $&#123;USER&#125; -p $&#123;PASS&#125; -P3306 --protocol=tcp -h $&#123;HOST&#125; mysql -e "show processlist" &gt; $&#123;tmp_file&#125;for l in `grep 'table level lock' $&#123;tmp_file&#125; | grep -v 'system user' | awk '&#123;print $1&#125;'`; do mysql -u $&#123;USER&#125; -p $&#123;PASS&#125; -P3306 --protocol=tcp -h $&#123;HOST&#125; mysql -e "kill $l;"done]]></content>
      <categories>
        <category>架构</category>
      </categories>
      <tags>
        <tag>死锁</tag>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hazelcast Client配置]]></title>
    <url>%2Fposts%2F354%2F</url>
    <content type="text"><![CDATA[最大value 单个k-v的操作本身不受数据字节大小限制 操作受最大堆内存-Xmx限制 操作受超时时间限制hazelcast.max.operation.timeout 12INFO HazelcastTest - size:273437KBINFO HazelcastTest - elapsed:62ms 数量、过期等限制 针对每个map均可限制1234567891011121314151617//限制instruments特定mapMapConfig mCfg = new MapConfig("instruments");//超时时间mCfg.setTimeToLiveSeconds(60);//节点备份数mCfg.setBackupCount(1);//删除策略mCfg.setEvictionPolicy(EvictionPolicy.LRU);//存储模式mCfg.setInMemoryFormat(InMemoryFormat.BINARY);MaxSizeConfig maxSizeConfig = new MaxSizeConfig();//最大数量maxSizeConfig.setSize(1000);//针对节点限制maxSizeConfig.setMaxSizePolicy(MaxSizeConfig.MaxSizePolicy.PER_NODE);mCfg.setMaxSizeConfig(maxSizeConfig); 集群性能 -Xms128M -Xmx256M 2个节点 k:递增,value：1k client并发50 双节点puts平均为290/s，延迟为0.5ms自动扩充 基于广播 基于TCP-IP 基于Eureka 基于Zk]]></content>
      <categories>
        <category>架构</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>Hazelcast</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hazelcast性能评估]]></title>
    <url>%2Fposts%2F19102%2F</url>
    <content type="text"><![CDATA[基准测试基于benchmarking tool 123INFO Performance IntByteMapTestTotal throughput 100.00% 7,948,805 ops 128,179.66 ops/s Agent C_A1 100.00% 7,948,805 ops 128,179.66 ops/s 结论 int-int每秒可完成17W请求，并发线程10，随机读写，写概率0.1，读0.9 int-byte每秒13万请求，value最大2k，并发线程10，随机读写，写概率0.1，读0.9 客户端测试 serive为40服务器docker client为本地java 单线程写入对象1万次 多线程10，并发 结论 单线程时，puts:56/s，server并发处理 多线程10个时，puts:496/s，server并发处理 处理延迟,0.02ms 优势 基于Java开发，部署简单、无主从、自动扩展 基础java集合框架，可本地使用，解决分布式缓存问题 提供全局id、消息、队列、分布式锁等分布式服务常见工具 有manager-ui spring boot/cloud默认已集成 劣势 中文材料较少 基准测试方法下载simulator 下载安装包至服务器或本地 安装包：https://download.hazelcast.com/simulator/hazelcast-simulator-0.9.10-dist.tar.gz 源码：https://github.com/hazelcast/hazelcast-simulator.git 安装与测试 ./hazelcast-simulator-0.9.8/bin/simulator-wizard –install 测试是否成功。新建一个teminor，输入命令:simulator-wizard –help 执行123simulator-wizard --createWorkDir testscd tests./run 等待console输出结果 修改测试条件cat test.properties 123IntByteMapTest@class = com.hazelcast.simulator.tests.map.IntByteMapTestIntByteMapTest@threadCount = 10IntByteMapTest@putProb = 0.1 测试类下载源码可见，默认com.hazelcast.simulator.tests.map.IntIntMapTest 注意 测试模拟器自带Hazelcast，无需安装配置 本地不要启动Hazelcast，否则端口冲突，无法成功否则有以下错误:12FATAL [C_A1] Failed to start Worker: Failed to start WorkerFATAL [C_A1] Failed to start Worker: Failed to start Worker]]></content>
      <categories>
        <category>架构</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>Hazelcast</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker部署Hazelcast]]></title>
    <url>%2Fposts%2F39886%2F</url>
    <content type="text"><![CDATA[Hazelcast management-center123docker pull hazelcast/management-centerdocker run -d -p 8200:8080 hazelcast/management-center:latest 安装配置管理节点，监控和实时查看缓存情况 Hazelcast镜像单节点部署下载镜像 1docker pull hazelcast/hazelcast 启动 1docker run -d -e JAVA_OPTS="-Dhazelcast.local.publicAddress=192.168.1.40:5701 -Dhazelcast.rest.enabled=true -Xms128M -Xmx256M" -p 5701:5701 hazelcast/hazelcast 注意： hazelcast.rest.enabled=true，需要开启，不然管理节点连不上 docker需要后台启动服务-d，内部端口为5701 最好指定publicAddress且需要设置JVM大小 节点输出 123Members &#123;size:1, ver:1&#125; [ Member [192.168.1.40]:5701 - dbbe08e2-ed8c-4228-9cf8-a0ab0ae08632 this] Hazelcast镜像多节点multicast集群部署节点1： 1docker run -d -e JAVA_OPTS="-Dhazelcast.local.publicAddress=192.168.1.43:5701 -Dhazelcast.rest.enabled=true -Xms128M -Xmx256M" -e MANCENTER_URL="http://192.168.1.40:8200/hazelcast-mancenter" -p 5701:5701 hazelcast/hazelcast 节点2： 1docker run -d -e JAVA_OPTS="-Dhazelcast.local.publicAddress=192.168.1.43:5702 -Dhazelcast.rest.enabled=true -Xms128M -Xmx256M" -e MANCENTER_URL="http://192.168.1.40:8200/hazelcast-mancenter" -p 5702:5701 hazelcast/hazelcast 注意： 指定MANCENTER_URL管理节点地址 multicast广播必须为同一台集群，因为docker下广播必须本机容器才能连接 Hazelcast镜像多节点TCP-IP集群部署hazelcast.xml配置： 123456789101112131415 &lt;management-center enabled="true"&gt;http://192.168.1.40:8200/hazelcast-mancenter&lt;/management-center&gt;...&lt;port auto-increment="true" port-count="10"&gt;5701&lt;/port&gt;... &lt;multicast enabled="false"&gt; &lt;multicast-group&gt;224.2.2.3&lt;/multicast-group&gt; &lt;multicast-port&gt;54327&lt;/multicast-port&gt; &lt;/multicast&gt; &lt;tcp-ip enabled="true"&gt; &lt;interface&gt;192.168.1.40-45&lt;/interface&gt; &lt;member-list&gt; &lt;member&gt;192.168.1.40&lt;/member&gt; &lt;member&gt;192.168.1.43&lt;/member&gt; &lt;/member-list&gt; &lt;/tcp-ip&gt; 节点1 1docker run -d -e JAVA_OPTS="-Dhazelcast.config=/opt/hazelcast/config_ext/hazelcast.xml -Dhazelcast.local.publicAddress=192.168.1.40:5701 -Dhazelcast.rest.enabled=true -Xms128M -Xmx512M" -v /home/xxx:/opt/hazelcast/config_ext -p 5701:5701 hazelcast/hazelcast 节点2 1docker run -d -e JAVA_OPTS="-Dhazelcast.config=/opt/hazelcast/config_ext/hazelcast.xml -Dhazelcast.local.publicAddress=192.168.1.43:5701 -Dhazelcast.rest.enabled=true -Xms128M -Xmx512M" -v /home/xxx:/opt/hazelcast/config_ext -p 5701:5701 hazelcast/hazelcast 输出 1234Members &#123;size:2, ver:2&#125; [ Member [192.168.1.40]:5701 - cd40d155-d993-46a5-b07c-19f001c71f3c Member [192.168.1.43]:5701 - 34d0798c-37d0-42e8-88f0-1268eab9a90a this] 注意： 端口自增限制为10，即每个机器端口限制为5701-5711，以提高发现效率 multicast关闭，tcp-ip开启 限制interface，指定ip范围 指定member-list，指定集群成员 指定宿主机配置文件地址 配置登录management-center 打开地址：http://192.168.1.40:8200/hazelcast-mancenter 第一次设置初始化账户和密码，密码有格式要求 添加成员节点，即Change URL 输入Cluster Name and Password，即集群名和集群密码 输入Server UR，为Management Center URL，即管理系统地址；例如http://192.168.1.40:8200/hazelcast-mancenter 测试连接引入包pom.xml12345678910&lt;dependency&gt; &lt;groupId&gt;com.hazelcast&lt;/groupId&gt; &lt;artifactId&gt;hazelcast&lt;/artifactId&gt; &lt;version&gt;3.8.5&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.hazelcast&lt;/groupId&gt; &lt;artifactId&gt;hazelcast-client&lt;/artifactId&gt; &lt;version&gt;3.8.5&lt;/version&gt;&lt;/dependency&gt; client代码1234567891011121314151617181920212223242526272829303132333435363738@Slf4jpublic class HazelcastTest &#123; public static void main(String[] args) &#123; ClientConfig clientConfig = new ClientConfig(); //集群组名称 clientConfig.getGroupConfig().setName("dev"); //节点地址 clientConfig.getNetworkConfig().addAddress("192.168.1.40", "192.168.1.40:5702"); //客户端 HazelcastInstance client = HazelcastClient.newHazelcastClient(clientConfig); UserInfo userInfo = new UserInfo(); userInfo.setUserName("xxxx"); userInfo.setUserDesc("com.hazelcast.core.Hazelcast"); //map缓存 Map&lt;Integer, UserInfo&gt; userInfoMap = client.getMap("instruments"); //并发测试 Runnable runnable = () -&gt; &#123; long total = 10000; Stopwatch stopwatch = Stopwatch.createStarted(); for (int i = 0; i &lt; total; i++) &#123; //插入缓存 userInfoMap.put(i, userInfo); &#125; stopwatch.stop(); log.info("total:&#123;&#125;,elapsed:&#123;&#125;,qps:&#123;&#125;", total, stopwatch.elapsed(TimeUnit.MILLISECONDS), stopwatch.elapsed(TimeUnit.MILLISECONDS) / total); &#125;; ExecutorService executorService = Executors.newFixedThreadPool(10); int threadNum = 10; for (int i = 0; i &lt; threadNum; i++) &#123; executorService.submit(runnable); &#125; &#125;&#125;]]></content>
      <categories>
        <category>架构</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>Hazelcast</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java并发编程艺术 - 多线程状态]]></title>
    <url>%2Fposts%2F80%2F</url>
    <content type="text"><![CDATA[6种状态线程可以有如下6种状态: New (新创建) Runnable (可运行) Blocked (被阻塞) Waiting (等待) Timed waiting (计时等待) Terminated (被终止) 要确定一个线程的当前状态， 可调用 getState 方法。 新创建线程当用new操作符创建一个新线程时，如newThread(r)，该线程还没有开始运行。这意味着它的状态是new。 当一个线程处于新创建状态时，程序还没有开始运行线程中的代码。在线程运行之前还有一些基础工作要做。 可运行线程一旦调用start方法， 线程处于runnable状态。一个可运行的线桿可能正在运行也可能没有运行， 这取决于操作系统给线程提供运行的时间。 一旦一个线程开始运行，它不必始终保持运行。事实上，运行中的线程被中断，目的是为了让其他线程获得运行机会。线程调度的细节依赖于操作系统提供的服务。 抢占式调度系统给每一个可运行线程一个时间片来执行任务。当时间片用完，操作系统剥夺该线程的运行权，并给另一个线程运行机会。当选择下一个线程时，操作系统考虑线程的优先级。 现在所有的桌面以及服务器操作系统都使用抢占式调度。但是，像手机这样的小型设备可能使用协作式调度。在这样的设备中，一个线程只有在调用yield方法、或者被阻塞或等待时，线程才失去控制权。在具有多个处理器的机器上，每一个处理器运行一个线程， 可以有多个线程并行运行。 当然， 如果线程的数目多于处理器的数目， 调度器依然采用时间片机制。记住， 在任何给定时刻， 二个可运行的线程可能正在运行也可能没有运行(这就是为什 么将这个状态称为可运行而不是运行 。) 被阻塞线程和等待线程当线程处于被阻塞或等待状态时，它暂时不活动。它不运行任何代码且消耗最少的资源。直到线程调度器重新激活它。细节取决于它是怎样达到非活动状态的。 当一个线程试图获取一个内部的对象锁而该锁被其他线程持有，则该线程进人阻塞状态。当所有其他线程释放该锁，并且线程调度器允许本线程持有它的时候，该线程将变成非阻塞状态。 当线程等待另一个线程通知调度器一个条件时，它自己进入等待状态。在调用Object.wait方法或Thread.join方法，或者是等待Lock或Condition时，就会出现这种情况。实际上，被阻塞状态与等待状态是有很大不同的。 有几个方法有一个超时参数。 调用它们导致线程进人计时等待(timed waiting)状态。这一状态将一直保持到超时期满或者接收到适当的通知。带有超时参数的方法有 Thread.sleep 和Object.wait、Thread.join、Lock,tryLock 以及Condition.await 的计时版。 线程可以具有的状态以及从一个状态到另一个状态可能的转换。当一个线程被阻塞或等待时(或终止时，) 另一个线程被调度为运行状态。当一个线程被重新激活(例如，因为超时期满或成功地获得了一个锁)，调度器检查它是否具有比当前运行线程更高的优先级。如果是这样，调度器从当前运行线程中挑选一个，剥夺其运行权，选择一个新的线程运行。 被终止的线程线程因如下两个原因之一而被终止: 因为run方法正常退出而自然死亡。 因为一个没有捕获的异常终止了run方法而意外死亡。]]></content>
      <categories>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>Java并发编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java并发编程艺术 - Join、Yield和Sleep]]></title>
    <url>%2Fposts%2F36650%2F</url>
    <content type="text"><![CDATA[Joinjoin() 的作用：让“主线程”等待“子线程”结束之后才能继续运行。 son.join()被调用的地方是发生在“Father主线程”中，但是son.join()是通过“子线程son”去调用的join()，父线程调用wait()的作用是让“当前线程”等待，而这里的“当前线程”是指当前在CPU上运行的线程。所以，虽然是调用子线程的wait()方法，但是它是通过“主线程”去调用的；所以，休眠的是主线程，而不是“子线程”！ 线程join方法1234public final void join() throws InterruptedException &#123; //调用父线程 join(0);&#125; 被调用的父线程12345678910111213141516171819202122232425262728public final synchronized void join(long millis)throws InterruptedException &#123; long base = System.currentTimeMillis(); long now = 0; if (millis &lt; 0) &#123; throw new IllegalArgumentException("timeout value is negative"); &#125; if (millis == 0) &#123; //父线程若激活，则一直等待被唤醒 while (isAlive()) &#123; wait(0); &#125; &#125; else &#123; //条件循环确认，即使被唤醒 while (isAlive()) &#123; long delay = millis - now; //等待超时退出 if (delay &lt;= 0) &#123; break; &#125; //等待唤醒 wait(delay); now = System.currentTimeMillis() - base; &#125; &#125;&#125; Demo12345678910111213141516public static void main(String[] args) throws InterruptedException &#123; AtomicInteger atomicInteger = new AtomicInteger(0); Runnable runnable = () -&gt; &#123; do &#123; log.info(atomicInteger.get() + "- run"); &#125; while (atomicInteger.incrementAndGet() &lt; 10); log.info(atomicInteger.get() + "- join"); &#125;; Thread thread = new Thread(runnable); thread.start(); //阻塞，等待子线程执行 thread.join(); log.info(atomicInteger.get() + "- end");&#125; 执行结果 1234567891011120- run1- run2- run3- run4- run5- run6- run7- run8- run9- run10- join10- end Yield1234static void yield( )导致当前执行线程处于让步状态。如果有其他的可运行线程具有至少与此线程同样高的优先级，那么这些线程接下来会被调度。注意，这是一个静态方法。`当前线程暂停，给予其他相同优先级或者更高优先级线程执行机会，但不会释放锁`。 Sleepsleep()方法需要指定等待的时间，它可以让当前正在执行的线程在指定的时间内暂停执行，进入阻塞状态，该方法既可以让其他同优先级或者高优先级的线程得到执行的机会，也可以让低优先级的线程得到执行机会。 但是sleep()方法不会释放“锁标志”，也就是说如果有synchronized同步块，其他线程仍然不能访问共享数据。 区别 sleep 和yield都不会释放对象的锁，都会导致当前线程等待。 sleep具有更大的灵活性，可以指定等待时间，可以唤醒其他更低优先级的线程，会抛出异常；yield只能唤醒同等优先级或者更高优先级的线程，不会给更低优先级线程执行机会，不会抛出异常。 yield,sleep都不会释放对象的锁， wait会释放对象的锁。如果不释放对象的锁，其他线程就没办法执行同步的代码。]]></content>
      <categories>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>Java并发编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java并发编程艺术 - 管道输入和输出流]]></title>
    <url>%2Fposts%2F18201%2F</url>
    <content type="text"><![CDATA[Java管道管道连接输入流和输出流。 管道I/O基于生产者 - 消费者模式，其中生产者产生数据，而消费者消费数据。在管道I/O中，创建两个流代表管道的两端。 PipedOutputStream对象表示流的一端，PipedInputStream对象则表示流的另一端。使用两个对象的connect()方法连接两端。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384@Slf4jpublic class PipedStreamTest &#123; public static void main(String[] args) throws InterruptedException &#123; PipedStreamReceive pipedStreamReceive1 = new PipedStreamReceive("receive1"); //指定输入管道 PipedStreamSend pipedStreamSend1 = new PipedStreamSend("send1", pipedStreamReceive1.pipedInputStream); Thread thread1 = new Thread(pipedStreamSend1.runnable); Thread thread2 = new Thread(pipedStreamReceive1.runnable); thread1.start(); //等先发一下 Thread.sleep(5000); thread2.start(); &#125; @Data public static class PipedStreamSend &#123; //初始化 private PipedOutputStream pipedOutputStream = new PipedOutputStream(); private PipedInputStream pipedInputStream; //消息内容 private AtomicInteger num = new AtomicInteger(0); //输入流管道标识 private String name; public PipedStreamSend(String name, PipedInputStream pipedInputStream) &#123; this.name = name; this.pipedInputStream = pipedInputStream; &#125; private Runnable runnable = () -&gt; &#123; try &#123; //连接输入管道 pipedOutputStream.connect(pipedInputStream); while (true) &#123; //写入流 pipedOutputStream.write(num.incrementAndGet()); //刷新缓冲 pipedOutputStream.flush(); log.info("name:&#123;&#125;,num:&#123;&#125;", this.name, this.num.get()); try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125;; &#125; @Data public static class PipedStreamReceive &#123; //初始化 private PipedInputStream pipedInputStream = new PipedInputStream(); //输入流管道标识 private String name; public PipedStreamReceive(String name) &#123; this.name = name; &#125; private Runnable runnable = () -&gt; &#123; try &#123; int num; //读取流 while ((num = pipedInputStream.read()) != -1) &#123; log.info("name:&#123;&#125;,num:&#123;&#125;", name, num); &#125; &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125;; &#125;&#125; 执行结果 123456789101112name:send1,num:1name:send1,num:2name:send1,num:3name:send1,num:4name:send1,num:5name:receive1,num:1name:receive1,num:2name:receive1,num:3name:receive1,num:4name:receive1,num:5name:receive1,num:6name:send1,num:6 优缺点优点: 创建管道输出流PipedOutputStream pos和管道输入流PipedInputStream pis 将pos和pis匹配，pos.connect(pis); 将pos赋给信息输入线程，pis赋给信息获取线程，就可以实现线程间的通讯了 缺点: 管道流只能在两个线程之间传递数据 管道流只能实现单向发送，如果要两个线程之间互通讯，则需要两个管道流 总结作为线程通讯方式之一，可以看到管道流使用起来很方便，但是制约也很大，具体使用要看实际的需求，如果项目中只有两个线程持续传递消息，那用管道流也很方便，如果项目中有很多个线程之间需要通讯，那还是用共享变量的方式来传递消息比较方便。]]></content>
      <categories>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>Java并发编程</tag>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java并发编程艺术 - 多线程wait和notify]]></title>
    <url>%2Fposts%2F48047%2F</url>
    <content type="text"><![CDATA[等待/通知机制等待/通知机制，是指一个线程A调用了对象O的wait()方法进入等待状态，而另一个线程B调用了对象O的notify()或者notifyAll()方法，线程A收到通知后从对象O的wait()方法返回，进而执行后续操作。 上述两个线程通过对象O来完成交互，而对象上的wait()和notify/notifyAll()的关系就如同开关信号一样，用来完成等待方和通知方之间的交互工作。 利用wait和notify进行交替执行12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758public class ThreadWaitAndNotify &#123; public static void main(String[] args) throws InterruptedException &#123; //对象锁标记 Object lock = new Object(); Runner runner1 = new Runner(lock, "runner1"); Runner runner2 = new Runner(lock, "runner2"); Thread thread1 = new Thread(runner1.runnable); Thread thread2 = new Thread(runner2.runnable); thread1.start(); Thread.sleep(100); thread2.start(); &#125; @Slf4j public static class Runner &#123; //全局自增 private static AtomicInteger num = new AtomicInteger(0); private Object lock; private String name; public Runner(Object lock, String name) &#123; this.lock = lock; this.name = name; &#125; //运行 Runnable runnable = () -&gt; &#123; //先获取锁，才能有锁状态变更 synchronized (lock) &#123; while (true) &#123; //首次：第一个线程为奇数，打印后等待；第二个线程为偶数，打印后通知第一个线程 num.incrementAndGet(); //等待唤醒 try &#123; if (num.get() % 2 == 1) &#123; log.info("name:&#123;&#125;,num:&#123;&#125;", this.name, num.get()); //奇数等待偶数放行通知 lock.wait(); lock.notify(); &#125; else if (num.get() % 2 == 0) &#123; log.info("name:&#123;&#125;,num:&#123;&#125;", this.name, num.get()); //偶数放行，等待奇数执行 lock.notify(); lock.wait(); &#125; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125;; &#125;&#125; 交替执行结果 12345678910$Runner - name:runner1,num:1$Runner - name:runner2,num:2$Runner - name:runner1,num:3$Runner - name:runner2,num:4$Runner - name:runner1,num:5$Runner - name:runner2,num:6$Runner - name:runner1,num:7$Runner - name:runner2,num:8$Runner - name:runner1,num:9$Runner - name:runner2,num:10 锁池和等待池每个同步对象都有自己的锁池和等待池。 锁池假设线程A已经拥有了某个对象(注意:不是类)的锁，而其它的线程想要调用这个对象的某个synchronized方法(或者synchronized块)，由于这些线程在进入对象的synchronized方法之前必须先获得该对象的锁的拥有权，但是该对象的锁目前正被线程A拥有，所以这些线程就进入了该对象的锁池中。 等待池假设一个线程A调用了某个对象的wait()方法，线程A就会释放该对象的锁(因为wait()方法必须出现在synchronized中，这样自然在执行wait()方法之前线程A就已经拥有了该对象的锁)，同时线程A就进入到了该对象的等待池中。如果另外的一个线程调用了相同对象的notifyAll()方法，那么处于该对象的等待池中的线程就会全部进入该对象的锁池中，准备争夺锁的拥有权。如果另外的一个线程调用了相同对象的notify()方法，那么仅仅有一个处于该对象的等待池中的线程(随机)会进入该对象的锁池. notify和notifyAll适用场景如上例，使用notify且2个runnner，可认为是一个生产者一个消费者的情况下，生产和消费有条不紊的运行，没有任何问题。 线程调用了wait()方法，便会释放锁，并进入等待池中，不会参与锁的竞争 调用notify()后，等待池中的某个线程(只会有一个)会进入该对象的锁池中参与锁的竞争，若竞争成功，获得锁，竞争失败，继续留在锁池中等待下一次锁的竞争。 调用notifyAll()后，等待池中的所有线程都会进入该对象的锁池中参与锁的竞争。 notify适用于所有等待的线程都是对等的（或者说唤醒顺序对其执行任务无影响），或者适用于本来就只有一个等待线程的场景。 只唤醒其它等待的消费者线程中的一个，如果改成notfiyAll的话就让其它线程被唤醒后立刻进入BLOCKED状态，增加了CPU的开销。 notfiyAll适用于等待的线程有不同的目标，可以并行执行的场景。这样才不至于使所有线程被唤醒后又进入到BLOCKED状态。]]></content>
      <categories>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>Java并发编程</tag>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java并发编程艺术 - 线程终结]]></title>
    <url>%2Fposts%2F52791%2F</url>
    <content type="text"><![CDATA[中断状态是线程的一个标识位，而中断操作是一种简便的线程间交互方式，而这种交互方式最适合用来取消或停止任务。 除了中断以外，还可以利用一个boolean变量来控制是否需要停止任务并终止该线程。 2种终结方式1234567891011121314151617181920212223242526272829303132333435363738394041424344454647public class ThreadShutdown &#123; public static void main(String[] args) throws InterruptedException &#123; Runner runner1 = new Runner("Runner1"); Thread thread1 = new Thread(runner1.runnable); thread1.start(); //中断方式1 Thread.sleep(1); thread1.interrupt(); Runner runner2 = new Runner("Runner2"); Thread thread2 = new Thread(runner2.runnable); thread2.start(); Thread.sleep(1); //中断方式2 runner2.shutdown(); &#125; @Slf4j public static class Runner &#123; //关闭标记 private AtomicBoolean shutdown = new AtomicBoolean(); //自增 private AtomicInteger num = new AtomicInteger(0); private String name = "Runner"; //运行 Runnable runnable = () -&gt; &#123; //手动关闭 while (!shutdown.get() &amp;&amp; !Thread.currentThread().isInterrupted()) &#123; num.incrementAndGet(); &#125; log.info("name:&#123;&#125;,end:&#123;&#125;", name, num.get()); &#125;; public Runner(String name) &#123; this.name = name; &#125; //关闭 public void shutdown() &#123; shutdown.set(true); &#125; &#125;&#125; 执行结果12[Thread-0] INFO ThreadShutdown$Runner - name:Runner1,end:4361[Thread-1] INFO ThreadShutdown$Runner - name:Runner2,end:64698 main线程通过中断操作和shutdown()方法均可使Runner得以终止。 这种通过标识位或者中断操作的方式能够使线程在终止时有机会去清理资源，而不是武断地将线程停止，因此这种终止线程的做法显得更加安全和优雅。]]></content>
      <categories>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>Java并发编程</tag>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java并发编程艺术 - 线程中断]]></title>
    <url>%2Fposts%2F45493%2F</url>
    <content type="text"><![CDATA[中断可以理解为线程的一个标识位属性，它表示一个运行中的线程是否被其他线程进行了中断操作。中断好比其他线程对该线程打了个招呼，其他线程通过调用该线程的interrupt()方法对其进行中断操作。 12345678910111213141516171819202122232425262728293031public static void main(String[] args) &#123; AtomicInteger atomicInteger = new AtomicInteger(0); Runnable runnable = () -&gt; &#123; while (true) &#123; atomicInteger.incrementAndGet(); try &#123; //阻塞cpu Thread.sleep(1000); if (atomicInteger.get() &gt; 5) &#123; //中断信号 Thread.currentThread().interrupt(); &#125; &#125; catch (InterruptedException e) &#123; e.printStackTrace(); //异常后的中断标记 System.out.println(Thread.currentThread().isInterrupted() + "-" + atomicInteger.get()); &#125; //输出中断标记 System.out.println(Thread.currentThread().isInterrupted() + "-" + atomicInteger.get()); &#125; &#125;; Thread thread = new Thread(runnable); //就绪，并行；不能直接使用run，run是串行 thread.start(); &#125; 输出 1234567891011false-1false-2false-3false-4false-5true-6java.lang.InterruptedException: sleep interrupted at java.lang.Thread.sleep(Native Method) at ThreadInterrupt.lambda$main$0(ThreadInterrupt.java:19) at java.lang.Thread.run(Thread.java:748)false-7 线程通过检查自身是否被中断来进行响应，线程通过方法isInterrupted()来进行判断是否被中断，也可以调用静态方法Thread.interrupted()对当前线程的中断标识位进行复位true-6。如果该线程已经处于终结状态，即使该线程被中断过，在调用该线程对象的isInterrupted()时依旧会返回false。 从上面false-7可以看到，抛出InterruptedException的方法，Java虚拟机会先将该线程的中断标识位清除，然后抛出InterruptedException，此时调用isInterrupted()方法将会返回false。 interrupt有两个非常类似的方法，interrupted 和 islnterrupted。Interrupted 方法是一个静态方法， 它检测当前的线程是否被中断。 而且， 调用 interrupted 方法会清除该线程的中断状态。另一方面，islnterrupted 方法是一个实例方法，可用来检验是否有线程被中断。调用这个方法不会改变中断状态。 123456789void interrupt()实例方法，针对线程对象。向线程发送中断请求。线程的中断状态将被设置为 true。如果目前该线程被一个sleep调用阻塞，那么，InterruptedException 异常被抛出。•static boolean interrupted()静态方法，针对当前线程。测试当前线程（即正在执行这一命令的线程）是否被中断。注意，这是一个静态方法。这一调用会产生副作用—它将当前线程的中断状态重置为 false。• boolean islnterrupted()实例方法，针对线程对象。测试线程是否被终止。不像静态的中断方法，这一调用不改变线程的中断状态。•static Thread currentThread()返回代表当前执行线程的 Thread 对象。 扩展当对一个线程调用interrupt方法时，线程的中断状态将被置位。这是每一个线程都具有的 boolean标志。每个线程都应该不时地检査这个标志，以判断线程是否被中断。 要想弄清中断状态是否被置位，首先调用静态的 Thread.currentThread 方法获得当前线程，然后调用 islnterrupted 方法： 1234while (!Thread.currentThread().islnterrupted() &amp;&amp; more work to do)&#123;do more work&#125; 但是，如果线程被阻塞，就无法检测中断状态。这是产生 InterruptedExceptioii 异常的地方。当在一个被阻塞的线程（调用 sleep 或 wait) 上调用 interrupt 方法时，阻塞调用将会被Interrupted Exception 异常中断。 中断一个线程不过是引起它的注意。被中断的线程可以决定如何响应中断。某些线程是如此重要以至于应该处理完异常后， 继续执行，而不理会中断。这种线程的 run 方法具有如下形式： 12345678910111213Runnable r = () -&gt; &#123; try&#123; while (!Thread.currentThread().islnterrupted0 &amp;&amp; more work to do)&#123; do more work Thread,sleep(delay); &#125; &#125;catch(InterruptedException e)&#123;// thread was interr叩ted during sleep or wait &#125;finally&#123; cleanup, ifrequired &#125;// exiting the run method terminates the thread&#125;； 如果在每次工作迭代之后都调用 sleep 方法（或者其他的可中断方法)islnterrupted 检测既没有必要也没有用处。如果在中断状态被置位时调用 sleep 方法，它不会休眠。相反，它将清除这一状态并拋出 IntemiptedException。因此,如果你的循环调用 sleep，不会检测中断状态。]]></content>
      <categories>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>Java并发编程</tag>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java并发编程艺术 - 多线程构造和启动]]></title>
    <url>%2Fposts%2F58008%2F</url>
    <content type="text"><![CDATA[构造线程在运行线程之前首先要构造一个线程对象，线程对象在构造的时候需要提供线程所需要的属性，如线程所属的线程组、线程优先级、是否是Daemon线程等信息。 线程启动线程对象在初始化完成之后，调用start()方法就可以启动这个线程。 线程start()方法的含当前线程（即parent线程）同步告知Java虚拟机，只要线程规划器空闲，应立即启动调用()方法的线程。 注意 启动一个线程前，最好为这个线程设置线程名称，因为这样在使用jstack分析或者进行问题排查时，就会给开发人员提供一些提示，自定义的线程最好能够起个名字。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152public class ThreadTest &#123; Runnable target; char[] name; boolean daemon; int priority; public Thread init(Runnable target, String name) &#123; if (name == null) &#123; throw new NullPointerException("name cannot be null"); &#125; // 当前线程就是该线程的父线程 Thread parent = currentThread(); // 将daemon、priority属性设置为父线程的对应属性 this.daemon = parent.isDaemon(); this.priority = parent.getPriority(); this.name = name.toCharArray(); this.target = target; //构造线程组，便于统一管控 ThreadGroup g = new ThreadGroup(name + "Group"); g.setDaemon(daemon); g.setMaxPriority(priority); //构造线程 Thread thread = new Thread(g, target, name); return thread; &#125; public void run(Thread thread) &#123; //处于就绪（可运行）状态，并没有运行，一旦得到cpu时间片，就开始执行相应线程的run()方法 thread.start(); //run()就和普通的成员方法一样，可以被重复调用 //thread.run(); &#125; public static void main(String[] args) &#123; //执行方法 Runnable runnable = () -&gt; &#123; System.out.println("Test"); &#125;; ThreadTest threadTest = new ThreadTest(); while (true) &#123; threadTest.run(threadTest.init(runnable, "Test")); &#125; &#125;&#125; 实现并启动线程有两种方法 写一个类继承自Thread类，重写run方法。用start方法启动线程 写一个类实现Runnable接口，实现run方法。用new Thread(Runnable target).start()方法来启动 start()和run() start启动线程，无需等待run方法体代码执行完毕，可以直接继续执行下面的代码；start()方法来启动一个线程， 这时此线程是处于就绪状态， 并没有运行。 然后通过此Thread类调用方法run()来完成其运行操作的， 这里方法run()称为线程体，它包含了要执行的这个线程的内容， Run方法运行结束， 此线程终止。然后CPU再调度其它线程。 run方法当作普通方法的方式调用。程序还是要顺序执行，要等待run方法体执行完毕后，才可继续执行下面的代码。]]></content>
      <categories>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>Java并发编程</tag>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Maven自定义打包脚本]]></title>
    <url>%2Fposts%2F26061%2F</url>
    <content type="text"><![CDATA[利用Maven脚本，实现以下需求: 将第三方lib单独打包 将脚本单独打包 将执行jar单独打包 将配置文件单独打包 自动关闭和启动进程 assembly目录123456789101112131415161718192021222324252627282930313233343536373839404142434445464748&lt;assembly&gt; &lt;id&gt;bin&lt;/id&gt; &lt;formats&gt; &lt;format&gt;zip&lt;/format&gt; &lt;/formats&gt; &lt;dependencySets&gt; &lt;dependencySet&gt; &lt;!--不使用项目的artifact，第三方jar不要解压，打包进zip文件的lib目录--&gt; &lt;useProjectArtifact&gt;false&lt;/useProjectArtifact&gt; &lt;outputDirectory&gt;lib&lt;/outputDirectory&gt; &lt;unpack&gt;false&lt;/unpack&gt; &lt;/dependencySet&gt; &lt;/dependencySets&gt; &lt;fileSets&gt; &lt;!-- 把项目脚本文件，打包进zip文件的根目录 --&gt; &lt;fileSet&gt; &lt;directory&gt;$&#123;project.basedir&#125;/bin&lt;/directory&gt; &lt;outputDirectory&gt;&lt;/outputDirectory&gt; &lt;includes&gt; &lt;include&gt;*.sh&lt;/include&gt; &lt;/includes&gt; &lt;/fileSet&gt; &lt;!-- 把配置文件，打包进zip文件的config目录 --&gt; &lt;fileSet&gt; &lt;directory&gt;$&#123;project.basedir&#125;/src/main/resources&lt;/directory&gt; &lt;outputDirectory&gt;config&lt;/outputDirectory&gt; &lt;includes&gt; &lt;include&gt;**/*&lt;/include&gt; &lt;include&gt;*.xml&lt;/include&gt; &lt;include&gt;*.properties&lt;/include&gt; &lt;include&gt;*.yml&lt;/include&gt; &lt;include&gt;*.key&lt;/include&gt; &lt;/includes&gt; &lt;/fileSet&gt; &lt;!-- 把jar，打进zip文件的根目录 --&gt; &lt;fileSet&gt; &lt;directory&gt;$&#123;project.build.directory&#125;&lt;/directory&gt; &lt;outputDirectory&gt;&lt;/outputDirectory&gt; &lt;includes&gt; &lt;include&gt;*.jar&lt;/include&gt; &lt;/includes&gt; &lt;/fileSet&gt; &lt;/fileSets&gt;&lt;/assembly&gt; bin目录123456789101112131415#!/bin/bashset -xcat xx.pid | xargs kill -9sleep 1nohup java -jar xx.jar &gt;nohup.log 2&gt;&amp;1 &amp;pid=$!echo $pid &gt; xx.pidtail -200f nohup.info 12345678910111213141516171819202122232425262728293031323334353637&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;executions&gt; &lt;execution&gt; &lt;goals&gt; &lt;goal&gt;repackage&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;!-- The configuration of maven-assembly-plugin --&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-assembly-plugin&lt;/artifactId&gt; &lt;version&gt;3.1.0&lt;/version&gt; &lt;!-- The configuration of the plugin --&gt; &lt;configuration&gt; &lt;descriptors&gt; &lt;!-- 配置 assembly 的路径 --&gt; &lt;descriptor&gt;assembly/assembly.xml&lt;/descriptor&gt; &lt;/descriptors&gt; &lt;/configuration&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;make-assembly&lt;/id&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;single&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt;]]></content>
      <categories>
        <category>工具利器</category>
      </categories>
      <tags>
        <tag>Maven</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java Collection Sort之IllegalArgumentException]]></title>
    <url>%2Fposts%2F63757%2F</url>
    <content type="text"><![CDATA[java.lang.IllegalArgumentException: Comparison method violates its general contract!在 JDK 7 版本以上， Comparator 要满足自反性，传递性，对称性，不然Arrays.sort、Collections.sort会报 IllegalArgumentException 异常。 说明：1 ） 自反性： x ， y 的比较结果和 y ， x 的比较结果相反。2 ） 传递性： x &gt; y , y &gt; z ,则 x &gt; z 。3 ） 对称性： x = y ,则 x , z 比较结果和 y ， z 比较结果相同。 反例： 下例中没有处理相等的情况，实际使用中可能会出现异常 123456new Comparator&lt;Student&gt;() &#123; @Override public int compare(Student o1, Student o2) &#123; return o1.getId() &gt; o2.getId() ? 1 : -1; &#125;&#125; 正例: 12345678910111213/** * 基于某种 Comparable 接口实现一个关键码类，并将所有通常的比较方法封装起来，以支持关键码之间的比较。 */public interface Comparator &#123; /** * 若a&gt;（=或&lt;）b，返回正数、零或负数 * * @param a * @param b * @return */ public int compare(Object a, Object b);&#125;]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Sort</tag>
        <tag>Comparator</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java双份对象数据热切换]]></title>
    <url>%2Fposts%2F42352%2F</url>
    <content type="text"><![CDATA[1234567//当前副本public List&lt;String&gt; r1 = null;//第二个副本public List&lt;String&gt; r2 = null;public AtomicBoolean replicationIsEmpty = new AtomicBoolean(); 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051private void initCurrent() &#123; r1 = new ArrayList&lt;String&gt;(10);&#125;private void initReplication() &#123; r2 = new ArrayList&lt;String&gt;(10);&#125;/** * 更新数据至副本，同时切换副本状态 * * @param keys */private void addKeys(List&lt;String&gt; keys) &#123; //replicationIsEmpty为true，表示可用 if (replicationIsEmpty.get()) &#123; r2.addAll(keys); replicationIsEmpty.set(false); try &#123; //等其他正在引用该数据方法处理完成 Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; initCurrent(); &#125; else &#123; r1.addAll(keys); //先改状态，运行两份数据并存 replicationIsEmpty.set(true); try &#123; //等其他正在引用该数据方法处理完成 Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; //后清空 initReplication(); &#125;&#125;/** * 根据副本状态，返回引用对象 * * @return */private List&lt;String&gt; getIdList() &#123; if (!replicationIsEmpty.get()) &#123; return r2; &#125; else &#123; return r1; &#125;&#125;]]></content>
      <categories>
        <category>架构</category>
      </categories>
      <tags>
        <tag>数据切换</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[WatchService监控目录和文件变化]]></title>
    <url>%2Fposts%2F34381%2F</url>
    <content type="text"><![CDATA[两种监控文件和目录方式Commons-io 在Apache的Commons-io提供文件的监控功能。 由文件监控类FileAlterationMonitor中的线程不停的扫描文件观察器FileAlterationObserver。 如果有文件的变化，则根据相关的文件比较器，判断文件时新增，还是删除，还是更改。（默认为1000毫秒执行一次扫描） WatchService Java1.7中提供了NIO WatchService来监控系统中文件的变化。 该监控是基于操作系统的文件系统监控器，可以监控系统是所有文件的变化，这种监控是无需遍历、无需比较的，是一种基于信号收发的监控。 整个监控目录文件操作的流程大致如下： 获取 WatchService 注册指定目录的监视器 等待目录下的文件发生变化 对发生变化的文件进行操作 WatchService文件监控1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283@Slf4jpublic class FileWatchTask implements Runnable &#123; private String fileDirectory; private List&lt;String&gt; monitorFileNameList = new ArrayList&lt;&gt;(); private ParseIF parseIF; /** * @param fileDirectory 监控目录 * @param monitorFileNameList 监控文件名 * @param parseIF 处理函数 */ public FileWatchTask(String fileDirectory, List&lt;String&gt; monitorFileNameList, ParseIF parseIF) &#123; this.fileDirectory = fileDirectory; if (monitorFileNameList != null) &#123; this.monitorFileNameList = monitorFileNameList; &#125; this.parseIF = parseIF; &#125; @Override public void run() &#123; WatchService service = null; try &#123; //获取当前文件系统的监控对象 service = FileSystems.getDefault().newWatchService(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; try &#123; //获取文件目录下的Path对象注册到 watchService中。 //监听的事件类型，有创建，删除，以及修改 Paths.get(fileDirectory) .register(service, StandardWatchEventKinds.ENTRY_CREATE, StandardWatchEventKinds.ENTRY_DELETE, StandardWatchEventKinds.ENTRY_MODIFY); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; while (true) &#123; //WatchKey 类代表了这个监听服务的注册，可以用它来获取事件的各个属性。 WatchKey key = null; try &#123; //获取可用key.没有可用的就wait key = service.take(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; for (WatchEvent&lt;?&gt; event : key.pollEvents()) &#123; log.warn(event.context() + "-" + event.kind() + "-" + event.count()); final WatchEvent.Kind&lt;?&gt; kind = event.kind(); if (kind == StandardWatchEventKinds.OVERFLOW) &#123; continue; &#125; // get the filename for the event final WatchEvent&lt;Path&gt; watchEventPath = (WatchEvent&lt;Path&gt;) event; final Path fileName = watchEventPath.context(); if (monitorFileNameList.stream().noneMatch(e -&gt; e.equals(fileName.getFileName().toString()))) &#123; continue; &#125; //创建事件 if (kind == StandardWatchEventKinds.ENTRY_CREATE) &#123; parseIF.parse(FileStatus.CREATE); &#125; //修改事件 if (kind == StandardWatchEventKinds.ENTRY_MODIFY) &#123; parseIF.parse(FileStatus.MODIFY); &#125; //删除事件 if (kind == StandardWatchEventKinds.ENTRY_DELETE) &#123; parseIF.parse(FileStatus.DELETE); &#125; &#125; //重置，这一步很重要，否则当前的key就不再会获取将来发生的事件 boolean valid = key.reset(); //失效状态，退出监听 if (!valid) &#123; break; &#125; &#125; &#125;&#125; 文件类型123public enum FileStatus &#123; CREATE, DELETE, MODIFY&#125; 处理函数@FunctionalInterfacepublic interface ParseIF { boolean parse(FileStatus type);} 线程池123456789101112131415161718192021222324252627282930313233/** * 目录监控 * * @return */private synchronized boolean monitor() &#123; if (monitor) &#123; return false; &#125; monitor = true; //因为是线程安全的所以可以放入ThreadPool中使用 ExecutorService cachedThreadPool = newFixedThreadPool(1); //监控文件 List&lt;String&gt; monitorFileNameList = Arrays.asList("a.txt", "b.txt"); //处理 ParseIF parseIF = (type) -&gt; &#123; if (type == FileStatus.CREATE || type == FileStatus.MODIFY) &#123; reload(filePath); &#125; else &#123; return false; &#125; return true; &#125;; //监控目录、文件及处理 cachedThreadPool.execute(new FileWatchTask(filePath+"/c", monitorFileNameList, parseIF)); return true;&#125;]]></content>
      <categories>
        <category>架构</category>
      </categories>
      <tags>
        <tag>WatchService</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RPC框架 - Thrift协议定义]]></title>
    <url>%2Fposts%2F45936%2F</url>
    <content type="text"><![CDATA[rpcRPC 是远程过程调用（Remote Procedure Call）。 RPC 是指计算机 A 上的进程，调用另外一台计算机 B 上的进程，其中 A 上的调用进程被挂起，而 B 上的被调用进程开始执行，当值返回给 A 时，A 进程继续执行。调用方可以通过使用参数将信息传送给被调用方，而后可以通过传回的结果得到信息。 远程过程调用采用客户机/服务器(C/S)模式。请求程序就是一个客户机，而服务提供程序就是一台服务器。和常规或本地过程调用一样，远程过程调用是同步操作，在远程过程结果返回之前，需要暂时中止请求程序。使用相同地址空间的低权进程或低权线程允许同时运行多个远程过程调用。 编写IDL文件时需要注意的问题 函数的参数要用数字依序标好，序号从1开始，形式为：“序号:参数名” 每个函数的最后要加上“,”，最后一个函数不加 在IDL中可以使用/……/添加注释 IDL支持的数据类型IDL大小写敏感，它共支持以下几种基本的数据类型： string,字符串类型，注意是全部小写形式 i16,16位整形类型，相当于 short 类型 i32，32位整形类型，对应C/C++/java中的int类型 i64，64位整形，对应C/C++/java中的long类型 byte，8位的字符类型，对应C/C++中的char，java中的byte类型 bool, 布尔类型，对应C/C++中的bool，java中的boolean类型 double，双精度浮点类型，对应C/C++/java中的double类型 void，空类型，对应C/C++/java中的void类型；该类型主要用作函数的返回值 注：Thrift 不支持无符号整数类型，因为很多编程语言不存在无符号类型，比如 Java 除上述基本类型外，ID还支持以下类型： map，map类型 set，集合类型 list，列表类型 在Thrift文件中自定义数据类型 枚举类型 结构体类型 thrift定义字段12345- 1:optional a.b c;- 2:required string d;- 3:required i32 e=-1;- 4:optional f g;- 5:optional bool h=false; required: 必须填充，并且会序列化 optional:可以不填充，但是不填充，不会序列化，填充的才会序列化， thrift定义枚举和结构体12345678enum f&#123; x,y,z&#125;struct b&#123; 1:optional i16 o; 2:optional string p; 3:optional double q;&#125; thrift定义接口1234service Service&#123; list&lt;b&gt; getList(1:list&lt;i64&gt; ids); b getInfo(1:i64 id);&#125; 定义类型别名1typedefi32 Integer 就可以为i32类型重新起个名字Integer。 常量12345const string SERVER_IP = "127.0.0.1"const i32 SERVER_PORT = 5900const map&lt;string, string&gt; MAP_CONST = &#123;"hello": "world", "goodnight": "moon"&#125; 异常异常在语法和功能上类似于结构体，差别是异常使用关键字exception，而且异常是继承每种语言的基础异常类。 12345exception Extest &#123;1: i32 errorCode,2: string message,3: StUser userinfo&#125; Namespace和Includes12345namespace java com.xx.xx.xxinclude "xxx.thrift"include "xx.thrift"include "xxx.thrift" Thrift中的命名空间同C++中的namespace和java中的package类似 Thrift允许一个IDL文件包含另一个IDL文件，被包含的文件会在当前目录下查找。在使用被包含文件中的类型时要注意通过文件名前缀来访问。 联合当一个结构体中，field 之间的关系是互斥的，即只能有一个 field 可生效被赋值。我们可以用 union 来声明这个结构体，而不是一堆堆 optional 的 field，语意上也更明确了。例如： 12345678union JavaObjectArg &#123; 1: i32 int_arg; 2: i64 long_arg; 3: string string_arg; 4: bool bool_arg; 5: binary binary_arg; 6: double double_arg;&#125;]]></content>
      <categories>
        <category>架构</category>
      </categories>
      <tags>
        <tag>thrift</tag>
        <tag>rpc</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Lucene利用Hanlp分词索引和检索]]></title>
    <url>%2Fposts%2F49532%2F</url>
    <content type="text"><![CDATA[包引入 pom引入lucene和hanlp lucene版本为7.4 hanlp分词器版本为1.1.6 1234567891011121314151617&lt;dependency&gt; &lt;groupId&gt;org.apache.lucene&lt;/groupId&gt; &lt;artifactId&gt;lucene-core&lt;/artifactId&gt; &lt;version&gt;7.4.0&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.lucene&lt;/groupId&gt; &lt;artifactId&gt;lucene-queryparser&lt;/artifactId&gt; &lt;version&gt;7.4.0&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.hankcs.nlp&lt;/groupId&gt; &lt;artifactId&gt;hanlp-lucene-plugin&lt;/artifactId&gt; &lt;version&gt;1.1.6&lt;/version&gt;&lt;/dependency&gt; 对数据文件进行索引123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354public class DocIndex &#123; // 建立索引文件的目录 public static String indexPath = "/index"; public static void index(String path, Map&lt;String, SugRecord&gt; map, boolean reIndex) &#123; indexPath = path + indexPath; if (!reIndex) &#123; return; &#125; IndexWriter writer = null; try &#123; // 存储索引数据的目录 Directory dir = FSDirectory.open(Paths.get(indexPath)); // 创建分析器 Analyzer analyzer = new HanLPAnalyzer(); IndexWriterConfig iwc = new IndexWriterConfig(analyzer); iwc.setOpenMode(IndexWriterConfig.OpenMode.CREATE); writer = new IndexWriter(dir, iwc); indexDoc(writer, map); writer.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; private static void indexDoc(IndexWriter writer, Map&lt;String, SugRecord&gt; map) &#123; map.forEach((k, v) -&gt; &#123; // 创建一个新的空文档 Document doc = new Document(); //创建索引字段 doc.add(new TextField("id", v.getId(), Field.Store.YES)); doc.add(new TextField("question", v.getQueryNorm(), Field.Store.NO)); doc.add(new TextField("query", v.getQuery(), Field.Store.NO)); // 写文档 try &#123; writer.addDocument(doc); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125;); try &#123; writer.flush(); writer.commit(); writer.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 对索引进行检索123456789101112131415161718192021222324252627282930313233343536373839404142434445464748@Slf4jpublic class DocSearcher &#123; public static List&lt;SugTerm&gt; search(String content) &#123; IndexReader reader = null; try &#123; reader = DirectoryReader.open(FSDirectory.open(Paths.get(DocIndex.indexPath))); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; IndexSearcher searcher = new IndexSearcher(reader); //或关系，多域检索 String[] fields = &#123;"question", "query"&#125;; BooleanClause.Occur[] clauses = &#123;BooleanClause.Occur.SHOULD, BooleanClause.Occur.SHOULD&#125;; try &#123; //指定分词器 Query query = MultiFieldQueryParser.parse(content, fields, clauses, new HanLPAnalyzer()); return doPagingSearch(searcher, query); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; return null; &#125; private static List&lt;SugTerm&gt; doPagingSearch(IndexSearcher searcher, Query query) throws IOException &#123; // TopDocs保存搜索结果 TopDocs results = null; List&lt;SugTerm&gt; sugTermList = new ArrayList&lt;&gt;(); //分页数 results = searcher.search(query, 10); ScoreDoc[] hits = results.scoreDocs; for (ScoreDoc hit : hits) &#123; Document document = searcher.doc(hit.doc); String id = Objects.requireNonNull(document).get("id"); SugRecord sugRecord = KefuBotSug.dataIdx.get(id); SugTerm sugTerm = new SugTerm(); sugTerm.id = sugRecord.getId(); sugTerm.query = sugRecord.getQuery(); sugTerm.question = sugRecord.queryNorm; sugTerm.score = hit.score; sugTermList.add(sugTerm); &#125; log.info(sugTermList.toString()); return sugTermList; &#125;&#125;]]></content>
      <categories>
        <category>架构</category>
      </categories>
      <tags>
        <tag>lucene</tag>
        <tag>hanlp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java线程池 - ThreadPool自定义封装]]></title>
    <url>%2Fposts%2F33509%2F</url>
    <content type="text"><![CDATA[自定义线程池，便于调试和控制线程 自定义线程数、拒绝策略、关闭等 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164@Slf4jpublic class BotTaskThreadPool implements BotThreadPool &#123; /** * 核心大小 */ private static int CORE_POOLSIZE = Runtime.getRuntime().availableProcessors() * 2; /** * 上限 */ private static int MAX_POOLSIZE = CORE_POOLSIZE * 10; //留存时间ms private static long KEEP_ALIVETIME = 300000L; private static long SHUTDOWN_WAIT_TIME = 300000L; /** * 时间单位 */ private static TimeUnit UNIT = TimeUnit.MILLISECONDS; /** * 队列容量 */ private static int CAPACITY = 20; /** * 队列 */ private static BlockingQueue&lt;Runnable&gt; WORK_QUEUE; /** * 线程工厂 */ private static ThreadFactory THREAD_FACTORY; /** * 默认拒绝策略 */ private static RejectedExecutionHandler REJECTED_EXECUTION_HANDLER; private static ThreadPoolExecutor executor = null; private static class BotTaskThreadPoolFactory &#123; public static BotTaskThreadPool botTaskThreadPool = new BotTaskThreadPool(); &#125; /** * 线程池单例 * * @return */ public static BotTaskThreadPool getInstance() &#123; return BotTaskThreadPoolFactory.botTaskThreadPool; &#125; public BotTaskThreadPool() &#123; if (CORE_POOLSIZE &lt;= 0 || CORE_POOLSIZE &gt; 10) &#123; CORE_POOLSIZE = 4; MAX_POOLSIZE = CORE_POOLSIZE * 10; &#125; THREAD_FACTORY = new BotThreadFactory(); WORK_QUEUE = new ArrayBlockingQueue&lt;&gt;(CAPACITY); REJECTED_EXECUTION_HANDLER = new AbortPolicy(); executor = new ThreadPoolExecutor( CORE_POOLSIZE, MAX_POOLSIZE, KEEP_ALIVETIME, UNIT, WORK_QUEUE, THREAD_FACTORY, REJECTED_EXECUTION_HANDLER ); &#125; static &#123; Runtime.getRuntime().addShutdownHook(new Thread(new BotRunnable() &#123; @Override public void run() &#123; close(); &#125; &#125;)); &#125; private static void close() &#123; try &#123; log.warn("即将关闭线程池，等待:&#123;&#125;ms,活跃:&#123;&#125;,未完成:&#123;&#125;,最大完成:&#123;&#125;,总完成:&#123;&#125;", SHUTDOWN_WAIT_TIME, executor.getActiveCount(), executor.getQueue().size(), executor.getLargestPoolSize(), executor.getCompletedTaskCount()); executor.shutdown(); //等待关闭 executor.awaitTermination(SHUTDOWN_WAIT_TIME, UNIT); log.warn("已关闭线程池"); //未完成 List&lt;Runnable&gt; botRunnableList = executor.shutdownNow(); if (!CollectionUtil.isEmpty(botRunnableList)) &#123; botRunnableList.forEach(e -&gt; log.warn("关闭未完成任务:" + e.toString())); &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; @Override public boolean execute(Runnable runnable) &#123; try &#123; executor.execute(new BotRunnable(runnable)); &#125; catch (Exception e) &#123; log.error(e.getMessage(), e); return false; &#125; return true; &#125; @Override public &lt;T&gt; Future&lt;T&gt; submit(Callable&lt;T&gt; tCallable) &#123; try &#123; return executor.submit(new BotCallable&lt;T&gt;(tCallable)); &#125; catch (RejectedExecutionException e) &#123; log.error(e.getMessage(), e); &#125; return null; &#125; @Override public void shutDown() &#123; executor.shutdown(); &#125; /** * 拒绝策略，丢弃不作任何处理 */ public static class AbortPolicy implements RejectedExecutionHandler &#123; @Override public void rejectedExecution(Runnable r, ThreadPoolExecutor e) &#123; String info = ""; try &#123; Field field = FutureTask.class.getDeclaredField("callable"); field.setAccessible(true); FutureTask futureTask = (FutureTask) r; Callable callable = (Callable) field.get(futureTask); BotCallable botCallable = (BotCallable) ((BotCallable) callable).callable; info = botCallable.toString(); &#125; catch (Exception ex) &#123; ex.printStackTrace(); &#125; log.error("AbortPolicy: " + info + " rejected from " + e.toString()); &#125; &#125;&#125; 注意 计算密集型 线程数 = CPU核数+1，也可以设置成CPU核数*2，但还要看JDK的版本以及CPU配置(服务器的CPU有超线程)。 IO密集型 线程数 = CPU核心数/(1-阻塞系数) 这个阻塞系数一般为0.8~0.9之间，也可以取0.8或者0.9。套用公式，对于双核CPU来说，它比较理想的线程数就是20，当然这都不是绝对的，需要根据实际情况以及实际业务来调整：final int poolSize = (int)(cpuCore/(1-0.9)) 对于阻塞系数，我们可以先试着猜测，抑或采用一些性能分析工具或java.lang.management API 来确定线程花在系统/IO操作上的时间与CPU密集任务所耗的时间比值。 Runtime.getRuntime().availableProcessors() 因为容器不是物理隔离的，使用Runtime.getRuntime().availableProcessors() ，会拿到物理CPU个数，而不是容器申请时的个数。 例如宿主机器是4核CPU16G内存 java 6/7/8/9 docker run –cpus 1 -m 1G -it adoptopenjdk/openjdk9:latest # 给1核 jshell -J-Xmx512M -v # 启动jshell Runtime.getRuntime().availableProcessors() # 结果是不是1！！！ java 10 docker run –cpus 1 -m 1G -it adoptopenjdk/openjdk10:latest # 给1核 jshell -J-Xmx512M -v # 启动jshell Runtime.getRuntime().availableProcessors() # 结果是1]]></content>
      <categories>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>线程池</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java线程池 - ThreadFactory封装]]></title>
    <url>%2Fposts%2F59782%2F</url>
    <content type="text"><![CDATA[自定义ThreadFactory，便于创建自定义线程 自定义ThreadGroup，便于对线程分组管理 ThreadFactory和ThreadGroup封装123456789101112131415161718192021222324252627282930313233343536373839404142@Slf4jpublic class BotThreadFactory implements ThreadFactory &#123; private AtomicInteger threadNum = new AtomicInteger(1); private final static String prefix = "bot-thread-"; @Override public Thread newThread(Runnable r) &#123; String name = prefix + threadNum.getAndIncrement(); ThreadGroup threadGroup = new BotThreadGroup("BOT_GROUP"); //非守护进程 threadGroup.setDaemon(false); //优先执行 threadGroup.setMaxPriority(Thread.MAX_PRIORITY); Thread thread = new Thread(threadGroup, r, name); return thread; &#125; static class BotThreadGroup extends ThreadGroup &#123; public BotThreadGroup(String name) &#123; super(name); &#125; public BotThreadGroup(ThreadGroup parent, String name) &#123; super(parent, name); &#125; /** * 异常处理 * * @param t * @param e */ @Override public void uncaughtException(Thread t, Throwable e) &#123; log.error("线程名称:&#123;&#125;,异常信息:&#123;&#125;,异常栈:&#123;&#125;", t.getName(), e.getMessage(), e); &#125; &#125;&#125; ThreadFactory ThreadFactory的作用就是提供创建线程的功能的线程工厂 它是通过newThread()提供创建线程 newThread()创建的线程对应的任务是Runnable对象 它创建的线程默认都是“非守护线程”而且“线程优先级都是Thread.NORM_PRIORITY”。 ThreadGroup 方便地对加入这个线程组的多个线程进行操作。 重写uncaughtException()来实现自己的线程运行时异常处理逻辑 线程组可以进行复制，快速定位到一个线程 Thread类的enumerate()方法用于将每个活动线程的线程组及其子组复制到指定的数组中 1234567891011121314151617ThreadGroup group = Thread.currentThread().getThreadGroup(); ThreadGroup topGroup = group; // 遍历线程组树，获取根线程组 while (group != null) &#123; topGroup = group; group = group.getParent(); &#125; Thread[] slackList = new Thread[topGroup.activeCount() ]; // 获取根线程组的所有线程 int actualSize = topGroup.enumerate(slackList); // copy into a list that is the exact size Thread[] list = new Thread[actualSize]; System.arraycopy(slackList, 0, list, 0, actualSize); System.out.println("Thread list size == " + list.length); for (Thread thread : list) &#123; System.out.println(thread.getName()); &#125;]]></content>
      <categories>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>线程池</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java线程池 - Callable和Runnable封装]]></title>
    <url>%2Fposts%2F9431%2F</url>
    <content type="text"><![CDATA[对Callable和Runnable封装，提供自定义执行接口 补充异常处理 Runnable123456789101112131415161718192021222324252627282930313233343536373839@Slf4jpublic class BotRunnable implements Runnable &#123; private Runnable runnable; public BotRunnable() &#123; &#125; public BotRunnable(final Runnable runnable) &#123; this.runnable = runnable; &#125; private String taskId; public void setTaskId(String taskId) &#123; this.taskId = taskId; &#125; @Override public void run() &#123; if (runnable == null) &#123; return; &#125; try &#123; runnable.run(); &#125; catch (Exception e) &#123; log.error("任务:&#123;&#125;,错误栈:&#123;&#125;", taskId, e); e.printStackTrace(); &#125; &#125; @Override public String toString() &#123; return Thread.currentThread().getName(); &#125;&#125; Callable1234567891011121314151617181920212223242526272829303132333435@Slf4jpublic class BotCallable&lt;T&gt; implements Callable &#123; Callable&lt;T&gt; callable; public BotCallable(Callable&lt;T&gt; callable) &#123; this.callable = callable; &#125; private String taskId; public void setTaskId(String taskId) &#123; this.taskId = taskId; &#125; @Override public T call() throws Exception &#123; if (callable == null) &#123; return null; &#125; try &#123; return callable.call(); &#125; catch (Exception e) &#123; log.error("任务:&#123;&#125;,错误栈:&#123;&#125;", taskId, e); e.printStackTrace(); &#125; return null; &#125; @Override public String toString() &#123; return Thread.currentThread().getName(); &#125;&#125; 区别 模块 Runnable Callable 返回值 否 是 返回对象 无 Future 执行方法 run call 执行超时 无 get(long timeout,TimeUtil unit) 获取结果 无 get、isDone 异常处理 无 throws Exception 线程阻塞 否 是,LockSupport.park]]></content>
      <categories>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>线程池</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Maven配置Profile]]></title>
    <url>%2Fposts%2F52371%2F</url>
    <content type="text"><![CDATA[项目根据环境不同，设置不同参数 实现在代码中无需改动，以防误提交 在pom中添加以下配置 12345678910111213141516171819&lt;profiles&gt; &lt;profile&gt; &lt;id&gt;dev&lt;/id&gt; &lt;properties&gt; &lt;profile.active&gt;dev&lt;/profile.active&gt; &lt;resource.exclude&gt;-&lt;/resource.exclude&gt; &lt;/properties&gt; &lt;/profile&gt; &lt;profile&gt; &lt;id&gt;prod&lt;/id&gt; &lt;activation&gt; &lt;activeByDefault&gt;true&lt;/activeByDefault&gt; &lt;/activation&gt; &lt;properties&gt; &lt;profile.active&gt;prod&lt;/profile.active&gt; &lt;resource.exclude&gt;*.yml&lt;/resource.exclude&gt; &lt;/properties&gt; &lt;/profile&gt; &lt;/profiles&gt; 默认prod 本地开发时，在Idea中Maven插件的Profiles中选择dev即可]]></content>
      <categories>
        <category>架构</category>
      </categories>
      <tags>
        <tag>maven</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker部署和配置Nginx]]></title>
    <url>%2Fposts%2F29980%2F</url>
    <content type="text"><![CDATA[获取镜像1docker search nginx 安装官方版本name： docker.io/nginxOFFICIAL： ok 123docker pull nginxdocker images nginx 拉取并查看镜像 启动12345mkdir -p ./nginx/www ./nginx/logs ./nginx/confdocker run --name nginx-bot -p 9803:80 -d -v /home/nginx/www:/usr/share/nginx/html -v /home/nginx/conf/nginx.conf:/etc/nginx/nginx.conf -v /home/nginx/logs:/var/log/nginx nginxdocker ps name: 容器名称。-d:设置容器在在后台一直运行。-p: 端口进行映射，将本地9803端口映射到容器内部的80端口。www: 目录将映射为nginx容器配置的虚拟目录。logs: 目录将映射为nginx容器的日志目录。conf: 目录里的配置文件将映射为nginx容器的配置文件。 配置index.html1234567891011121314cd ./nginx/wwwvi index.html&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt;&lt;meta charset="utf-8"&gt;&lt;title&gt;welcome&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;h1&gt;hello&lt;/h1&gt; &lt;p&gt;world。&lt;/p&gt;&lt;/body&gt;&lt;/html&gt; 配置默认页面 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253vi /home/nginx/conf/nginx.confuser nginx;worker_processes 1;error_log /var/log/nginx/error.log warn;pid /var/run/nginx.pid;events &#123; worker_connections 1024;&#125;http &#123; include /etc/nginx/mime.types; default_type application/octet-stream; log_format main '$remote_addr - $remote_user [$time_local] "$request" ' '$status $body_bytes_sent "$http_referer" ' '"$http_user_agent" "$http_x_forwarded_for"'; access_log /var/log/nginx/access.log main; sendfile on; #tcp_nopush on; keepalive_timeout 65; #gzip on; server&#123; listen 80; server_name localhost; index index.html index.htm; root /usr/share/nginx/html; location /recommend &#123; proxy_pass http://recommend_api; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; &#125; &#125; upstream recommend_api &#123; server 172.16.25.70:9819; server 192.168.1.41:9804 down; &#125; include /etc/nginx/conf.d/*.conf;&#125; 配置nginx文件及反向代理 测试12345docker restart c7d0b0a20287ecurl -l localhost:9803curl -l localhost:9803/recommend/api 说明设备状态 own：表示单前的server暂时不参与负载. weight：默认为1.weight越大，负载的权重就越大。 max_fails：允许请求失败的次数默认为1.当超过最大次数时，返回proxy_next_upstream 模块定义的错误. fail_timeout : max_fails次失败后，暂停的时间。 backup： 其它所有的非backup机器down或者忙的时候，请求backup机器。所以这台机器压力会最轻 分配策略 none（轮询）upstream按照轮询（默认）方式进行负载，每个请求按时间顺序逐一分配到不同的后端服务器，如果后端服务器down掉，能自动剔除。虽然这种方式简便、成本低廉。但缺点是：可靠性低和负载分配不均衡。 weight（权重）指定轮询几率，weight和访问比率成正比，用于后端服务器性能不均的情况。例如 server 192.168.61.22 weight = 6; # 60% 请求 server 192.168.61.23 weight = 4; # 40% 请求 ip_hash（访问ip）每个请求按访问ip的hash结果分配，这样每个访客固定访问一个后端服务器，可以解决session的问题。 配置只需要在upstream中加入ip_hash即可。]]></content>
      <categories>
        <category>架构</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java Lambda Stream原理]]></title>
    <url>%2Fposts%2F42366%2F</url>
    <content type="text"><![CDATA[举例1234567List list = new ArrayList(1); list.add(1); list.add(2); list.stream().forEach( System.out::println ); List.stream方法1234567891011121314default Stream&lt;E&gt; stream() &#123; return StreamSupport.stream(spliterator(), false);&#125;@Overridedefault Spliterator&lt;E&gt; spliterator() &#123; return Spliterators.spliterator(this, 0);&#125;public static &lt;T&gt; Spliterator&lt;T&gt; spliterator(Collection&lt;? extends T&gt; c, int characteristics) &#123; return new IteratorSpliterator&lt;&gt;(Objects.requireNonNull(c), characteristics);&#125; List的stream()接口位于java.util.Collection类中；默认实现输入的参数1是拆分方法spliterator，2是并行默认false。spliterator()接口也在该类中，默认实现调用final Spliterators类的spliterator方法，返回IteratorSpliterator。而static IteratorSpliterator类实现了Spliterator。Spliterator提供了tryAdvance处理每个元素、forEachRemaining、trySplit分割拆分等方法。 也就是说，stream()实际是采用Spliterator对于元素进行遍历、拆分处理。 StreamSupport.stream123456789101112131415public static &lt;T&gt; Stream&lt;T&gt; stream(Spliterator&lt;T&gt; spliterator, boolean parallel) &#123; Objects.requireNonNull(spliterator); return new ReferencePipeline.Head&lt;&gt;(spliterator, StreamOpFlag.fromCharacteristics(spliterator), parallel);&#125;Head(Spliterator&lt;?&gt; source, int sourceFlags, boolean parallel) &#123; super(source, sourceFlags, parallel); &#125;ReferencePipeline(Spliterator&lt;?&gt; source, int sourceFlags, boolean parallel) &#123; super(source, sourceFlags, parallel);&#125; list.stream()方法最终会实例化ReferencePipeline.Head&lt;&gt;对象，Head为pipeline流的头结。Head&lt;E_IN, E_OUT&gt; extends ReferencePipeline&lt;E_IN, E_OUT&gt;，E_IN为上游输入类型，E_OUT为输出类型点。StreamOpFlag.fromCharacteristics(spliterator)，将spliterator字符集转换为带有排序的流标记。ReferencePipeline为继承了AbstractPipeline得抽象类，提供pipeline处理类型的各阶段基类。 AbstractPipeline123456789101112AbstractPipeline(Spliterator&lt;?&gt; source, int sourceFlags, boolean parallel) &#123; this.previousStage = null; this.sourceSpliterator = source; this.sourceStage = this; this.sourceOrOpFlags = sourceFlags &amp; StreamOpFlag.STREAM_MASK; // The following is an optimization of: // StreamOpFlag.combineOpFlags(sourceOrOpFlags, StreamOpFlag.INITIAL_OPS_VALUE); this.combinedFlags = (~(sourceOrOpFlags &lt;&lt; 1)) &amp; StreamOpFlag.INITIAL_OPS_VALUE; this.depth = 0; this.parallel = parallel;&#125; AbstractPipeline为pipeline抽象基类，定义包括前一个、当前、下一个等AbstractPipeline处理流程等。AbstractPipeline继承abstract class PipelineHelper，PipelineHelper定义了流的操作、输出、标记和并行等参数。 forEach1void forEach(Consumer&lt;? super T&gt; action); 对流中的每个元素执行操作。 123456789@Overridepublic void forEach(Consumer&lt;? super E_OUT&gt; action) &#123; if (!isParallel()) &#123; sourceStageSpliterator().forEachRemaining(action); &#125; else &#123; super.forEach(action); &#125;&#125; forEach具体实现位于ReferencePipeline中，执行串行遍历或并行分割处理。 forEach并行1234567891011121314151617181920212223242526@Overridepublic void forEach(Consumer&lt;? super P_OUT&gt; action) &#123; evaluate(ForEachOps.makeRef(action, false));&#125;final &lt;R&gt; R evaluate(TerminalOp&lt;E_OUT, R&gt; terminalOp) &#123; assert getOutputShape() == terminalOp.inputShape(); if (linkedOrConsumed) throw new IllegalStateException(MSG_STREAM_LINKED); linkedOrConsumed = true; return isParallel() ? terminalOp.evaluateParallel(this, sourceSpliterator(terminalOp.getOpFlags())) : terminalOp.evaluateSequential(this, sourceSpliterator(terminalOp.getOpFlags()));&#125;default &lt;P_IN&gt; R evaluateParallel(PipelineHelper&lt;E_IN&gt; helper, Spliterator&lt;P_IN&gt; spliterator) &#123; if (Tripwire.ENABLED) Tripwire.trip(getClass(), &quot;&#123;0&#125; triggering TerminalOp.evaluateParallel serial default&quot;); return evaluateSequential(helper, spliterator);&#125; @Override public &lt;S&gt; Void evaluateSequential(PipelineHelper&lt;T&gt; helper, Spliterator&lt;S&gt; spliterator) &#123; return helper.wrapAndCopyInto(this, spliterator).get(); &#125; forEach并行时，主要采用evaluate方法，在pipeline中采用终止操作处理结果。]]></content>
      <categories>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>Lambda</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java Lambda FunctionalInterface原理]]></title>
    <url>%2Fposts%2F54901%2F</url>
    <content type="text"><![CDATA[123456789101112@FunctionalInterfaceinterface Print&lt;T&gt; &#123; public void print(T x);&#125;public class Lambda &#123; public static void PrintString(String s, Print&lt;String&gt; print) &#123; print.print(s); &#125; public static void main(String[] args) &#123; PrintString("test", (x) -&gt; System.out.println(x)); &#125;&#125; 编译器会根据Lambda表达式生成一个私有的静态函数 123456789101112131415161718192021@FunctionalInterfaceinterface Print&lt;T&gt; &#123; public void print(T x);&#125;public class Lambda &#123; public static void PrintString(String s, Print&lt;String&gt; print) &#123; print.print(s); &#125; private static void lambda$0(String x) &#123; System.out.println(x); &#125; final class $Lambda$1 implements Print&#123; @Override public void print(Object x) &#123; lambda$0((String)x); &#125; &#125; public static void main(String[] args) &#123; PrintString("test", new Lambda().new $Lambda$1()); &#125;&#125;]]></content>
      <categories>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>Lambda</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java8常用文件处理方法]]></title>
    <url>%2Fposts%2F58696%2F</url>
    <content type="text"><![CDATA[获取并解析文件 1234567891011121314151617public void parse() &#123; InputStream resource = Test.class.getResourceAsStream("/a.txt"); try &#123; BufferedReader bufferedReader = new BufferedReader( new InputStreamReader(resource)); // 获取文件 String line; while ((line = bufferedReader.readLine()) != null) &#123; &#125; &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; 获取其及子孙目录下的所有文件和目录 1234567891011public static List&lt;Path&gt; getFileList() &#123; try &#123; return Files.walk(Paths.get(dir)) .filter(Files::isRegularFile) .filter(e -&gt; e.toString().contains("app")) .collect(Collectors.toList()); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; return null;&#125; 写入文件 123456789101112public static void write(StringBuilder stringBuilder) &#123; BufferedWriter bfw = null; try &#123; bfw = Files.newBufferedWriter(Paths.get(dir + "/a.txt")); bfw.write(stringBuilder.toString()); bfw.flush(); bfw.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125;&#125;]]></content>
      <categories>
        <category>工具利器</category>
      </categories>
      <tags>
        <tag>Java8</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker基本操作]]></title>
    <url>%2Fposts%2F5308%2F</url>
    <content type="text"><![CDATA[查看进程docker ps 关闭进程docker kill -s KILL 376ec4b90 docker kill 376ec4b90 docker rm 376ec4b90 docker restart 376ec4b90]]></content>
      <categories>
        <category>架构</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Prometheus与Grafana部署和安装]]></title>
    <url>%2Fposts%2F1379%2F</url>
    <content type="text"><![CDATA[prometheus Prometheus是开源监控报警系统。 多维度数据模型。 灵活的查询语言。 不依赖分布式存储，单个服务器节点是自主的。 通过基于HTTP的pull方式采集时序数据。 可以通过中间网关进行时序列数据推送。 通过服务发现或者静态配置来发现目标服务对象。 支持多种多样的图表和界面展示，比如Grafana等。 概念Prometheus生态系统由多个组件组成，它们中的一些是可选的。多数Prometheus组件是Go语言写的，这使得这些组件很容易编译和部署。 Prometheus Server主要负责数据采集和存储，提供PromQL查询语言的支持。 客户端SDK官方提供的客户端类库有go、java、scala、python、ruby，其他还有很多第三方开发的类库，支持nodejs、php、erlang等。 Push Gateway支持临时性Job主动推送指标的中间网关。 PromDash使用Rails开发可视化的Dashboard，用于可视化指标数据。 ExporterExporter是Prometheus的一类数据采集组件的总称。它负责从目标处搜集数据，并将其转化为Prometheus支持的格式。与传统的数据采集组件不同的是，它并不向中央服务器发送数据，而是等待中央服务器主动前来抓取。 Prometheus提供多种类型的Exporter用于采集各种不同服务的运行状态。目前支持的有数据库、硬件、消息中间件、存储系统、HTTP服务器、JMX等。 alertmanager警告管理器，用来进行报警。 prometheus_cli命令行工具。 其他辅助性工具多种导出工具，可以支持Prometheus存储数据转化为HAProxy、StatsD、Graphite等工具所需要的数据存储格式。 node-exporter下载镜像docker pull prom/node-exporter 运行1234567docker run -d \ -p 9090:9090 \ --net="host" \ --pid="host" \ -v "/:/host:ro,rslave" \ quay.io/prometheus/node-exporter \ --path.rootfs /host redis_exporter下载镜像docker pull oliver006/redis_exporter 运行1234docker run -d \--name redis_exporter \-p 9121:9121 \oliver006/redis_exporter --redis.addr redis://h:password@192.168.1.41:6380 或者 123wget https://github.com/oliver006/redis_exporter/releases/download/v0.13/redis_exporter-v0.13.linux-amd64.tar.gz./redis_exporter -redis.addr 192.168.1.41:6380 -redis.password password &amp; mysqld-exporter下载镜像docker pull prom/mysqld-exporter 运行1234docker run -d \ -p 9101:9104 \ -e DATA_SOURCE_NAME="root:password@(192.168.1.41:3308)/test" \ prom/mysqld-exporter 或者 123456789wget https://github.com/prometheus/mysqld_exporter/releases/download/v0.10.0/mysqld_exporter-0.10.0.linux-amd64.tar.gz -O mysqld_exporter-0.10.0.linux-amd64.tar.gz cat &lt;&lt; EOF &gt; my.cnf[client]user=prompassword=abc123EOF./mysqld_exporter -config.my-cnf=&quot;my.cnf&quot; grafana下载镜像docker pull grafana/grafana 运行1docker run -d --name=grafana -p 3000:3000 grafana/grafana prometheus下载镜像docker pull prom/prometheus 运行12345sudo docker run -d \ -p 9090:9090 \ -v /home/config/prometheus.yml:/home/config/prometheus.yml \ quay.io/prometheus/prometheus \ --config.file=/home/config/prometheus.yml 配置prometheus.yml 12345678910111213141516171819202122crape_configs: - job_name: 'prometheus' static_configs: - targets: ['localhost:9090'] - job_name: 'redis-41' static_configs: - targets: ['192.168.1.41:9121'] labels: instance: redis - job_name: 'linux-41' static_configs: - targets: ['192.168.1.41:9100'] labels: instance: node - job_name: 'mysql-41' static_configs: - targets: ['192.168.1.41:9101'] labels: instance: db 重启服务 123docker psdocker restart `prometheus-processid` 登录验证12prometheus 192.168.1.41:9090grafana 192.168.1.41:3000 admin/admin]]></content>
      <categories>
        <category>工具利器</category>
      </categories>
      <tags>
        <tag>Prometheus</tag>
        <tag>Grafana</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[搭建Http-Server用于文件传输]]></title>
    <url>%2Fposts%2F4544%2F</url>
    <content type="text"><![CDATA[Http-Serverhttp-server 安装npm install http-server -g 启动cd ~/Public/http-server默认是 8080端口，./public文件夹 文件上传./public 文件下载wget http://172.16.25.70:8080/prometheus.yml pm2开机启动github```bashpm2 delete http-localwhich http-serverpm2 start /usr/local/bin/http-server –name http-local – -p 8080pm2 savepm2 startup]]></content>
      <categories>
        <category>工具利器</category>
      </categories>
      <tags>
        <tag>Http-Server</tag>
        <tag>nodejs</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Prometheus集成SpringBoot1.5]]></title>
    <url>%2Fposts%2F42635%2F</url>
    <content type="text"><![CDATA[Prometheus集成SpringBoot1.5pom12345678910111213141516171819202122232425262728&lt;!-- Actuator (with security enabled) --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-security&lt;/artifactId&gt;&lt;/dependency&gt;&lt;!-- Monitoring endpoint - Micrometer + Prometheus --&gt; &lt;dependency&gt; &lt;groupId&gt;io.micrometer&lt;/groupId&gt; &lt;artifactId&gt;micrometer-registry-prometheus&lt;/artifactId&gt; &lt;version&gt;1.0.3&lt;/version&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;artifactId&gt;HdrHistogram&lt;/artifactId&gt; &lt;groupId&gt;org.hdrhistogram&lt;/groupId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.micrometer&lt;/groupId&gt; &lt;artifactId&gt;micrometer-spring-legacy&lt;/artifactId&gt; &lt;version&gt;1.0.3&lt;/version&gt; &lt;/dependency&gt; bootstrap.yml123456789101112131415management: endpoints: web: exposure: include: &apos;*&apos; jmx: exposure: include: &apos;*&apos; shutdown: enabled: true metrics: distribution: percentiles-histogram[http.server.requests]: true security: enabled: false application.java1234567@BeanMeterRegistryCustomizer meterRegistryCustomizer(MeterRegistry meterRegistry) &#123; return meterRegistry1 -&gt; &#123; meterRegistry.config() .commonTags("application", "micrometer-oceanus-chatbot-web"); &#125;;&#125; 配置prometheus.yml 1234- job_name: 'app-41' metrics_path: '/mgmt/prometheus' static_configs: - targets: ['192.168.1.41:9915'] 重启服务 123docker psdocker restart `prometheus-processid` 登录验证12prometheus 192.168.1.41:9090grafana 192.168.1.41:3000 admin/admin]]></content>
      <categories>
        <category>工具利器</category>
      </categories>
      <tags>
        <tag>Prometheus</tag>
        <tag>SpringBoot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java Lambda用法]]></title>
    <url>%2Fposts%2F15864%2F</url>
    <content type="text"><![CDATA[特点 函数传递 函数编程 闭包 Java 中的 Lambda 表达式通常使用 (argument) -&gt; (body) 语法书写，例如： (arg1, arg2…) -&gt; { body } (type1 arg1, type2 arg2…) -&gt; { body }以下是一些 Lambda 表达式的例子： 123456789(int a, int b) -&gt; &#123; return a + b; &#125;() -&gt; System.out.println("Hello World");(String s) -&gt; &#123; System.out.println(s); &#125;() -&gt; 42() -&gt; &#123; return 3.1415 &#125;; 每个 Lambda 表达式都能隐式地赋值给函数式接口，例如，我们可以通过 Lambda 表达式创建 Runnable 接口的引用。 1Runnable r = () -&gt; System.out.println("hello world"); 当不指明函数式接口时，编译器会自动解释这种转化： 123new Thread( () -&gt; System.out.println("hello world")).start(); @FunctionalInterface 函数式接口只能有一个抽象方法，如果你尝试添加第二个抽象方法，将抛出编译时错误 12345678910111213141516171819202122232425262728//定义一个函数式接口### @FunctionalInterfacepublic interface WorkerInterface &#123; public void doSomeWork();&#125;public class WorkerInterfaceTest &#123;public static void execute(WorkerInterface worker) &#123; worker.doSomeWork();&#125;public static void main(String [] args) &#123; //invoke doSomeWork using Annonymous class execute(new WorkerInterface() &#123; @Override public void doSomeWork() &#123; System.out.println("Worker invoked using Anonymous class"); &#125; &#125;); //invoke doSomeWork using Lambda expression execute( () -&gt; System.out.println("Worker invoked using Lambda expression") );&#125;&#125; 用法区别123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172//Old way:List&lt;Integer&gt; list = Arrays.asList(1, 2, 3, 4, 5, 6, 7);for(Integer n: list) &#123; System.out.println(n);&#125;//New way:List&lt;Integer&gt; list = Arrays.asList(1, 2, 3, 4, 5, 6, 7);list.forEach(n -&gt; System.out.println(n));//or we can use :: double colon operator in Java 8list.forEach(System.out::println);public class Main &#123;public static void main(String [] a) &#123; List&lt;Integer&gt; list = Arrays.asList(1, 2, 3, 4, 5, 6, 7); System.out.println("Print all numbers:"); evaluate(list, (n)-&gt;true); System.out.println("Print no numbers:"); evaluate(list, (n)-&gt;false); System.out.println("Print even numbers:"); evaluate(list, (n)-&gt; n%2 == 0 ); System.out.println("Print odd numbers:"); evaluate(list, (n)-&gt; n%2 == 1 ); System.out.println("Print numbers greater than 5:"); evaluate(list, (n)-&gt; n &gt; 5 );&#125;public static void evaluate(List&lt;Integer&gt; list, Predicate&lt;Integer&gt; predicate) &#123; for(Integer n: list) &#123; if(predicate.test(n)) &#123; System.out.println(n + " "); &#125; &#125;&#125;&#125; //Old way:List&lt;Integer&gt; list = Arrays.asList(1,2,3,4,5,6,7);for(Integer n : list) &#123; int x = n * n; System.out.println(x);&#125;//New way:List&lt;Integer&gt; list = Arrays.asList(1,2,3,4,5,6,7);list.stream().map((x) -&gt; x*x).forEach(System.out::println);//Old way:List&lt;Integer&gt; list = Arrays.asList(1,2,3,4,5,6,7);int sum = 0;for(Integer n : list) &#123; int x = n * n; sum = sum + x;&#125;System.out.println(sum);//New way:List&lt;Integer&gt; list = Arrays.asList(1,2,3,4,5,6,7);int sum = list.stream().map(x -&gt; x*x).reduce((x,y) -&gt; x + y).get();System.out.println(sum); findAny12345 Optional&lt;A&gt; optional = list().stream().filter(e -&gt; (e.getType() == tag.getType())).findAny();if (!optional.isPresent()) &#123; &#125; collect12tagList = list.parallelStream().filter(e -&gt;e.getType() == tag.getType() ).collect(Collectors.toList()); map1List&lt;String&gt; list = tagList.stream().map(Tag::getValue).collect(Collectors.toList()); limit123456789Stream.iterate(0, i -&gt; i + 1).limit(tagList.size()).forEach( i -&gt; &#123; if (i == 0) &#123; &#125; else &#123; &#125; if (i == (tagList.size() - 1)) &#123; &#125; &#125; ); forEach123tagList().forEach(e -&gt; &#123; parse(e);&#125;); comparing1list.sort(Comparator.comparing(e -&gt; e.getPriority())); parallelStream12345public Ele getEle() &#123; return ist().parallelStream() .filter(e -&gt; Objects.equals("", "")) .findAny().orElse(null); &#125; of12345Stream.of("张三","李四","王二","张四五") .filter(x -&gt; x.startsWith("张")) .mapToInt(String::length) .max() .ifPresent(System.out::println);]]></content>
      <categories>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>Lambda</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ElasticSearch基本操作]]></title>
    <url>%2Fposts%2F278%2F</url>
    <content type="text"><![CDATA[Dochttps://docs.spring.io/spring-data/elasticsearch/docs/current/reference/html/ 聚合去重http://192.168.1.100:9200/a-b/a_b/_search 123456789101112&#123; &quot;from&quot;: 0, &quot;size&quot;: 0, &quot;aggregations&quot;: &#123; &quot;field1&quot;: &#123; &quot;terms&quot;: &#123; &quot;field&quot;: &quot;xx&quot;, &quot;size&quot;: 21474837 &#125; &#125; &#125; &#125;]]></content>
      <categories>
        <category>架构</category>
      </categories>
      <tags>
        <tag>ElasticSearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[List利用Comparator进行Sort]]></title>
    <url>%2Fposts%2F50004%2F</url>
    <content type="text"><![CDATA[代码123456789101112131415161718public static void main(String[] args) &#123; List&lt;Integer&gt; a = new ArrayList(10); a.add(1); a.add(4); a.add(2); a.add(5); a.add(3); Collections.sort(a, new Comparator&lt;Integer&gt;() &#123; @Override public int compare(Integer o1, Integer o2) &#123; return o2 - o1;//倒叙 &#125; &#125;); a.stream().forEach(x -&gt; System.out.println(x));&#125; 输出： 1234554321 分析Comparator 比较器 java.util包 接口 用于排序和分组 常用于数组和列表 Arrays.sort(T[],Comparator&lt;? super T&gt; c) Collections.sort(List list,Comparator&lt;? super T&gt; c) 原理List.java 123456789default void sort(Comparator&lt;? super E&gt; c) &#123; Object[] a = this.toArray(); Arrays.sort(a, (Comparator) c); ListIterator&lt;E&gt; i = this.listIterator(); for (Object e : a) &#123; i.next(); i.set((E) e); &#125;&#125; 调用List默认接口实现 实际调用Arrays.sort(a, (Comparator) c); Arrays.java 12345678910public static &lt;T&gt; void sort(T[] a, Comparator&lt;? super T&gt; c) &#123; if (c == null) &#123; sort(a); &#125; else &#123; if (LegacyMergeSort.userRequested) legacyMergeSort(a, c); else TimSort.sort(a, 0, a.length, c, null, 0, 0); &#125;&#125; LegacyMergeSort归并排序，默认不使用 TimSort利用合并和插入排序 指定Comparator逆序1Collections.sort(result, Collections.reverseOrder()); 源码 1234567891011121314151617181920212223public static &lt;T&gt; Comparator&lt;T&gt; reverseOrder() &#123; return (Comparator&lt;T&gt;) ReverseComparator.REVERSE_ORDER;&#125;private static class ReverseComparator implements Comparator&lt;Comparable&lt;Object&gt;&gt;, Serializable &#123; private static final long serialVersionUID = 7207038068494060240L; static final ReverseComparator REVERSE_ORDER = new ReverseComparator(); //逆序 public int compare(Comparable&lt;Object&gt; c1, Comparable&lt;Object&gt; c2) &#123; return c2.compareTo(c1); &#125; private Object readResolve() &#123; return Collections.reverseOrder(); &#125; @Override public Comparator&lt;Comparable&lt;Object&gt;&gt; reversed() &#123; return Comparator.naturalOrder(); &#125;&#125;]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Comparator</tag>
        <tag>List</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[IDEA基本配置]]></title>
    <url>%2Fposts%2F49684%2F</url>
    <content type="text"><![CDATA[IDEA通用插件安装Alibaba Java Code Guidelines Preferences &gt;&gt; Plugins &gt;&gt; Marketplace 查询Alibaba Java Code Guidelines并安装后重启 Git Flow Integrationgit flow集成 GitToolBox行代码给与log历史提示 类的注释格式 Preferences &gt;&gt; Editor &gt;&gt; File and Code Templates &gt;&gt; Includes &gt;&gt; File Header 12345/*** @author: Perkins* @date: $&#123;DATE&#125;* @description: todo*/ lombok IDEA插件查询lombok并安装 pom 123456&lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;version&gt;1.16.18&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt;&lt;/dependency&gt; 代码使用注解@Data，@Log]]></content>
      <categories>
        <category>工具利器</category>
      </categories>
      <tags>
        <tag>IDEA</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Maven基本操作]]></title>
    <url>%2Fposts%2F725%2F</url>
    <content type="text"><![CDATA[Maven环境变量配置 创建文件 123cd ~touch .bash_profileopen -e .bash_profile 写入bash_profile 12345M2_HOME=/Users/work/apache-maven-3.5.0/PATH=$M2_HOME/bin:$PATHexport M2_HOMEexport PATH 执行 1source .bash_profile 测试 1mvn -v 安装jar和源码至本地仓库 jarmvn install:install-file -Dfile=/Users/xx-1.0.1.jar -DgroupId=xx -DartifactId=xx -Dversion=1.0.1 -Dpackaging=jar sourcemvn install:install-file -Dfile=/Users/xx-1.0.1-sources.jar -DgroupId=xx -DartifactId=xx -Dversion=1.0.1 -Dpackaging=jar -Dclassifier=sources scope12345&lt;dependency&gt; &lt;groupId&gt;xx.xx.xx&lt;/groupId&gt; &lt;artifactId&gt;xx-xx&lt;/artifactId&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; 值 说明 provided 打包时不包含，认为容器会提供 compile 默认，在编译、测试和打包阶段均有效 runtime 跳过编译，直接参与运行和测试 test 依赖性参与测试工作，包括测试代码的编译和运行，例如junit system 包来自本地系统文件 打包命令 值 说明 package 测试、打包 install 测试、打包并安装至本地仓库 deploy 测试、打包并安装至本地仓库，且上传至Maven中央服务器]]></content>
      <categories>
        <category>工具利器</category>
      </categories>
      <tags>
        <tag>Maven</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mac下用iterm2免密码]]></title>
    <url>%2Fposts%2F49300%2F</url>
    <content type="text"><![CDATA[安装Homebrew1/usr/bin/ruby -e "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)" 安装sshpass123brew install http://git.io/sshpass.rbwhich sshpass 输出/usr/local/bin/sshpass Item2配置1/usr/local/bin/sshpass -p 123456 ssh -p22 root@192.168.1.41 操作先用本地终端连接第一次，再用item2]]></content>
      <categories>
        <category>工具利器</category>
      </categories>
      <tags>
        <tag>iterm2</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS7安装部署 - Redis]]></title>
    <url>%2Fposts%2F85%2F</url>
    <content type="text"><![CDATA[redis 拉取 1wget http://download.redis.io/releases/redis-3.2.6.tar.gz 解压 1tar -zxvf redis-3.2.6.tar.gz 编译 12cd redis-3.2.6make 修改数据目录vi redis.conf 1234567891011121314#指定日志目录logfile /root/data/soft/redis-3.2.6/data/logs/redis.log#指定数据目录dir /root/data/soft/redis-3.2.6/data#修改后台启动daemonize yes#允许外网访问protected-mode no #允许ip访问#bind 127.0.0.1#修改绑定端口port 6380#密码访问requirepass root123 启动 123cd redis-3.2.6/src #启动./redis-server ../redis.conf 测试 1234./redis-cli -p 6380dbsizeflushallexit 客户端安装Redis Desktop Manager输入连接ip、端口、密码]]></content>
      <categories>
        <category>安装部署</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS7安装部署 - MongoDB]]></title>
    <url>%2Fposts%2F277%2F</url>
    <content type="text"><![CDATA[mogo 下载12345wget https://fastdl.mongodb.org/linux/mongodb-linux-x86_64-rhel70-4.0.6.tgz ./tar xzvf mongodb-linux-x86_64-rhel70-4.0.6.tgzmkdir -p data/mongo_data data/logs 配置 1234567891011121314touch mongo.conf#数据目录dbpath=/home/admin/soft/mongodb/data/mongo_datalogpath=/home/admin/soft/mongodb/data/logs/mongo.log#后台允许fork=truequiet=truejournal=truelogappend=true#可以外网访问bind_ip=0.0.0.0#修改端口port=27018 启动： 1/bin/mongod -f mongo.conf 创建管理员 123456789mongo localhost:27018&gt;use admin db.createUser( &#123; user: "root", pwd: "root123", roles: [ &#123; role: "userAdminAnyDatabase", db: "admin" &#125;, "readWriteAnyDatabase" ] &#125; ) exit 开启权限vi /etc/mongod.conf 123#security security: authorization: enabled 重启mongodb： 12pkill mongod/bin/mongod -f mongo.conf 安装GUI 123456789#先安装nodebrew install nodegit clone https://github.com/mrvautin/adminMongo cd adminMongonpm installnpm start#测试地址：http://127.0.0.1:1234 后台进程 1234#指定name启动pm2 start app.js --name adminMongo#删除pm2 delete adminMongo GUI连接打开http://127.0.0.1:1234地址：mongodb://root:root123@192.168.1.41:27018/admin pm21234567npm install pm2 -gpm2 listpm2 restartpm2 monitpm2 start app.js --name adminMongopm2 delete adminMongoMon 安装service 12yum list | grep initscriptsyum install initscripts -y docker不能启动问题Failed to get D-Bus connection: Operation not permitted解决： 1docker run -d -it --privileged ContainerId /usr/sbin/init]]></content>
      <categories>
        <category>安装部署</category>
      </categories>
      <tags>
        <tag>MongoDB</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Centos7安装部署 - MySQL]]></title>
    <url>%2Fposts%2F21810%2F</url>
    <content type="text"><![CDATA[mysql5.7 下载并安装源123wget 'https://dev.mysql.com/get/mysql57-community-release-el7-11.noarch.rpm'sudo rpm -Uvh mysql57-community-release-el7-11.noarch.rpmyum repolist all | grep mysql 安装 1sudo yum install mysql-community-server 更改数据目录 123456789chown -R mysql:mysql /root/data/soft/mysql vi /etc/my.cnf#修改数据目录#datadir=/var/lib/mysql#socket=/var/lib/mysql/mysql.sockdatadir=/root/data/soft/mysqlsocket=/root/data/soft/mysql/mysql.sock 启动 123456789service mysqld start#查看错误日志tail -200 /var/log/mysqld.log#因为修改了目录 需要再初始化cd /root/data/soft/mysqlrm -rf *chown -R mysql:mysql .mysqld --initialize --user=mysql --consoleservice mysqld start 登录和修改密码 12345678#获取密码grep 'temporary password' /var/log/mysqld.logmysql -uroot -P3308 -p select @@log_error;set password for 'root'@'localhost'=password('root@123'); 授权登录 12GRANT ALL PRIVILEGES ON *.* TO 'root'@'%' IDENTIFIED BY 'root@123' WITH GRANT OPTION;FLUSH PRIVILEGES; 客户端workbench 解决中文乱码 123set global character_set_server=utf8;set global character_set_database=utf8;show variables like '%char%';]]></content>
      <categories>
        <category>安装部署</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java并发编程艺术 - 多线程]]></title>
    <url>%2Fposts%2F24227%2F</url>
    <content type="text"><![CDATA[启动Java应用程序则是一个进程，一个进程可以启动多个线程，线程是操作系统调度最小单元。线程拥有独立的计数器、栈和局部变量，可以共享堆内存。 一个Java程序入口是main主线程，线程优先级从1-10，优先级越高分配时间片越长。 为什么使用多线程 更多的处理器核心 使用多线程技术，将计算逻辑分配到多个处理器核心上，就会显著减少程序的处理时间，并且随着更多处理器核心的加入而变得更有效率。 更快的响应时间 使用多线程技术，即将数据一致性不强的操作派发给其他线程处理（也可以使用消息队列），如生成订单快照、发送邮件等。这样做的好处是响应用户请求的线程能够尽可能快地处理完成，缩短了响应时间，提升了用户体验。 更好的编程模型 Java为多线程编程提供了良好、考究并且一致的编程模型，使开发人员能够更加专注于问题的解决，即为所遇到的问题建立合适的模型，而不是绞尽脑汁地考虑如何将其多线程化。一旦开发人员建立好了模型，稍做修改总是能够方便地映射到Java提供的多线程编程模型上。 线程状态 NEW 新建 Thread.start(); RUNNABLE 运行，包括就绪和运行 Thread.run(); BLOCKED 阻塞 synchronized WAITING 等待，等待其他线程通知和中断 Object.wait() Object.join() LockSupport.park(Thread) TIME_WAITTING 等待，等待指定时间超时 Thread.sleep(long) Object.wait(long) Object.join(long) LockSupport.parkNanos() LockSupport.parkUntil() TERMINATED 终止 interrupt(),isInterrupted()和interrupted() suspend()、resume()和stop()线程在自身的生命周期中，并不是固定地处于某个状态，而是随着代码的执行在不同的状态之间进行切换 线程创建之后，调用start()方法开始运行。 当线程执行wait()方法之后，线程进入等待状态。 进入等待状态的线程需要依靠其他线程的通知才能够返回到运行状态 而超时等待状态相当于在等待状态的基础上增加了超时限制，也就是超时时间到达时将会返回到运行状态。 当线程调用同步方法时，在没有获取到锁的情况下，线程将会进入到阻塞状态。 线程在执行Runnable的run()方法之后将会进入到终止状态。 Java将操作系统中的运行和就绪两个状态合并称为运行状态。 阻塞状态是线程阻塞在进入synchronized关键字修饰的方法或代码块（获取锁）时的状态。 但是阻塞在java.concurrent包中Lock接口的线程状态却是等待状态，因为java.concurrent包中Lock接口对于阻塞的实现均使用了LockSupport类中的相关方法。 线程优先级123Thread thread = new Thread(job, "Thread:" + i);thread.setPriority(priority);thread.start(); 在Java线程中，通过一个整型成员变量priority来控制优先级，优先级的范围从1~10，在线程构建的时候可以通过setPriority(int)方法来修改优先级，默认优先级是5，优先级高的线程分配时间片的数量要多于优先级低的线程。 设置线程优先级时，针对频繁阻塞（休眠或者I/O操作）的线程需要设置较高优先级，而偏重计算（需要较多CPU时间或者偏运算）的线程则设置较低的优先级，确保处理器不会被独占。在不同的JVM以及操作系统上，线程规划会存在差异，有些操作系统甚至会忽略对线程优先级的设定。 线程优先级不能作为程序正确性的依赖，因为操作系统可以完全不用理会Java线程对于优先级的设定。 Daemon线程守护线程，为非Daemon线程提供后台调度和服务，例如GC线程。 123Thread thread = new Thread(new DaemonRunner(), "DaemonRunner");thread.setDaemon(true);thread.start(); Daemon线程是一种支持型线程，因为它主要被用作程序中后台调度以及支持性工作。这意味着，当一个Java虚拟机中不存在非Daemon线程的时候，Java虚拟机将会退出。可以通过调用Thread.setDaemon(true)将线程设置为Daemon线程。 Daemon属性需要在启动线程之前设置，不能在启动线程之后设置。 线程中断其他线程调用该线程的interrupt()方法进行中断，线程本身调用isInterrupted(()判断是否中断，也可以调用Thread.interrupted()对当前线程的中断标识位进行复位。 123456789101112131415161718192021222324252627282930313233343536373839404142public class Thread2 &#123; public static void main(String[] args) throws Exception &#123; Runner one = new Runner(); Thread countThread = new Thread(one, "CountThread1"); countThread.start(); // 睡眠1秒，main线程对CountThread进行中断，使CountThread能够感知中断而结束 TimeUnit.SECONDS.sleep(1); countThread.interrupt(); Runner two = new Runner(); countThread = new Thread(two, "CountThread2"); countThread.start(); // 睡眠1秒，main线程对Runner two进行取消，使CountThread能够感知on为false而结束 TimeUnit.SECONDS.sleep(1); two.cancel(); &#125; private static class Runner implements Runnable &#123; private long i; private volatile boolean on = true; @Override public void run() &#123; while (on &amp;&amp; !Thread.currentThread().isInterrupted()) &#123; try &#123; i++; Thread.sleep(100); &#125; catch (InterruptedException e) &#123; Thread.currentThread().interrupt();//重新设置中断标示 &#125; &#125; System.out.println("Count i = " + i + ",Name:" + Thread.currentThread().getName()); &#125; public void cancel() &#123; on = false; &#125; &#125;&#125; 线程等待和通知 notify() 随机通知在对象上等待的另一个线程，使其在wait()状态上尝试获取锁，如获取锁成功则返回 notifyAll() 通知在对象上等待的所有线程，竞争锁 wait() 进入WAITING状态，等待通知或中断，会释放锁 wait(long) 进入TIME_WAITTING状态，等待超时 join() 进入WAITING状态，等待其他线程终止后返回，不释放锁 join(long) 进入TIME_WAITTING状态，等待其他线程终止后返回，不释放锁]]></content>
      <categories>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>Java并发编程</tag>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java并发编程艺术 - 延迟加载与双重检查锁定double check lock]]></title>
    <url>%2Fposts%2F31866%2F</url>
    <content type="text"><![CDATA[类延迟初始化常采用单例模式。 方法1： 12345678910public class Singleton &#123; private static Singleton singleton = null; public static Singleton getInstance() &#123; if (singleton == null) &#123;//1 singleton=new Singleton();//2 &#125; return singleton; &#125;&#125; 多线程中，步骤1可以同步执行，导致步骤2多次执行。 方法2： 12345678910public class Singleton &#123; private static Singleton singleton = null; public static synchronized Singleton getInstance() &#123; if (singleton == null) &#123;//1 singleton=new Singleton();//2 &#125; return singleton; &#125;&#125; 多线程中，singleton只会实例一次，但每次获取getInstance都会加锁导致性能下降。 方法3： 12345678910111213141516public class Singleton &#123; private static Singleton singleton = null; public static Singleton getInstance() &#123; //one check if (singleton == null) &#123;//1 synchronized (Singleton.class) &#123;//2 //two check if (singleton == null) &#123;//3 singleton = new Singleton();//4 &#125; &#125; &#125; return singleton; &#125;&#125; 步骤4分解为3条指令执行，包括1-先分配内存，2-标记对象指向内存地址，3-初始化构造；如果指令12重排导致先赋值，多线程并发中步骤1不为null，但获取的singleton仍未初始化。 方法4： 1234567891011121314151617public class Singleton &#123; //防止重排 private volatile static Singleton singleton = null;//5 public static Singleton getInstance() &#123; //one check if (singleton == null) &#123;//1 synchronized (Singleton.class) &#123;//2 //two check if (singleton == null) &#123;//3 singleton = new Singleton();//4 &#125; &#125; &#125; return singleton; &#125;&#125; 步骤5使用volatile防止指令重排，是标准的DCL实例方案。 方法5： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public class Singleton implements Serializable&#123;//序列化 //防止重排 private volatile static Singleton singleton = null;//5 private static boolean flag = false; private Singleton() &#123;//6 //防止反射漏洞 synchronized (Singleton.class) &#123; if (flag) &#123; System.out.println("init twice"); &#125; else &#123; flag = true; System.out.println("init once"); &#125; &#125; &#125; public static Singleton getInstance() &#123; //one check if (singleton == null) &#123;//1 synchronized (Singleton.class) &#123;//2 //two check if (singleton == null) &#123;//3 singleton = new Singleton();//4 &#125; &#125; &#125; return singleton; &#125; //防止反序列化漏洞，替换反序列化对象 private Object readResolve() &#123; return singleton; &#125; public static void main(String[] args) throws Exception &#123; Class&lt;Singleton&gt; clazz = (Class&lt;Singleton&gt;) Class.forName("Singleton"); Constructor&lt;Singleton&gt; singletonConstructor = clazz.getDeclaredConstructor(null); singletonConstructor.setAccessible(true);//反射打开访问权限 Singleton singleton = singletonConstructor.newInstance();//第一次实例化 singleton.say(); System.out.println(singleton); singleton = singletonConstructor.newInstance();//第二次实例化 singleton.say(); &#125;&#125; 步骤6对构造函数进行私有化，防止多次被实例化；同时，为防止反射多次实例，使用全局变量flag；也支持单例模式的序列化和反序列化。在执行类的初始化期间，JVM会去获取一个锁。这个锁可以同步多个线程对同一个类的初始化。 方法6： 1234567891011public class Singleton &#123; private static Singleton singleton = null; private static class SingletonFactory &#123; public static Singleton singleton2 = new Singleton(); &#125; public static Singleton getInstance() &#123; return SingletonFactory.singleton2; &#125;&#125; 利用类加载机制来实现，延迟初始化,类加载分为加载-&gt;验证-&gt;准备-&gt;解析-&gt;初始化-&gt;使用-&gt;卸载等步骤，Java中当类的静态域或静态方法被引用的时候，必须对声明这个静态域或方法的类进行初始化。 方法7： 123456789101112public enum SingletonEnum &#123; INSTANCE_ENUM; DataSource dataSource; private SingletonEnum() &#123; dataSource = null; &#125; public DataSource getDataSource() &#123; return dataSource; &#125;&#125; 利用枚举类实现单例模式。SingletonEnum会被编译成public final class SingletonEnum extends Enum，INSTANCE_ENUM会编译成public static final SingletonEnum INSTANCE_ENUM，根据类加载机制，初始化是线程安全的；同时，枚举序列化和反序列化禁止writeObject、readObject，不采用反射而是根据name属性和valueOf方法，防止破坏单例。]]></content>
      <categories>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>Java并发编程</tag>
        <tag>单例模式</tag>
        <tag>双重检测锁定</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java并发编程艺术 - 重排序]]></title>
    <url>%2Fposts%2F35014%2F</url>
    <content type="text"><![CDATA[重排序是编译器和处理器为优化程序性能而对指令进行重新排序的手段。 数据依赖性 写后写;a=1,a=2 写后读;a=1,b=a 读后写;a=b,b=1 以上三种情况存在数据依赖，重排将会引起结果改变。 as-if-serial不管怎么重排序，但不能影响结果，编译器、runtime和处理器都必须遵守这个语义，即可以对不存在数据依赖关系的指令进行重排。 例如 123int a=1;//操作1int b=2;//操作2int c=a+b;//操作3 以上操作1和2可以重排。 重排对多线程的影响1234567891011121314class ReorderExample &#123; int a = 0; boolean flag = false; public void writer() &#123; a = 1; // 1 flag = true; // 2 &#125; public void reader() &#123; if (flag) &#123; // 3 int i = a * a; // 4 …… &#125; &#125;&#125; 在多线程开发中： 如果线程1对操作1和2进行重排，线程2执行reader的操作3时，变量a可能没有及时同步，结果可能为0而不是1。 如果线程1对操作3和4进行重排，先将操作4结果暂存缓存，等待操作3决定是否缓存写入i；在单线程没有问题，但多线程操作3可能会被改变。 因此，多线程开发需要考虑程序执行的顺序性，可以采用同步原语，包括valatile、synchronized和final。]]></content>
      <categories>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>Java并发编程</tag>
        <tag>重排序</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java并发编程艺术 - Java内存模型基础]]></title>
    <url>%2Fposts%2F49164%2F</url>
    <content type="text"><![CDATA[并发编程的两个关键性问题 线程通信 线程同步 线程通信 通信是指线程间的信息交换，主要有两种：共享内存和消息传递。 共享内存是线程利用内存的公共状态进行隐私通信。 在Java中主要利用堆内存变量实现共享内存，包括静态域、数据、实例。 12345678910111213141516public class ThreadShare &#123; //利用内存静态变量进行状态传递 static int num = 0; private void increase() &#123; num++; System.out.println(num); &#125; public static void main(String[] args) &#123; ThreadShare threadShare = new ThreadShare(); new Thread(threadShare::increase).start(); new Thread(threadShare::increase).start(); &#125;&#125; 消息传递是利用管道消息进行显示通信。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364public class Consumer implements Runnable &#123; private PipedInputStream pis; public Consumer(PipedInputStream pis) &#123; this.pis = pis; &#125; @Override public void run() &#123; // 将数据保存在byte数组中 byte[] bytes = new byte[100]; try &#123; // 从数组中得到实际大小。 int length = pis.read(bytes); System.out.println(new String(bytes, 0, length)); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; finally &#123; try &#123; pis.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125;public class Producer implements Runnable &#123; private PipedOutputStream pos; public Producer(PipedOutputStream pos) &#123; this.pos = pos; &#125; @Override public void run() &#123; try &#123; pos.write("Hello World".getBytes()); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; finally &#123; try &#123; pos.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125;public class TestPipedStream &#123; public static void main(String[] args) &#123; PipedOutputStream pos = new PipedOutputStream(); PipedInputStream pis = new PipedInputStream(); try &#123; // 连接管道 pos.connect(pis); new Thread(new Producer(pos)).start(); new Thread(new Consumer(pis)).start(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 线程同步 在共享内存中必须显式指定某个方法或代码段进行线程互斥，在消息传递中隐式说明消息接收需在消息发送前。 互斥锁主要有Lock，synchronized。 JMM内存结构线程AB间要通信，需要经过两步： A将共享变量X的本地内存刷新到主存 B到主存更新本地内存的共享变量X 实质上是线程A在向线程B发送消息，而且这个通信过程必须要经过主内存。 JMM通过控制主内存与每个线程的本地内存之间的交互，提供内存可见性保证。 指令重排执行程序为提高性能，编译器和处理器会进行指令重排，主要有3种。 编译器在不影响单线程结果的前提下，进行指令重排。 指令并行重排。多条指令不存在数据依赖性，处理器可以改变机器指令执行顺序。 内存重排。处理器使用缓存和读写缓冲区进行加载和存储。 JMM通过插入内存屏障防止指令重排。 happens-beforeJMM中，如果一个操作执行结果需要对另一个操作可见，两个操作需要存在happens-before关系。 该两个操作可以是一个线程也可以是不同线程。 happens-before规则如下： 程序顺序规则：一个线程每个操作，happens-before线程后续操作 监视器锁规则：一个监视器锁的解锁，happens-before锁的加锁 volatile变量规则：一个volatile的写，happens-before任意对此域的读 传递性：如果A happens-before B，且B happens-before C，那么A happens-before C 两个操作存在happens-before关系，并不意味着一个操作必须在另一个之前，而是第一个操作的结果对第二个可见。]]></content>
      <categories>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>Java并发编程</tag>
        <tag>Java内存模型</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java并发编程艺术 - 原子性及CAS使用和原理]]></title>
    <url>%2Fposts%2F28363%2F</url>
    <content type="text"><![CDATA[原子性处理器保障从系统内存中读取和写入字节是原子的，即其他处理器不能访问该字节地址。 总线锁保障原子性处理器发出Lock#信号到总线上，其他处理器阻塞，该处理器独享内存。 缓存锁保障原子性总线锁把CPU和内存通信锁住，其他CPU无法访问其他内存地址，开销较大。 可以在缓存中，锁定内存地址，保障原子性。 缓存锁定缓存行时，回写内存不声明LOCK#，而是修改内部内存地址，同时通过缓存一致性阻止其他处理器修改；当其他处理器回写，将会无效缓存行，从内存重新加载数据。 JAVA实现原子操作通过锁实现原子操作锁机制保障只有获取锁的线程才能操作内存区域，常见的JVM锁有偏向锁、轻量锁和互斥锁。 除偏向锁外，其他锁实现都采用CAS进行锁的获取和释放。 通过CAS实现原子操作CAS通过Compare And Swap可以实现原子操作；原子操作即不能被进一步分割的最小粒子。 CAS需要输入两个参数，old值和expect值；若old值未发生变化，则替换old为expect，否则不交换。实际上是三个参数，第三个参数无需输入，可使用局部变量或者由操作指令维护，是old的origin值，用于和输入的old比较。 JVM中的CAS操作正是利用了处理器的CMPXCHG指令实现，自旋CAS实现的就是循环CAS直到成功。 从Java 1.5开始，JDK的JUC包里提供了原子操作，如AtomicBoolean（用原子方式更新的boolean值）、AtomicInteger（用原子方式更新的int值）和AtomicLong（用原子方式更新的long值）。这些原子包装类还提供了以原子的方式将当前值自增1和自减1。 CAS产生的问题ABA问题假如old和expect值相同，虽然交换了，但结果貌似没有变化，而且也不知道是否真的交换成功。 因此需要引入版本号，假如每次交换后版本加1，则可以明显确定是否交换成功，例如AtomicStampedReference。 长时间自旋如果长时间CAS自旋失败，则浪费CPU。 可以提供暂停操作，实现自旋延迟效果。 只能支持单个变量的原子性多个变量原子性操作通常需要用锁，或者采用把多个共享变量合并成一个共享变量。 AtomicReference支持对象的原子性，可以将多个变量放在一个对象中进行CAS。]]></content>
      <categories>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>Java并发编程</tag>
        <tag>CAS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java并发编程艺术 - synchronized使用和原理]]></title>
    <url>%2Fposts%2F43888%2F</url>
    <content type="text"><![CDATA[synchronized属于重量级锁，实现代码同步。 Java SE1.6优化引入了偏向锁和轻量级锁，同时支持锁升级，以减少获取锁和释放锁的性能消耗。 锁的对象synchronized可以修饰Java非空对象，常见3种形式： 锁当前实例修饰普通方法，例如: 12synchronized void add()&#123;&#125; 那么该对象实例将会在执行该方法时阻塞，以保持同步执行，不可并行执行；但是不同对象可以并行执行。 锁类所以对象修饰静态方法、全局变量、类，例如: 12synchronized static void add()&#123;&#125; 12synchronized (Singleton.class)&#123;&#125; 该类所有操作及类实例均会在执行时阻塞，以保持同步执行，不同对象也不可并行执行。 锁方法块 修饰实例或变量 12synchronized (this) &#123;&#125; 12synchronized (var) &#123;&#125; 该类所有操作及类实例均会在执行该代码块时阻塞，以保持同步执行，不同对象也不可并行执行；但对其他代码块不产生影响。 锁的实现synchronized由JVM实现，通过在代码块前后添加monitorenter和monitorexit指令。 线程执行到monitorenter尝试获取对象对应的monitor，即对象锁；如持有monitor锁，则对象处于锁定状态。 Java对象头synchronized锁信息存储在对象头中。 对象头包含Mark Word，存储对象HashCode、分代年龄和锁状态。 锁状态包括轻量锁、重量锁、偏向锁和GC标记。 锁升级锁的4种状态，由低到高： 无锁 偏向锁 轻量锁 重量锁 锁因为竞争可以由低到高升级，不可由高到低降级，以提高锁获取和释放效率。 偏向锁大多数情况，锁是同一线程多次获取，因此引入偏向锁。 在线程获取锁后，在对象头和栈帧中记录线程ID；后续该线程进入和退出代码同步块时不需要CAS获取和释放锁。 偏向锁释放当出现线程竞争偏向锁时，持有偏向锁的线程需要释放偏向锁。 释放偏向锁时，需要等待安全点，即该线程没有正在执行的字节码。 然后暂停拥有偏向锁的线程，若该线程处于不活动状态，将对象头设置为无锁状态；若活着，则重新偏向其他线程。 偏向锁优化偏向锁在程序启动后会延迟激活，-XX:BiasedLockingStartupDelay=0可以关闭延迟。 如果程序通常处于竞争状态，可以通过-XX:-UseBiasedLocking=false关闭偏向锁，那么程序默认会进入轻量级锁状态。 轻量锁轻量锁加锁JVM在执行同步代码块前，先在线程栈帧创建锁记录空间，并将对象头Mark Word复制到锁记录空间。 线程通过CAS将对象头的Mark Word替换为锁记录空间地址；若成功，则获取锁成功。 如失败，则存在锁竞争，线程通过自旋来获取锁。 轻量锁解锁在解锁时，线程采用CAS将锁记录空间信息替换回对象头的Mark Word；若成功，则释放锁。 若失败，则说明存在锁竞争，则升级为重量级锁。 重量锁因为自旋需要消耗CPU，所以轻量锁升级到重量锁后不能降级。 处于重量级锁状态，其他线程获取锁将被阻塞，指导当前线程释放锁并唤醒其他线程竞争。 锁比较 锁 优点 缺点 说明 偏向锁 速度快，和非同步方法执行效率差不多 出现锁竞争时，需要额外释放锁 适合一个线程并发访问同步块 轻量锁 无阻塞，响应速度快 始终得不到锁的线程会自旋消耗CPU 适合方法块执行块，追求响应速度 重量级锁 无自旋，不消耗CPU 阻塞，响应慢 适合同步块执行慢，追求吞吐量]]></content>
      <categories>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>Java并发编程</tag>
        <tag>synchronized</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java并发编程艺术 - volatile使用和原理]]></title>
    <url>%2Fposts%2F34733%2F</url>
    <content type="text"><![CDATA[Java代码经过Java编译器编译成字节码，并由类加载器加载到JVM运行时数据区，最终由JVM执行引擎执行字节码，转换为汇编指令在CPU内执行。 Java并发机制主要依赖JVM实现和CPU指令。 volatilevolatile修饰变量，提供多处理器并发中共享变量的可见性，是轻量的synchronized。 volatile由CPU指令实现，不会引起上下文切换，性能比synchronized高。 可见性问题可见性问题是受Java内存模型的影响。 从上图可知，多线程对共享变量在本地内存进行处理，虽然提高执行效率，但是将带来可见性和数据同步问题。 多线程编程中，对于volatile共享变量，一个线程进行了修改，对于其他线程能及时读取修改后的值，以做到资源同步。 volatile定义如果一个变量被声明为volatile，那么该变量在多线程中将互相可见，保障准确和一致性。 内存屏障/内存栅栏一系列CPU指令，控制内存操作的顺序，可以解决指令重排和可见性问题。 其中，指令重排是JIT对代码的优化。 内存屏障插入策略： 在volatile写前插入storestore，禁止上面普通写与volatile写重排 在volatile写后插入storeload，禁止下面volatile读/写与volatile写重排 在volatile读后插入loadload，禁止下面普通读与volatile写读重排 在volatile读后插入loadstore，禁止下面普通写与volatile读重排 volatile实现原理在共享变量写前，CPU新增Lock操作指令，实现以下效果： 将当期缓存行回写系统内存 其他CPU缓存该内存地址数据无效 为提高处理速度，CPU不和主存直接交互，而是将主存数据读取到缓存，但缓存写回内存时间未知。 通过volatile将通过Lock指令实现写回操作，其他处理器通过总线检查缓存值是否过期；若发现缓存行地址变更，则将缓存行置为无效。 当处理器处理数据时，发现无效标志则会从主存中重新加载数据至缓存。 说明 Lock前缀指令会引起处理器缓存写回内存。Lock可以锁定缓存区域，实现原子操作。 处理器缓存写回操作将引起其他处理的该缓存无效。处理器嗅探缓存地址，若处于共享状态，无效缓存行后，下次访问进行强制缓存行填充。 volatile优化 JDK7追加64字节能够提高LinkedTransferQueue并发编程的效率 缓存的最小单位是缓存行，常见CPU的缓存行是64字节宽(8字节)，不支持部分缓存行。 不满64字节，则缓存队列头和尾至同一缓存行。 当CPU修改头节点，需要锁定缓存行，导致其他CPU不能处理缓存，影响队列入队和出队效率。 追加至64位，填满缓存行，避免队列的头和尾节点被同一缓存行同时锁定。 volatile使用12345678910111213141516171819202122232425262728293031323334public class VolatileTest &#123; //原子变量，缓存无效直接取主存 private volatile int num = 0; //检测值变化 private void test() &#123; while (true) &#123; //测试在一行代码中，num是否会有多个值情况 if (num == 1 &amp;&amp; num == 2 &amp;&amp; num == 3) &#123; System.out.println("不一致"); &#125; &#125; &#125; //修改值 private void change() &#123; while (true) &#123; //频繁修改num值 for (int i = 0; i &lt; 4; i++) &#123; num = i; &#125; &#125; &#125; public void start() &#123; new Thread(this::test).start(); new Thread(this::change).start(); &#125; public static void main(String[] args) &#123; new VolatileTest().start(); &#125;&#125; 结果频繁出现：不一致若不使用volatile，因为线程执行速度快，偶尔会出现不一致但不频繁说明volatile可以实时同步各线程共享变量 volatile修饰用法 volatile 基本变量int\boolean等，例如volatile int a=1；保障可见性 volatile 对象，例如volatile Singleton singleton；防止指令重排 注意 volatile保障变量在线程间的可见性，但不保障操作原子性]]></content>
      <categories>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>Java并发编程</tag>
        <tag>volatile</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Cloud - 如何利用Zuul实现接口限流]]></title>
    <url>%2Fposts%2F33184%2F</url>
    <content type="text"><![CDATA[以下为Zuul利用ratelimit在网关进行接口限流。 限流方案 方案 说明 基于用户id 根据用户标识或匿名 基于用户角色 根据用户角色 基于用户源IP 请求源IP 基于请求URL 下游服务地址 基于请求方法类型 HTTP请求方法，GET、POST等 基于请求服务 下游服务 POM引入123456&lt;!-- 请求限流 --&gt;&lt;dependency&gt; &lt;groupId&gt;com.marcosbarbero.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-zuul-ratelimit&lt;/artifactId&gt; &lt;version&gt;2.0.4.RELEASE&lt;/version&gt;&lt;/dependency&gt; 参数配置1234567891011121314151617181920212223242526272829303132333435#60秒内允许10个访问，并且要求总请求时间小于1000秒#seviceA在120秒内允许20个访问，并且要求总请求时间小于2000秒#seviceA针对匿名用户，IP为10.10.10.10，角色为用户，请求URL为/api/，请求方法为GETzuul: ratelimit: key-prefix: your-prefix #缓存key的前缀 enabled: true #开启限流 repository: REDIS #key存储方式为redis behind-proxy: true # 当前网关是代理后的请求，需要获取Header中的X-FORWARDED-FOR以便获取源IP add-response-headers: true #在response header中添加限流信息 default-policy-list: # 默认策略 - limit: 10 #每个刷新窗口请求数 quota: 1000 #每个刷新窗口总请求时间(秒) refresh-interval: 60 #刷新窗口时间(秒),默认60秒 type: - user #基于用户标识，默认匿名anonymous - origin #基于用户IP - url #基于下游服务URL - httpmethod #基于请求方法 policy-list: #指定服务策略，优先默认 seviceA: #微服务ID - limit: 20 quota: 2000 refresh-interval: 120 type: - user - origin - url - type: #每种类型值设定 - user=anonymous #指定用户,匿名用户 - origin=10.10.10.10 #指定源URL - url=/api #指定下游请求URL前缀 - role=user #指定用户角色 - httpmethod=get #指定请求方法类型，大小写不敏感 其中，user=anonymous和role=user采用Shiro或者Spring Security进行维护，或者自定义request域UserPrincipal。 数据存储 InMemory(ConcurrentHashMap) Redis Consul Spring Data JPA JCache Infinispan Hazelcast Ignite 将会对服务集群的请求情况同步至选择的存储中，以做到数据共享和实时存储。 源码及原理分析自定义key1234567891011121314151617@Bean public RateLimitKeyGenerator ratelimitKeyGenerator(RateLimitProperties properties, RateLimitUtils rateLimitUtils) &#123; return new DefaultRateLimitKeyGenerator(properties, rateLimitUtils) &#123; @Override public String key(HttpServletRequest request, Route route, RateLimitProperties.Policy policy) &#123; //super.key()为默认实现 //keyPrefix+serviceId+(type1Key+...+typenKey) String key= super.key(request, route, policy) ; //":" + request.getMethod() 为自定义策略 key += ":" + request.getMethod(); //实现对key的重写，限流策略是以key为标识依据 return key; &#125; &#125;; &#125; 自定义错误12345678910111213141516171819@Bean public RateLimiterErrorHandler rateLimitErrorHandler() &#123; return new DefaultRateLimiterErrorHandler() &#123; @Override public void handleSaveError(String key, Exception e) &#123; // 处理存储key异常 &#125; @Override public void handleFetchError(String key, Exception e) &#123; // 处理查询key异常 &#125; @Override public void handleError(String msg, Exception e) &#123; // 处理异常信息 &#125; &#125; &#125; 自定义用户和角色SecuredRateLimitUtils.java 12345678@Overridepublic Set&lt;String&gt; getUserRoles() &#123; Authentication authentication = SecurityContextHolder.getContext().getAuthentication(); if (authentication == null) &#123; return emptySet(); &#125; return AuthorityUtils.authorityListToSet(authentication.getAuthorities());&#125; SecurityContextHolder为Spring Security框架，可获取用户角色和标识。 Spring Security样例如下： 12345678@Override protected void configure(AuthenticationManagerBuilder auth) throws Exception &#123; auth .inMemoryAuthentication() .withUser("user") .password("password") .roles("USER"); &#125;]]></content>
      <categories>
        <category>微服务</category>
      </categories>
      <tags>
        <tag>Spring Cloud</tag>
        <tag>Zuul</tag>
        <tag>ratelimit</tag>
        <tag>限流</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Cloud - 如何利用Zuul进行网关开发]]></title>
    <url>%2Fposts%2F33205%2F</url>
    <content type="text"><![CDATA[Zuul介绍Zuul是Spring Cloud全家桶一员，用于微服务网关开发，实现对外服务请求的白黑名单控制、代理转发、限流、权鉴认证、灰度测试等。 Zuul POM引入1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;!-- spring-boot版本 --&gt; &lt;version&gt;2.0.5.RELEASE&lt;/version&gt; &lt;relativePath/&gt;&lt;/parent&gt;&lt;properties&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;!-- Spring Cloud版本 --&gt; &lt;spring-cloud.version&gt;Finchley.RELEASE&lt;/spring-cloud.version&gt;&lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-ribbon&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-zuul&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.retry&lt;/groupId&gt; &lt;artifactId&gt;spring-retry&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;$&#123;spring-cloud.version&#125;&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt; 开启ZuulApplication.java 1234567891011//开启Zuul@EnableZuulProxy@EnableEurekaClient@SpringBootApplicationpublic class Application &#123; public static void main(String[] args) &#123; SpringApplication.run(Application.class,args); &#125;&#125; Zuul配置bootstrap.yml 1234567891011121314151617181920212223242526272829303132333435#路由方式是serviceIdribbon: #对所有操作请求都进行重试 OkToRetryOnAllOperations: true #切换实例的重试次数 MaxAutoRetriesNextServer: 2 #对当前实例的重试次数 MaxAutoRetries: 1 #请求链接的超时时间 ConnectTimeout: 6000 #请求处理的超时时间 ReadTimeout: 8000 eureka: enable: falsezuul: sensitive-headers: #自动重试 retryable: true routes: client-api: #过滤headers，不进入下游 sensitiveHeaders: Cookie,Set-Cookie,Authorization #服务名称 a: #转发匹配规则 path: /api/a/** #直接转发，不过滤前缀 stripPrefix: false #转发到服务ID serviceId: a-service b: path: /api/b/** stripPrefix: false serviceId: b-server Zuul开发在网关统一完成请求过滤和用户认证AccessFilter.java 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113@Component//实现ZuulFilterpublic class AccessFilter extends ZuulFilter &#123; //实现run逻辑 @Override public Object run() &#123; return exec(); &#125; private Object exec() &#123; RequestContext ctx = RequestContext.getCurrentContext(); //获取HttpServletRequest HttpServletRequest request = ctx.getRequest(); //解析ip String ip = getIpAddr(request); //补充到header，可以带入下游 ctx.addZuulRequestHeader("ip", ip); //接口的白名单和黑名单 String url = request.getRequestURI(); //白名单可以直接进入下游 if (isWhite(url)) &#123; return null; &#125; //黑名单禁止访问 if (isBlack(url)) &#123; setBlack(ctx, url); return null; &#125; //token解析 validToken(ctx, url); return null; &#125; /** * 获取用户id，检验token真实性 * * @param ctx * @param url * @return */ void validToken(RequestContext ctx, String url) &#123; // 获取请求的参数 String token = ctx.getRequest().getHeader(Constant.TOKEN); //解析token业务，获取用户信息 String userId = parseToken(token); //传入下游 ctx.addZuulRequestHeader("userId", userId); &#125; public static boolean setBlack(RequestContext ctx, String requestUrl) &#123; logger.error("无权限请求：&#123;&#125;", requestUrl); setStatus(ctx, EnumStatus.ERROR, false); return true; &#125; public static void setStatus(RequestContext ctx, EnumStatus enumStatus, boolean flag) &#123; ctx.getResponse().setContentType("application/json; charset=utf-8"); //令zuul过滤该请求，不对其进行路由，直接返回客户端错误信息， ctx.setSendZuulResponse(false); ctx.setResponseBody("&#123;\"msg\":\"" + enumStatus.getInfo() + "\",\"code\":" + enumStatus.getValue() + "&#125;"); ctx.set("isSuccess", flag); &#125; /** * 是否是白名单 * * @param url * @return */ boolean isWhite(String url) &#123; return Arrays.stream(Constant.WHITE_LIST).anyMatch(s -&gt; url.contains(s)); &#125; /** * 是否是白名单 * * @param url * @return */ boolean isBlack(String url) &#123; return Arrays.stream(Constant.BLACK_LIST).anyMatch(s -&gt; url.contains(s)); &#125; @Override public boolean shouldFilter() &#123; // 是否执行该过滤器，此处为true，说明需要过滤 return true; &#125; @Override public int filterOrder() &#123; // 数字越大，优先级越低 return 0; &#125; @Override public String filterType() &#123; // 前置过滤器 return "pre"; &#125;&#125; 在网关统一处理异常ErrorFilter.java 12345678910111213141516171819202122232425262728293031@Componentpublic class ErrorFilter extends ZuulFilter &#123; private static Logger log = LoggerFactory.getLogger(ErrorFilter.class); @Override public String filterType() &#123; //异常过滤器 return "error"; &#125; @Override public int filterOrder() &#123; //优先级，数字越大，优先级越低 return 30; &#125; @Override public boolean shouldFilter() &#123; //是否执行该过滤器，true代表需要过滤 return true; &#125; @Override public Object run() &#123; RequestContext ctx = RequestContext.getCurrentContext(); setError(ctx, ctx.getRequest().getRequestURL().toString()); return null; &#125;&#125;]]></content>
      <categories>
        <category>微服务</category>
      </categories>
      <tags>
        <tag>Spring Cloud</tag>
        <tag>Zuul</tag>
        <tag>网关</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Cloud - Ribbon在Zuul上实现灰度和版本测试]]></title>
    <url>%2Fposts%2F25628%2F</url>
    <content type="text"><![CDATA[本文依赖ribbon实现在Spring Cloud中的灰度测试。 POM引入Zuul及下游服务中均引入包 123456&lt;!-- 实现灰度测试关键包 --&gt; &lt;dependency&gt; &lt;groupId&gt;io.jmnarloch&lt;/groupId&gt; &lt;artifactId&gt;ribbon-discovery-filter-spring-cloud-starter&lt;/artifactId&gt; &lt;version&gt;2.1.0&lt;/version&gt; &lt;/dependency&gt; Zuul服务开发12345678910111213private void fixGray(UserInfo userInfo) &#123; // 配置转发渠道，例如用户id if (isGrayer(userInfo.getUserId())) &#123; RibbonFilterContextHolder.clearCurrentContext(); //灰度标识 RibbonFilterContextHolder.getCurrentContext().add("prod", "2"); RibbonFilterContextHolder.getCurrentContext().add("prod", "1.0"); &#125; else &#123; RibbonFilterContextHolder.clearCurrentContext(); RibbonFilterContextHolder.getCurrentContext().add("prod", "1"); RibbonFilterContextHolder.getCurrentContext().add("prod", "1.1"); &#125;&#125; 下游服务开发添加版本拦截器 12345678910@Configurationpublic class WebMvcConfig extends WebMvcConfigurerAdapter &#123; @Override public void addInterceptors(InterceptorRegistry registry) &#123; super.addInterceptors(registry); registry.addInterceptor(new VersionInterceptor()); &#125;&#125; 实现拦截器 123456789101112131415public class VersionInterceptor extends HandlerInterceptorAdapter &#123; @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123; //清除现有数据，防止干扰 RibbonFilterContextHolder.clearCurrentContext(); String prod = request.getHeader("prod"); String version = request.getHeader("version"); if (!StringUtils.isEmpty(prod)&amp;&amp;!StringUtils.isEmpty(version)) &#123; RibbonFilterContextHolder.getCurrentContext().add("prod", prod); RibbonFilterContextHolder.getCurrentContext().add("version", version); &#125; return true; &#125;&#125; 下游服务配置12345678910eureka: instance: preferIpAddress: true instance-id: $&#123;spring.cloud.client.ip-address&#125;:$&#123;server.port&#125; metadataMap: #元信息 prod: 2 #灰度标识，1生产服务,2为灰度服务 version: 1.1 #服务版本标识 client: registerWithEureka: true fetchRegistry: true 注意事项 通过以上配置，启动各服务，可以实现灰度测试和版本测试 在网关依据灰度和版本请求标识，Ribbon利用各服务的元信息进行匹配，以实现过滤和负载 服务中必须配置相应的请求标识，否则该请求无法负载，将会报错 关闭组件，ribbon.filter.metadata.enabled=false #默认true 源码及原理分析 元信息筛选 123456789101112131415161718public class MetadataAwarePredicate extends DiscoveryEnabledPredicate &#123; /** * &#123;@inheritDoc&#125; */ @Override protected boolean apply(DiscoveryEnabledServer server) &#123; //当前请求上下文 final RibbonFilterContext context = RibbonFilterContextHolder.getCurrentContext(); //当前请求属性 final Set&lt;Map.Entry&lt;String, String&gt;&gt; attributes = Collections.unmodifiableSet(context.getAttributes().entrySet()); //当前服务元信息 final Map&lt;String, String&gt; metadata = server.getInstanceInfo().getMetadata(); //服务元信息是否完全包含请求属性 return metadata.entrySet().containsAll(attributes); &#125;&#125; 注册实例 123456789101112131415@Configuration@ConditionalOnClass(DiscoveryEnabledNIWSServerList.class)@AutoConfigureBefore(RibbonClientConfiguration.class)@ConditionalOnProperty(value = "ribbon.filter.metadata.enabled", matchIfMissing = true)public class RibbonDiscoveryRuleAutoConfiguration &#123; //在Spring application context注册DiscoveryEnabledRule @Bean @ConditionalOnMissingBean @Scope(ConfigurableBeanFactory.SCOPE_PROTOTYPE) public DiscoveryEnabledRule metadataAwareRule() &#123; //使用自定义元信息过滤 return new MetadataAwareRule(); &#125;&#125; 配置请求信息 RibbonFilterContextHolder.getCurrentContext().add(&quot;version&quot;, &quot;1.1&quot;).add(&quot;variant&quot;, &quot;A&quot;); 在zuul中配置，以便调取下游 在下游拦截器中配置，以便当前服务继续调用下游服务 也可以在RestTemplate的ClientHttpRequestInterceptor中配置]]></content>
      <categories>
        <category>微服务</category>
      </categories>
      <tags>
        <tag>Spring Cloud</tag>
        <tag>Ribbon</tag>
        <tag>Zuul</tag>
        <tag>灰度测试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Cloud - Nacos与Eureka区别及如何选型]]></title>
    <url>%2Fposts%2F35353%2F</url>
    <content type="text"><![CDATA[Nacos与Eureka均提供注册中心和服务治理功能，以下为两者差异和选型方案。 功能差异 模块 Nacos Eureka 说明 注册中心 是 是 服务治理基本功能，负责服务中心化注册 配置中心 是 否 Eureka需要配合Config实现配置中心，且不提供管理界面 动态刷新 是 否 Eureka需要配合MQ实现配置动态刷新，Nacos采用Netty保持TCP长连接实时推送 可用区AZ 是 是 对服务集群划分不同区域，实现区域隔离，并提供容灾自动切换 分组 是 否 Nacos可用根据业务和环境进行分组管理 元数据 是 是 提供服务标签数据，例如环境或服务标识 权重 是 否 Nacos默认提供权重设置功能，调整承载流量压力 健康检查 是 是 Nacos支持由客户端或服务端发起的健康检查，Eureka是由客户端发起心跳 负载均衡 是 是 均提供负责均衡策略，Eureka采用Ribion 管理界面 是 否 Nacos支持对服务在线管理，Eureka只是预览服务状态 部署安装 模块 Nacos Eureka 说明 MySql 是 否 Nacos需要采用MySql进行数据进行持久化 MQ 否 是 Eureka需要采用MQ进行配置中心刷新 配置中心 是 否 Eureka结合Config或者Consul实现配置中心 配置文件 在线编辑 本地文件或者Git远程文件 Eureka结合Config或者Consul 集群 是 是 Nacos需要配置集群ip再启动 稳定及扩展性 模块 Nacos Eureka 说明 版本 1.0.0 1.9.9 Eureka2.0已停止开发,Nacos处于1.x-2.0开发 厂商 阿里巴巴 Netflix Netflix已长期用于生产,阿里刚起步 生产建议 否 是 Nacos0.8以前不可用于生产,建议生产采用Nacos1.0,便于节省配置中心集群和服务管理 未来发展 是 否 Nacos 2.0主要关注在统一服务管理、服务共享及服务治理体系的开放的服务平台的建设 选型建议采用Eureka方案的考虑 想用Spring Cloud原生全家桶 想用本地文件和Git作为配置管理的,将配置与服务分开管理 考虑短期的稳定性 采用Nacos方案的考虑 想在线对服务进行上下线和流量管理 不想采用MQ实现配置中心动态刷新 不想新增配置中心生产集群 考虑引入Spring Cloud Alibaba生态]]></content>
      <categories>
        <category>微服务</category>
      </categories>
      <tags>
        <tag>Spring Cloud</tag>
        <tag>Nacos</tag>
        <tag>Eureka</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux运维常用命令 - grep]]></title>
    <url>%2Fposts%2F48230%2F</url>
    <content type="text"><![CDATA[以下为Linux开发中常用的命令。 筛选文本并查看指定上下行数常用于筛选日志，并查看上下文 grep [选项] ‘模式’ [文件] 选项: -A 后几行 -B 前几行 -C 前后几行 模式: 待筛选文本 文件: 待筛选源文件举例 123grep -A 20 'cat' info.log # 显示info.log及后20行grep -B 20 'cat' info.log # 显示info.log及前20行grep -C 20 'cat' info.log # 显示info.log文件里匹配cat字串行以及上下20行 查看linux内存使用情况命令 1free -m 结果 123 total used free shared buff/cache availableMem: 64083 42542 6321 210 15219 20451Swap: 0 0 0 Mem:内存的使用情况总览表 totel:机器总的物理内存 单位为：M used:用掉的内存 free:空闲的物理内存 shared:多个进程共享的内存总和，当前废弃不用 buffers:缓存内存数 cached:缓存内存数注： 物理内存(totel)=系统看到的用掉的内存(used)+系统看到空闲的内存(free) 程序预留的内存=buffers+cached buffer是即将要写入磁盘的，而cache是被从磁盘中读出来的 进程查看器htop 1yum install htop 界面划分成了四个区域，其中： 上左区：显示了CPU、物理内存和交换分区的信息； 上右区：显示了任务数量、平均负载和连接运行时间等信息；平均负载表示的是过去的5分钟、10分钟和15分钟系统的平均负载； 进程区域：显示出当前系统中的所有进程； 123456789101112PID：进程标志号，是非零正整数USER：进程所有者的用户名PR：进程的优先级别NI：进程的优先级别数值VIRT：进程占用的虚拟内存值RES：进程占用的物理内存值SHR：进程使用的共享内存值S：进程的状态，其中S表示休眠，R表示正在运行，Z表示僵死状态，N表示该进程优先值是负数%CPU：该进程占用的CPU使用率%MEM：该进程占用的物理内存和总内存的百分比TIME+：该进程启动后占用的总的CPU时间COMMAND：进程启动的启动命令名称 操作提示区：显示了当前界面中F1-F10功能键中定义的快捷功能。 压缩解压.gz 123解压1：gunzip FileName.gz解压2：gzip -d FileName.gz压缩：gzip FileName]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java并发编程艺术 - 死锁产生及优化]]></title>
    <url>%2Fposts%2F20463%2F</url>
    <content type="text"><![CDATA[本文介绍死锁产生的条件及优化方案。 死锁产生 线程互相等待 常见的死锁有JDK死锁和数据库死锁。 以JDK死锁为例： 12345678910111213141516171819202122232425262728293031323334353637383940public class Deadlock &#123; static class Friend &#123; private final String name; public Friend(String name) &#123; this.name = name; &#125; public String getName() &#123; return this.name; &#125; //同步锁bow public synchronized void bow(Friend bower) &#123; System.out.format("%s: %s" + " has bowed to me!%n", this.name, bower.getName()); //调用同步锁bowBack bower.bowBack(this); &#125; //同步锁bowBack public synchronized void bowBack(Friend bower) &#123; System.out.format("%s: %s" + " has bowed back to me!%n", this.name, bower.getName()); &#125; &#125; public static void main(String[] args) &#123; final Friend alphonse = new Friend("Alphonse"); final Friend gaston = new Friend("Gaston"); new Thread(new Runnable() &#123; public void run() &#123; alphonse.bow(gaston); &#125; &#125;).start(); new Thread(new Runnable() &#123; public void run() &#123; gaston.bow(alphonse); &#125; &#125;).start(); &#125;&#125; 输出： 12Alphonse: Gaston has bowed to me!Gaston: Alphonse has bowed to me! 分析： 执行程序期望是alphonse向gaston鞠躬，并等待gaston还礼；gaston向alphonse鞠躬，并等待alphonse还礼。 两个线程，分别是alphonse线程和gaston线程；alphonse线程传入gaston对象，gaston传入alphonse对象，均执行执行bowBack。 问题是：如果单线程执行，例如alphonse线程执行，结果会是： 12Alphonse: Gaston has bowed to me!Gaston: Alphonse has bowed back to me! 多线程执行时，alphonse和gaston互相鞠躬，但是均等待对方回礼，则在bowBack产生等待死锁。 alphonse和gaston均为对象锁，但是内部进行了互相调用bowBack(Friend bower)。 alphonse获得对象锁，gaston获得对象锁。 alphonse同步调用bow，gaston同步调用bow；没有问题，不会死锁。 alphonse同步锁继续，使用gaston对象调用bowBack，但是gaston也在使用alphonse对象调用bowBack，产生问题。 alphonse-&gt;gaston-&gt;bowBack;gaston-&gt;alphonse-&gt;bowBack;因此alphonse和gaston对象锁都互相加锁且等待对方释放锁，导致死锁。 死锁查看 查看进程执行情况： 1jstack -l 69733 或者采用VisualVM，查看两个对象锁处于等待状态 除了死锁还有活锁、饥饿锁 Oracle说明 避免死锁方法 避免一个线程操作获取多个锁，例如上例中一个方法内获取两个对象锁 避免一个线程在锁内占用多个资源，尽量保证每个锁占用一个，例如上例一个方法期望锁定两个对象 采用定时锁，即lock.tryLock(timeout)，即在限定时间内获取锁，获取不到则放弃，防止死锁等待 123456789/** * @return &#123;@code true&#125; 如果当前线程请求到锁或者本来就拥有锁 * @throws InterruptedException if the current thread is interrupted * @throws NullPointerException if the time unit is null */ public boolean tryLock(long timeout, TimeUnit unit) throws InterruptedException &#123; return sync.tryAcquireNanos(1, unit.toNanos(timeout)); &#125; 对于数据库锁，加锁和解锁在一个数据库连接，否则解锁失败。同一个对象锁进行加锁和解锁操作。 123456789try &#123; //关闭事务自动提交(开启事务) this.connection.setAutoCommit(false); //无异常，手动提交 this.connection.commit();&#125; catch(Exception e) &#123; //当前；连接回滚 this.connection.rollback();&#125; 并发包JUC使用 参考Orace文档]]></content>
      <categories>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>Java并发编程</tag>
        <tag>多线程</tag>
        <tag>死锁</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[搭建GitHub博客教程 - Hexo及Next主题优化]]></title>
    <url>%2Fposts%2F60068%2F</url>
    <content type="text"><![CDATA[本文为针对Hexo博客和Next主题的优化和配置。 标题配置vi _config_yml 1234567title: xxx的技术博客subtitle: xxxdescription: xxkeywords: xxxauthor: xxlanguage: zh-CNtimezone: Asia/Chongqing 首页文章预览限制字数cd themes/next vi _config.yml 123auto_excerpt: enable: true length: 150 文章内使用&lt;!--more--&gt;作为预览分割 修改文章内链接文本样式./themes/next/source/css/_common/components/post/post.styl 末尾添加： 1234567891011// 文章内链接文本样式.post-body p a&#123; color: #0593d3; border-bottom: none; border-bottom: 1px solid #0593d3; &amp;:hover &#123; color: #fc6423; border-bottom: none; border-bottom: 1px solid #fc6423; &#125;&#125; 样式优化cd themes/next vi _config.yml 12345678910111213141516171819202122232425262728293031323334scheme: Piscesgithub_banner: enable: true permalink: https://github.com/xxxx title: Follow me on GitHubback2top: enable: true # Back to top in sidebar. sidebar: true # Scroll percent label in b2t button. scrollpercent: true //加载条pace: true//阅读统计busuanzi_count: enable: true//头像avatar: # In theme directory (source/images): /images/avatar.gif # In site directory (source/uploads): /uploads/avatar.gif # You can also use other linking images. url: http://xx/xxx.jpeg # If true, the avatar would be dispalyed in circle. rounded: true # The value of opacity should be choose from 0 to 1 to set the opacity of the avatar. opacity: 1 # If true, the avatar would be rotated with the cursor. rotated: true favicon.ico 放入/themes/next/source/images 123favicon: small: /images/favicon.png medium: /images/favicon.png 开启标签和分类主要是设置页面类型及关闭评论 创建 12hexo new page tagshexo new page categories 修改主题配置vi ./source/tags/index.md 1234title: tagsdate: 2019-04-20 14:24:27type: "tags"comments: false vi ./source/tags/index.md 1234title: tagsdate: 2019-04-20 14:24:27type: "tags"comments: false 菜单修改主要是打开菜单及统计 vi ./themes/next/_config.yml 123456789menu: home: / || home tags: /tags/ || tags categories: /categories/ || th archives: /archives/ || archive menu_settings: icons: true badges: true RSS、搜索、永久链接1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859npm install hexo-generator-feed --savenpm install hexo-generator-searchdb --savenpm install hexo-symbols-count-time --savenpm i --save hexo-wordcountnpm install hexo-abbrlink --savevi _config.ymlpermalink: posts/:abbrlink/feed: type: atom path: atom.xml limit: 20 hub: content: content_limit: 140 content_limit_delim: ' '# 搜索search: path: search.xml field: post format: html limit: 10000# 时间统计symbols_count_time: count: Symbols count in article count_total: Symbols count total time: Reading time time_total: Reading time total time_minutes: mins.# 字数统计post_wordcount: item_text: true #字数统计 wordcount: true #预览时间 min2read: true #总字数,显示在页面底部 totalcount: false separated_meta: true vi ./themes/next/_config.ymlrss: /atom.xmllocal_search: enable: true symbols_count_time: separated_meta: true item_text_post: true item_text_total: true awl: 4 wpm: 275 pm2 restart allhexo shexo cleanhexo g 本文结束在路径/themes/next/layout/_macro中新建 passage-end-tag.swig 文件,并添加以下内容： 12345&lt;div&gt; &#123;% if not is_index %&#125; &lt;div style="text-align:center;color: #ccc;font-size:14px;"&gt;------ 本文结束------&lt;/div&gt; &#123;% endif %&#125;&lt;/div&gt; 打开themes/next/layout/_macro/下的post.swig文件,添加： 12345678&#123;#####################&#125;&#123;### END POST BODY ###&#125;&#123;#####################&#125;&lt;div&gt; &#123;% if not is_index %&#125; &#123;% include 'passage-end-tag.swig' %&#125; &#123;% endif %&#125; &lt;/div&gt; 注意添加位置 vi ./themes/next/_config.yml,在末尾添加： 123# 文章末尾添加“本文结束”标记passage_end_tag: enabled: true SEO安装与配置1234567npm install hexo-generator-sitemap --savenpm install hexo-generator-baidu-sitemap --savesitemap: path: sitemap.xmlbaidusitemap: path: baidusitemap.xml 在hexo-site\source中新建文件robots.txt,内容如下，请自行替换 123456789101112131415User-agent: *Allow: /Allow: /archives/Allow: /categories/Allow: /tags/ Allow: /about/ Disallow: /vendors/Disallow: /js/Disallow: /css/Disallow: /fonts/Disallow: /vendors/Disallow: /fancybox/Sitemap: https://xxx.github.com/sitemap.xmlSitemap: https://xxx.github.com/baidusitemap.xml google登录https://search.google.com/search-console/welcome 网址前缀-&gt;其他验证方法-&gt;HTML标记，复制meta代码。 百度123vi themes/next/_config.ymlbaidu_push: true 登录https://ziyuan.baidu.com/linksubmit/url 站点管理-&gt;新建站点 HTML标签验证-&gt;复制meta代码 验证1vi ./themes/next/layout/_partials/head/head.swig 在meta下添加google的meta代码。 1hexo clean &amp;&amp; hexo g &amp;&amp; hexo d 然后分别点击刚才 百度、谷歌 验证页面的 验证 按钮进行站点验证。 提交sitemap谷歌 在https://search.google.com/search-console中添加新的站点地图 输入/sitemap.xml 百度 在https://ziyuan.baidu.com/linksubmit/index链接提交-&gt;自动提交-&gt;sitemap 输入:https://xxxx.github.io/baidusitemap.xml 坑：GitHub Pages 禁止百度爬虫，且需要HTTPS认证，提供自定义域名。 百度站点统计访问注册https://tongji.baidu.com/web/welcome/login Baidu Analytics ID: hm.src = https://hm.baidu.com/hm.js?`81b7a9fddbd9b9470364a87a43991a67`; 12vi themes/next/_config.ymlbaidu_analytics: 81b7a9fddbd9b9470364a87a43991a67 评论注册OAuth Application在GitHub上注册新应用, 链接:https://github.com/settings/applications/new 12345Application name 应用名称, 可以任意填入Homepage URL 网站URL, 注意用https://开头, 开头如https://vonsdite.cnApplication description 应用描述, 可以任意填入Authorization callback URL 网站URL, 注意用https://开头, 如https://vonsdite.cn注册后记下Client ID和Client Secret, 后续要使用到 修改主题配置文件_config.yml 在主题配置文件themes/next/_config.yml中添加如下内容: 12345678gitalk: enable: true githubID: github帐号 # 例：vonsdite 注意必须小写 repo: 仓库名称 # 例：vonsdite.github.io ClientID: Client ID # 上文注册 OAuth Application后得到的值 ClientSecret: Client Secret # 上文注册 OAuth Application后得到的值 adminUser: github帐号 # 指定可初始化评论账户, 例：vonsdite 注意必须小写 distractionFreeMode: true 版权声明主题配置文件 12345creative_commons: license: by-nc-sa sidebar: false post: true language: 相关文章npm install hexo-related-popular-posts --save 主题配置 123456related_posts: enable: true title: # custom header, leave empty to use the default one display_in_home: false params: maxCount: 5 图片大小配置下载 存储路径:./themes/next/source/js/hexo_resize_image.js 修改./themes/next/layout/_partials/head/head.swig 添加 1&lt;script src=&quot;&#123;&#123; url_for(theme.js) &#125;&#125;/hexo_resize_image.js?v=&#123;&#123; version &#125;&#125;&quot;&gt;&lt;/script&gt; 使用语法： url?&lt;width&gt;x&lt;height&gt;，指定宽高，例如/image/test.jpg?200x200 url?&lt;width&gt;x&lt;height&gt;，指定宽，高等比缩放，例如/image/test.jpg?200x url?&lt;width&gt;x&lt;height&gt;，指定高，宽等比缩放，例如/image/test.jpg?x200 url?缩放比例，指定缩放例如，例如/image/test.jpg?50 进度条1234567cd themes/nextgit clone https://github.com/theme-next/theme-next-pace source/lib/pacevi _config.ymlpace: true]]></content>
      <categories>
        <category>工具利器</category>
      </categories>
      <tags>
        <tag>工具</tag>
        <tag>Hexo</tag>
        <tag>GitHub</tag>
        <tag>Next</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Cloud - Nacos集群配置和集成]]></title>
    <url>%2Fposts%2F57096%2F</url>
    <content type="text"><![CDATA[本文介绍生产环境中Nacos集群的安装配置，及与Spring Cloud的集成。 Nacos介绍类似于Spring Cloud Eureka和Spring Cloud Config，Nacos提供了服务注册管理和配置中心的功能；其中配置中心实现动态刷新，无需MQ。 相对于Eureka，Nacos是由阿里提供的开源服务，可以兼容Spring Cloud，也支持其他语言例如python服务的注册管理。 Nacos安装 环境要求： 64 bit JDK 1.8+ MySql 5.6.5+ 安装包下载当前版本 1.0.0 解压unzip nacos-server-$version.ziptar -xvf nacos-server-$version.tar.gz Nacos配置 MySql内执行sql/nacos/conf/nacos-mysql.sql 数据源配置/nacos/conf/application.properties 12345spring.datasource.platform=mysqldb.num=1db.url.0=jdbc:mysql://xxx:3306/nacos_config?characterEncoding=utf8&amp;connectTimeout=1000&amp;socketTimeout=3000&amp;autoReconnect=truedb.user=xxxdb.password=xxx 集群配置/nacos/conf/cluster.conf 123192.168.1.100:8848192.168.1.101:8848192.168.1.102:8848 在100-102机器上，复制存储nacos文件。 Nginx负载均衡部署集群后，由3台集群提供管理界面，可以配置Nginx进行负载。 123456789101112131415161718upstream nacos_cluster &#123; server 192.168.1.100:8848; server 192.168.1.101:8848; server 192.168.1.102:8848;&#125;server&#123; listen 80; server_name localhost; location / &#123; proxy_pass http://nacos_cluster; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; &#125;&#125; 8848为管理系统端口访问localhost,可以进入Nacos管理界面默认用户名和密码是nacos/nacosusers表存储的是用户名、密码，可以进行修改new BCryptPasswordEncoder().encode(“nacos”)修改密码 启动和关闭 /nacos/bin 启动 sh startup.sh 启动后打印的关键参数 -server -Xms2g -Xmx2g -Xmn1g -XX:MetaspaceSize=128m -XX:MaxMetaspaceSize=320m -XX:-OmitStackTraceInFastThrow -XX:+HeapDumpOnOutOfMemoryError -XX:-UseLargePages -verbose:gc -XX:+PrintGCDetails -XX:+PrintGCDateStamps -XX:+PrintGCTimeStamps -XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles=10 -XX:GCLogFileSize=100M关闭 sh shutdown.sh Spring Cloud集成Nacospom引入12345678910111213141516171819202122232425262728293031323334353637383940414243&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.0.5.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;/parent&gt;&lt;properties&gt; &lt;spring-cloud-alibaba-dependencies.version&gt;0.2.1.RELEASE&lt;/spring-cloud-alibaba-dependencies.version&gt; &lt;spring-cloud.version&gt;Finchley.RELEASE&lt;/spring-cloud.version&gt;&lt;/properties&gt;&lt;dependencies&gt; &lt;!-- nacos服务注册与发现 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- nacos分布式配置 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-config&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt;&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;$&#123;spring-cloud.version&#125;&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-alibaba-dependencies&lt;/artifactId&gt; &lt;version&gt;$&#123;spring-cloud-alibaba-dependencies.version&#125;&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt; 配置参数Application.java 123456789@EnableDiscoveryClient@SpringBootApplication@RefreshScope@EnableFeignClientspublic class Application&#123; public static void main(String[] args) &#123; SpringApplication.run(Application.class, args); &#125;&#125; bootstrap.yml 1234567891011spring: application: name: xxxx profiles: active: dev cloud: nacos: discovery: server-addr: 192.168.1.100:8848,192.168.1.101:8848,192.168.1.102:8848 #注册中心地址集群 config: server-addr: 192.168.1.100:8848,192.168.1.101:8848,192.168.1.102:8848 #配置中心地址集群 fegin测试1234567@FeignClient(value = "xxxx")public interface XXXServer &#123; // 获取主码描述 @RequestMapping(path = "/api/xxxx", method = RequestMethod.POST) String getInfo();&#125;]]></content>
      <categories>
        <category>微服务</category>
      </categories>
      <tags>
        <tag>Spring Cloud</tag>
        <tag>Nacos</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java并发编程艺术 - 多线程与资源限制]]></title>
    <url>%2Fposts%2F10420%2F</url>
    <content type="text"><![CDATA[文本介绍多线程和资源的关系。 是否多线程越多速度越快？ 结论：并发编程中采用多线程，并非线程越多执行效率越高。 线程执行是由CPU分配较短的时间片，线程在得到时间片时执行，并在时间片后挂起，并切换其他线程执行。 线程切换时先会保存上一个线程状态，并加载当前线程的历史状态。 因为线程的上下文切换需要时间，影响多线程执行速度。 在执行某些简单、快速任务情况下，多线程执行效率还不如单线程执行。假如单核采用单线程执行任务仅需要20ms，但单核采用多线程，并发100，可能创建线程时间就超出20ms，再加上单核只能执行单线程，需要多线程频繁挂起、上下文切换肯定慢。 在低核时，不建议采用多线程进行CPU密集型计算；建议采用多线程执行监听输入、读取文件、网络通信等IO密集型操作。 如何减少上下文切换 采用无锁的并发编程，即不进行锁竞争；例如根据ID进行Hash取模，多线程进行分段处理数据。我们常见的JDK1.7中ConcurrentHashMap就是锁分段技术，对key进行hashcode，然后取桶位置，默认1/16；在更新数据时锁数据所在桶，不影响其他桶并发操作，以提高并发处理数据速度。 12345678910111213141516public V put(K key, V value) &#123; if (value == null) throw new NullPointerException(); // 计算键对应的散列码 int hash = hash(key.hashCode()); // 根据散列码找到对应的 Segment return segmentFor(hash).put(key, hash, value, false);&#125;/*** 使用 key 的散列码来得到 segments 数组中对应的 Segment*/final Segment&lt;K,V&gt; segmentFor(int hash) &#123; // 最后根据下标值返回散列码对应的 Segment 对象 return segments[(hash &gt;&gt;&gt; segmentShift) &amp; segmentMask];&#125; CAS算法，JAVA采用Atomic的CAS算法进行乐观锁更新数据，不进行加锁。所谓CAS其实就是compareAndSwap即比较并交换，参数有3个为old、expect和update；即如果old和expect仍然一致，没有因为并发和内存不可见性被修改，则修改old为update。 例如AtomicInteger中进行变量自增： 123456789101112131415161718192021/** * 通过当前值进行原子递增. * * @return 更新值 */public final int incrementAndGet() &#123; return unsafe.getAndAddInt(this, valueOffset, 1) + 1;&#125;public final int getAndAddInt(Object var1, long var2, int var4) &#123; int var5; do &#123; var5 = this.getIntVolatile(var1, var2); &#125; while(!this.compareAndSwapInt(var1, var2, var5, var5 + var4));//cas操作 return var5;&#125;public final boolean compareAndSet(int expect, int update) &#123; return unsafe.compareAndSwapInt(this, valueOffset, expect, update);&#125; 采用最小线程。避免不必要的线程，处于等待状态。 例如JUC包Executors类创建线程池参数，corePoolSize为核心线程数量，如allowCoreThreadTimeOut不设置，可以认为corePoolSize是最小线程数。 如果设置和maximumPoolSize一样大，则表示即使达到keepAliveTime空闲时间也不回收，均处于waiting状态。 123456789101112131415161718192021222324252627282930313233343536373839404142/** * 创建单个线程 * * @param threadFactory 线程工厂 * * @return 单线程执行器 * @throws NullPointerException if threadFactory is null */public static ExecutorService newSingleThreadExecutor(ThreadFactory threadFactory) &#123; return new FinalizableDelegatedExecutorService (new ThreadPoolExecutor(1, 1, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;(), threadFactory));&#125;/** * 根据参数和配置，创建线程池. * * @param corePoolSize 池中核心线程数 * @param maximumPoolSize 池中最大线程数 * @param keepAliveTime 线程数大于核心线程数时, 多余的待回收线程最大空闲时间 * @param unit 时间单位 * @param workQueue 任务执行队列 * @param threadFactory 创建线程的工厂 * @throws IllegalArgumentException if one of the following holds:&lt;br&gt; * &#123;@code corePoolSize &lt; 0&#125;&lt;br&gt; * &#123;@code keepAliveTime &lt; 0&#125;&lt;br&gt; * &#123;@code maximumPoolSize &lt;= 0&#125;&lt;br&gt; * &#123;@code maximumPoolSize &lt; corePoolSize&#125; * @throws NullPointerException if &#123;@code workQueue&#125; * or &#123;@code threadFactory&#125; is null */public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory) &#123; this(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue, threadFactory, defaultHandler);&#125; 协程。在单线程中实现多任务的调度，并在单线程中维持多任务的切换。 资源限制的挑战 并发编程受限与机器硬件或软件资源。例如带宽、硬盘读写速度等硬件资源和数据库连接数、socket连接数等软件资源。 并发编程为加快执行速度，将串行任务并发执行，受资源影响，实际仍在串行切换执行，切换上下文和资源调度反而降低执行速度。 解决资源限制，采用集群执行，改单机为多机。对数据id取机器数模，在该机器处理该数据；软件资源考虑资源池复用，NIO等。 在资源限制下并发编程，根据资源调整并发度，例如读写分离，读写锁等。]]></content>
      <categories>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>Java并发编程</tag>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[IDEA开发快捷键 - Mac]]></title>
    <url>%2Fposts%2F10018%2F</url>
    <content type="text"><![CDATA[本文介绍IDEA中进行Java开发的常用快捷键。 编辑撤销： ⌘+Z切换大小写： ⇧+⌘+U上一个位置： ⌥+⌘+←下一个位置： ⌥+⌘+→(反)注释行： ⌘+/(反)注释块： ⌥+⌘+/格式化： ⌥+⌘+L生成构造器： ⌘+N查看方法实现： ⌥+⌘+B删除当前或者选中块行： ⌘+⌫查找全局查找： ⇧+⇧]]></content>
      <categories>
        <category>工具利器</category>
      </categories>
      <tags>
        <tag>IDEA</tag>
        <tag>工具</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[快速搭建GitHub博客教程 - Hexo及Next主题安装]]></title>
    <url>%2Fposts%2F17587%2F</url>
    <content type="text"><![CDATA[本文为在Mac上利用Hexo搭建GitHub博客过程，选择主题为Next。 Git安装和配置Git安装 下载地址：downloads 选择Mac版本并安装 确认安装成功 1git --version Git GUI安装 下载地址：git-scm 建议：命令行用git bash，工具用SourceTree git常用命令：gittutorial Git私钥公钥配置 生成公钥和私钥 Github配置注册 地址:注册 创建Respository new Repository name:[username].github.io 配置公钥 settings 新建SSH Keys，输入本地公钥 查看本地公钥：cd ~ cd .ssh/cat id_rsa.pub拷贝结果至github的SSH Keys Hexo安装和配置Hexo安装 安装：npm install -g hexo-cli 初始化目录 hexo init [folder] hexo Next主题安装 cd hexo git clone https://github.com/theme-next/hexo-theme-next themes/next hexo-theme-next Hexo主题配置 vi _config.yml 修改theme: next Hexo配置Github部署地址 安装插件 npm install hexo-deployer-git –save 修改Hexo vi _config.yml，修改内容如下: 1234deploy: type: git repo: git@github.com:username/username.github.io.git brach: master deployment hexo-deployer-git Hexo操作12345hexo s，启动hexo d -g，生成并发布hexo new ’title‘，新建文章 参考文档 Mac后台启动Hexo服务准备工作 安装pm2 npm install -g pm2 编辑脚本代码 在hexo博客的根目录下新建run.js文件 12345678910//run.jsconst &#123; exec &#125; = require('child_process')exec('hexo s',(error, stdout, stderr) =&gt; &#123; if(error)&#123; console.log(`exec error: $&#123;error&#125;`) return &#125; console.log(`stdout: $&#123;stdout&#125;`); console.log(`stderr: $&#123;stderr&#125;`);&#125;) 运行 pm2 start run.js 重启pm2 restart all]]></content>
      <categories>
        <category>工具利器</category>
      </categories>
      <tags>
        <tag>工具</tag>
        <tag>Hexo</tag>
        <tag>GitHub</tag>
        <tag>Next</tag>
      </tags>
  </entry>
</search>
